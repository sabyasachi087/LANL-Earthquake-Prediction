{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we have seen in previous notebook, more feature engineering is required. Few of the Kaggle kernels used moving averages, quantiles and trends.\n",
    "<ol>\n",
    "    <li>Quantile features from this kernel: https://www.kaggle.com/andrekos/basic-feature-benchmark-with-quantiles</li>\n",
    "    <li>Trend features from this kernel: https://www.kaggle.com/jsaguiar/baseline-with-abs-and-trend-features</li>\n",
    "    <li>Rolling features from this kernel: https://www.kaggle.com/wimwim/rolling-quantiles</li>\n",
    "</ol>\n",
    "I have incorporated above and updated the train_data_generator.py to generate these feature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train file is ready with train_data_generator.py and train_sampler.py. All we need to do now is to import and see."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data file already exists ..Fitting completed\n",
      "Transformation completed ... \n",
      "Dropping columns  ['acc_mean', 'median_50', 'auc'] ...\n",
      "Standard Scaler applied ... \n"
     ]
    }
   ],
   "source": [
    "import accoustic_sampler as acs\n",
    "import data_formatter as dtFrm\n",
    "\n",
    "sampler = acs.AccousticSampler('D:/PYTHON_WORKSPACES/Kaggles/EarthquakePrediction/LANL_Earthquake/data/train_data_new')\n",
    "sampler.fit()\n",
    "data_df = sampler.get()\n",
    "# columns_to_drop=columns_to_drop\n",
    "formatter = dtFrm.LANLDataFormatter(data_df=data_df, data_type='train', doTransform=True, doScale=True, cols_to_keep=50)\n",
    "data_df = formatter.transform()\n",
    "most_dependent_columns = formatter.getMostImpCols()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variable 'most_dependent_columns' will be used for test data set as well. I have already trained the data set using LGBMRegressor and created a pickle file. All we need is to load the same. Please run the lgbm_test.py to generate the pickle model. The file also contains the CV test which are commented in order to improve the model if necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>q05_roll_std_100</th>\n",
       "      <th>q01_roll_std_100</th>\n",
       "      <th>q05_roll_std_10</th>\n",
       "      <th>q01_roll_std_10</th>\n",
       "      <th>q05_roll_std_1000</th>\n",
       "      <th>q01_roll_std_1000</th>\n",
       "      <th>q01_log</th>\n",
       "      <th>q99_log</th>\n",
       "      <th>q99_roll_mean_10_log</th>\n",
       "      <th>min_roll_std_1000</th>\n",
       "      <th>...</th>\n",
       "      <th>max_roll_std_10_log</th>\n",
       "      <th>time_per_max_range</th>\n",
       "      <th>max_dist_from_mean</th>\n",
       "      <th>acc_max_log</th>\n",
       "      <th>chg_acc_min_log</th>\n",
       "      <th>chg_acc_max_log</th>\n",
       "      <th>ave_roll_std_1000</th>\n",
       "      <th>ave_roll_std_10</th>\n",
       "      <th>median_25</th>\n",
       "      <th>ave_roll_std_100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.132463</td>\n",
       "      <td>1.084806</td>\n",
       "      <td>0.792875</td>\n",
       "      <td>0.931954</td>\n",
       "      <td>1.352746</td>\n",
       "      <td>1.829103</td>\n",
       "      <td>-0.828981</td>\n",
       "      <td>0.871222</td>\n",
       "      <td>0.796488</td>\n",
       "      <td>0.882394</td>\n",
       "      <td>...</td>\n",
       "      <td>0.620893</td>\n",
       "      <td>-0.602602</td>\n",
       "      <td>0.481358</td>\n",
       "      <td>0.474880</td>\n",
       "      <td>-0.615128</td>\n",
       "      <td>0.690355</td>\n",
       "      <td>0.397420</td>\n",
       "      <td>0.397058</td>\n",
       "      <td>-0.396808</td>\n",
       "      <td>0.337247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.583159</td>\n",
       "      <td>0.443190</td>\n",
       "      <td>0.192855</td>\n",
       "      <td>0.302379</td>\n",
       "      <td>0.520259</td>\n",
       "      <td>0.692956</td>\n",
       "      <td>-0.828981</td>\n",
       "      <td>0.741979</td>\n",
       "      <td>0.886868</td>\n",
       "      <td>0.556486</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.077081</td>\n",
       "      <td>-0.155580</td>\n",
       "      <td>0.036501</td>\n",
       "      <td>0.028676</td>\n",
       "      <td>0.108663</td>\n",
       "      <td>-0.003405</td>\n",
       "      <td>0.239752</td>\n",
       "      <td>0.191857</td>\n",
       "      <td>-0.396808</td>\n",
       "      <td>0.223631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.558992</td>\n",
       "      <td>-0.631891</td>\n",
       "      <td>-0.578320</td>\n",
       "      <td>-0.435531</td>\n",
       "      <td>-0.473787</td>\n",
       "      <td>-0.574577</td>\n",
       "      <td>0.991674</td>\n",
       "      <td>-1.199113</td>\n",
       "      <td>-1.201293</td>\n",
       "      <td>-0.165992</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.193241</td>\n",
       "      <td>1.467542</td>\n",
       "      <td>-1.386264</td>\n",
       "      <td>-1.371912</td>\n",
       "      <td>1.038745</td>\n",
       "      <td>-1.343103</td>\n",
       "      <td>-0.577111</td>\n",
       "      <td>-0.537765</td>\n",
       "      <td>-0.396808</td>\n",
       "      <td>-0.524857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.462218</td>\n",
       "      <td>0.351752</td>\n",
       "      <td>0.444617</td>\n",
       "      <td>0.302379</td>\n",
       "      <td>0.657004</td>\n",
       "      <td>0.752134</td>\n",
       "      <td>-0.157031</td>\n",
       "      <td>0.002353</td>\n",
       "      <td>-0.018339</td>\n",
       "      <td>0.335649</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.048894</td>\n",
       "      <td>0.656167</td>\n",
       "      <td>-0.768290</td>\n",
       "      <td>-0.768394</td>\n",
       "      <td>1.193979</td>\n",
       "      <td>-1.096030</td>\n",
       "      <td>-0.097282</td>\n",
       "      <td>-0.085439</td>\n",
       "      <td>-0.396808</td>\n",
       "      <td>-0.076643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.615791</td>\n",
       "      <td>0.699098</td>\n",
       "      <td>0.444617</td>\n",
       "      <td>0.931954</td>\n",
       "      <td>0.290687</td>\n",
       "      <td>0.417168</td>\n",
       "      <td>-0.459180</td>\n",
       "      <td>0.466500</td>\n",
       "      <td>0.405681</td>\n",
       "      <td>0.630478</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.195788</td>\n",
       "      <td>0.204231</td>\n",
       "      <td>-0.124539</td>\n",
       "      <td>-0.128639</td>\n",
       "      <td>-0.025142</td>\n",
       "      <td>-0.338301</td>\n",
       "      <td>0.106920</td>\n",
       "      <td>0.139062</td>\n",
       "      <td>-0.396808</td>\n",
       "      <td>0.089279</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   q05_roll_std_100  q01_roll_std_100  q05_roll_std_10  q01_roll_std_10  \\\n",
       "0          1.132463          1.084806         0.792875         0.931954   \n",
       "1          0.583159          0.443190         0.192855         0.302379   \n",
       "2         -0.558992         -0.631891        -0.578320        -0.435531   \n",
       "3          0.462218          0.351752         0.444617         0.302379   \n",
       "4          0.615791          0.699098         0.444617         0.931954   \n",
       "\n",
       "   q05_roll_std_1000  q01_roll_std_1000   q01_log   q99_log  \\\n",
       "0           1.352746           1.829103 -0.828981  0.871222   \n",
       "1           0.520259           0.692956 -0.828981  0.741979   \n",
       "2          -0.473787          -0.574577  0.991674 -1.199113   \n",
       "3           0.657004           0.752134 -0.157031  0.002353   \n",
       "4           0.290687           0.417168 -0.459180  0.466500   \n",
       "\n",
       "   q99_roll_mean_10_log  min_roll_std_1000  ...  max_roll_std_10_log  \\\n",
       "0              0.796488           0.882394  ...             0.620893   \n",
       "1              0.886868           0.556486  ...            -0.077081   \n",
       "2             -1.201293          -0.165992  ...            -1.193241   \n",
       "3             -0.018339           0.335649  ...            -1.048894   \n",
       "4              0.405681           0.630478  ...            -0.195788   \n",
       "\n",
       "   time_per_max_range  max_dist_from_mean  acc_max_log  chg_acc_min_log  \\\n",
       "0           -0.602602            0.481358     0.474880        -0.615128   \n",
       "1           -0.155580            0.036501     0.028676         0.108663   \n",
       "2            1.467542           -1.386264    -1.371912         1.038745   \n",
       "3            0.656167           -0.768290    -0.768394         1.193979   \n",
       "4            0.204231           -0.124539    -0.128639        -0.025142   \n",
       "\n",
       "   chg_acc_max_log  ave_roll_std_1000  ave_roll_std_10  median_25  \\\n",
       "0         0.690355           0.397420         0.397058  -0.396808   \n",
       "1        -0.003405           0.239752         0.191857  -0.396808   \n",
       "2        -1.343103          -0.577111        -0.537765  -0.396808   \n",
       "3        -1.096030          -0.097282        -0.085439  -0.396808   \n",
       "4        -0.338301           0.106920         0.139062  -0.396808   \n",
       "\n",
       "   ave_roll_std_100  \n",
       "0          0.337247  \n",
       "1          0.223631  \n",
       "2         -0.524857  \n",
       "3         -0.076643  \n",
       "4          0.089279  \n",
       "\n",
       "[5 rows x 50 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Using the entire data set for training\n",
    "y_train = data_df['time_to_failure']\n",
    "x_train_seg = data_df['segment_id']\n",
    "x_train = data_df.drop(['time_to_failure','segment_id'], axis=1)\n",
    "x_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMRegressor(bagging_fraction=0.5, bagging_freq=2, bagging_seed=5,\n",
       "       boosting='gbdt', boosting_type='gbdt', class_weight=None,\n",
       "       colsample_bytree=1.0, feature_fraction=1.0, importance_type='split',\n",
       "       learning_rate=0.001, max_depth=-1, metric='mae',\n",
       "       min_child_samples=20, min_child_weight=0.001, min_data_in_leaf=100,\n",
       "       min_split_gain=0.0, n_estimators=20000, n_jobs=-1, num_leaves=128,\n",
       "       objective='regression', random_state=None, reg_alpha=0.1,\n",
       "       reg_lambda=1.0, silent=False, subsample=1.0,\n",
       "       subsample_for_bin=200000, subsample_freq=0, verbosity=-1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "model = lgb.LGBMRegressor(bagging_fraction=0.5, bagging_freq=2, bagging_seed=5,\n",
    "       boosting='gbdt', boosting_type='gbdt', class_weight=None,\n",
    "       colsample_bytree=1.0, feature_fraction=1.0, importance_type='split',\n",
    "       learning_rate=0.001, max_depth=-1, metric='mae',\n",
    "       min_child_samples=20, min_child_weight=0.001, min_data_in_leaf=100,\n",
    "       min_split_gain=0.0, n_estimators=20000, n_jobs=-1, num_leaves=128,\n",
    "       objective='regression', random_state=None, reg_alpha=0.1,\n",
    "       reg_lambda=1.0, silent=False, subsample=1.0,\n",
    "       subsample_for_bin=200000, subsample_freq=0, verbosity=-1)\n",
    "model.fit(x_train, y_train, verbose=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data file already exists ..Fitting completed\n",
      "Transformation completed ... \n",
      "Dropping columns  ['acc_mean', 'median_50', 'auc'] ...\n",
      "Standard Scaler applied ... \n",
      "Test data size  2624\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>q05_roll_std_100</th>\n",
       "      <th>q01_roll_std_100</th>\n",
       "      <th>q05_roll_std_10</th>\n",
       "      <th>q01_roll_std_10</th>\n",
       "      <th>q05_roll_std_1000</th>\n",
       "      <th>q01_roll_std_1000</th>\n",
       "      <th>q01_log</th>\n",
       "      <th>q99_log</th>\n",
       "      <th>q99_roll_mean_10_log</th>\n",
       "      <th>min_roll_std_1000</th>\n",
       "      <th>...</th>\n",
       "      <th>time_per_max_range</th>\n",
       "      <th>max_dist_from_mean</th>\n",
       "      <th>acc_max_log</th>\n",
       "      <th>chg_acc_min_log</th>\n",
       "      <th>chg_acc_max_log</th>\n",
       "      <th>ave_roll_std_1000</th>\n",
       "      <th>ave_roll_std_10</th>\n",
       "      <th>median_25</th>\n",
       "      <th>ave_roll_std_100</th>\n",
       "      <th>segment_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.473070</td>\n",
       "      <td>0.578964</td>\n",
       "      <td>0.143651</td>\n",
       "      <td>0.199808</td>\n",
       "      <td>0.529071</td>\n",
       "      <td>0.512646</td>\n",
       "      <td>0.380333</td>\n",
       "      <td>-0.171774</td>\n",
       "      <td>-0.235943</td>\n",
       "      <td>-0.515151</td>\n",
       "      <td>...</td>\n",
       "      <td>0.444237</td>\n",
       "      <td>-0.241210</td>\n",
       "      <td>-0.243171</td>\n",
       "      <td>1.014980</td>\n",
       "      <td>-0.850613</td>\n",
       "      <td>-0.220017</td>\n",
       "      <td>-0.190820</td>\n",
       "      <td>0.400246</td>\n",
       "      <td>-0.182965</td>\n",
       "      <td>seg_00030f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.031385</td>\n",
       "      <td>0.103841</td>\n",
       "      <td>-0.056244</td>\n",
       "      <td>-0.247975</td>\n",
       "      <td>0.077580</td>\n",
       "      <td>0.323945</td>\n",
       "      <td>-0.326368</td>\n",
       "      <td>0.156542</td>\n",
       "      <td>0.121378</td>\n",
       "      <td>0.273865</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.465386</td>\n",
       "      <td>0.271509</td>\n",
       "      <td>0.263658</td>\n",
       "      <td>-0.258143</td>\n",
       "      <td>-0.275335</td>\n",
       "      <td>-0.065598</td>\n",
       "      <td>-0.068861</td>\n",
       "      <td>0.400246</td>\n",
       "      <td>-0.064598</td>\n",
       "      <td>seg_0012b5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.031155</td>\n",
       "      <td>0.125786</td>\n",
       "      <td>-0.056244</td>\n",
       "      <td>-0.157804</td>\n",
       "      <td>-0.231023</td>\n",
       "      <td>-0.018358</td>\n",
       "      <td>-0.174712</td>\n",
       "      <td>0.156542</td>\n",
       "      <td>0.253136</td>\n",
       "      <td>-0.330997</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.837817</td>\n",
       "      <td>1.150123</td>\n",
       "      <td>1.153133</td>\n",
       "      <td>-0.835552</td>\n",
       "      <td>0.427175</td>\n",
       "      <td>-0.027233</td>\n",
       "      <td>-0.072150</td>\n",
       "      <td>0.400246</td>\n",
       "      <td>-0.049649</td>\n",
       "      <td>seg_00184e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.037652</td>\n",
       "      <td>-0.846167</td>\n",
       "      <td>-1.081584</td>\n",
       "      <td>-0.980918</td>\n",
       "      <td>-0.958864</td>\n",
       "      <td>-0.966187</td>\n",
       "      <td>1.199520</td>\n",
       "      <td>-0.954900</td>\n",
       "      <td>-0.883336</td>\n",
       "      <td>-1.176640</td>\n",
       "      <td>...</td>\n",
       "      <td>0.620867</td>\n",
       "      <td>-0.800200</td>\n",
       "      <td>-0.792394</td>\n",
       "      <td>0.810318</td>\n",
       "      <td>-0.377557</td>\n",
       "      <td>-0.534459</td>\n",
       "      <td>-0.545865</td>\n",
       "      <td>2.446511</td>\n",
       "      <td>-0.517331</td>\n",
       "      <td>seg_003339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.368337</td>\n",
       "      <td>-0.378088</td>\n",
       "      <td>-0.308461</td>\n",
       "      <td>-0.247975</td>\n",
       "      <td>-0.630210</td>\n",
       "      <td>-0.580274</td>\n",
       "      <td>-0.008592</td>\n",
       "      <td>-0.003294</td>\n",
       "      <td>0.053253</td>\n",
       "      <td>-0.095551</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.615400</td>\n",
       "      <td>0.547272</td>\n",
       "      <td>0.540320</td>\n",
       "      <td>-0.019989</td>\n",
       "      <td>0.495314</td>\n",
       "      <td>-0.153716</td>\n",
       "      <td>-0.166164</td>\n",
       "      <td>0.400246</td>\n",
       "      <td>-0.150474</td>\n",
       "      <td>seg_0042cc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   q05_roll_std_100  q01_roll_std_100  q05_roll_std_10  q01_roll_std_10  \\\n",
       "0          0.473070          0.578964         0.143651         0.199808   \n",
       "1          0.031385          0.103841        -0.056244        -0.247975   \n",
       "2          0.031155          0.125786        -0.056244        -0.157804   \n",
       "3         -1.037652         -0.846167        -1.081584        -0.980918   \n",
       "4         -0.368337         -0.378088        -0.308461        -0.247975   \n",
       "\n",
       "   q05_roll_std_1000  q01_roll_std_1000   q01_log   q99_log  \\\n",
       "0           0.529071           0.512646  0.380333 -0.171774   \n",
       "1           0.077580           0.323945 -0.326368  0.156542   \n",
       "2          -0.231023          -0.018358 -0.174712  0.156542   \n",
       "3          -0.958864          -0.966187  1.199520 -0.954900   \n",
       "4          -0.630210          -0.580274 -0.008592 -0.003294   \n",
       "\n",
       "   q99_roll_mean_10_log  min_roll_std_1000  ...  time_per_max_range  \\\n",
       "0             -0.235943          -0.515151  ...            0.444237   \n",
       "1              0.121378           0.273865  ...           -0.465386   \n",
       "2              0.253136          -0.330997  ...           -0.837817   \n",
       "3             -0.883336          -1.176640  ...            0.620867   \n",
       "4              0.053253          -0.095551  ...           -0.615400   \n",
       "\n",
       "   max_dist_from_mean  acc_max_log  chg_acc_min_log  chg_acc_max_log  \\\n",
       "0           -0.241210    -0.243171         1.014980        -0.850613   \n",
       "1            0.271509     0.263658        -0.258143        -0.275335   \n",
       "2            1.150123     1.153133        -0.835552         0.427175   \n",
       "3           -0.800200    -0.792394         0.810318        -0.377557   \n",
       "4            0.547272     0.540320        -0.019989         0.495314   \n",
       "\n",
       "   ave_roll_std_1000  ave_roll_std_10  median_25  ave_roll_std_100  segment_id  \n",
       "0          -0.220017        -0.190820   0.400246         -0.182965  seg_00030f  \n",
       "1          -0.065598        -0.068861   0.400246         -0.064598  seg_0012b5  \n",
       "2          -0.027233        -0.072150   0.400246         -0.049649  seg_00184e  \n",
       "3          -0.534459        -0.545865   2.446511         -0.517331  seg_003339  \n",
       "4          -0.153716        -0.166164   0.400246         -0.150474  seg_0042cc  \n",
       "\n",
       "[5 rows x 51 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Let's load our test file which is again pre generated as test_data_model.csv.\n",
    "import accoustic_sampler as acs\n",
    "\n",
    "sampler = acs.AccousticSampler('D:/PYTHON_WORKSPACES/Kaggles/EarthquakePrediction/LANL_Earthquake/data/test_data',data_type='test')\n",
    "sampler.fit()\n",
    "test_data_df = sampler.get()\n",
    "\n",
    "import data_formatter as dtFrm\n",
    "formatter = dtFrm.LANLDataFormatter(data_df=test_data_df, data_type='test', doTransform=True, doScale=True,\\\n",
    "                                    most_dependent_columns=most_dependent_columns)\n",
    "test_df = formatter.transform()\n",
    "print('Test data size ',test_df.shape[0])\n",
    "test_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>q05_roll_std_100</th>\n",
       "      <th>q01_roll_std_100</th>\n",
       "      <th>q05_roll_std_10</th>\n",
       "      <th>q01_roll_std_10</th>\n",
       "      <th>q05_roll_std_1000</th>\n",
       "      <th>q01_roll_std_1000</th>\n",
       "      <th>q01_log</th>\n",
       "      <th>q99_log</th>\n",
       "      <th>q99_roll_mean_10_log</th>\n",
       "      <th>min_roll_std_1000</th>\n",
       "      <th>...</th>\n",
       "      <th>max_roll_std_10_log</th>\n",
       "      <th>time_per_max_range</th>\n",
       "      <th>max_dist_from_mean</th>\n",
       "      <th>acc_max_log</th>\n",
       "      <th>chg_acc_min_log</th>\n",
       "      <th>chg_acc_max_log</th>\n",
       "      <th>ave_roll_std_1000</th>\n",
       "      <th>ave_roll_std_10</th>\n",
       "      <th>median_25</th>\n",
       "      <th>ave_roll_std_100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.473070</td>\n",
       "      <td>0.578964</td>\n",
       "      <td>0.143651</td>\n",
       "      <td>0.199808</td>\n",
       "      <td>0.529071</td>\n",
       "      <td>0.512646</td>\n",
       "      <td>0.380333</td>\n",
       "      <td>-0.171774</td>\n",
       "      <td>-0.235943</td>\n",
       "      <td>-0.515151</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.696964</td>\n",
       "      <td>0.444237</td>\n",
       "      <td>-0.241210</td>\n",
       "      <td>-0.243171</td>\n",
       "      <td>1.014980</td>\n",
       "      <td>-0.850613</td>\n",
       "      <td>-0.220017</td>\n",
       "      <td>-0.190820</td>\n",
       "      <td>0.400246</td>\n",
       "      <td>-0.182965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.031385</td>\n",
       "      <td>0.103841</td>\n",
       "      <td>-0.056244</td>\n",
       "      <td>-0.247975</td>\n",
       "      <td>0.077580</td>\n",
       "      <td>0.323945</td>\n",
       "      <td>-0.326368</td>\n",
       "      <td>0.156542</td>\n",
       "      <td>0.121378</td>\n",
       "      <td>0.273865</td>\n",
       "      <td>...</td>\n",
       "      <td>0.317940</td>\n",
       "      <td>-0.465386</td>\n",
       "      <td>0.271509</td>\n",
       "      <td>0.263658</td>\n",
       "      <td>-0.258143</td>\n",
       "      <td>-0.275335</td>\n",
       "      <td>-0.065598</td>\n",
       "      <td>-0.068861</td>\n",
       "      <td>0.400246</td>\n",
       "      <td>-0.064598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.031155</td>\n",
       "      <td>0.125786</td>\n",
       "      <td>-0.056244</td>\n",
       "      <td>-0.157804</td>\n",
       "      <td>-0.231023</td>\n",
       "      <td>-0.018358</td>\n",
       "      <td>-0.174712</td>\n",
       "      <td>0.156542</td>\n",
       "      <td>0.253136</td>\n",
       "      <td>-0.330997</td>\n",
       "      <td>...</td>\n",
       "      <td>0.976964</td>\n",
       "      <td>-0.837817</td>\n",
       "      <td>1.150123</td>\n",
       "      <td>1.153133</td>\n",
       "      <td>-0.835552</td>\n",
       "      <td>0.427175</td>\n",
       "      <td>-0.027233</td>\n",
       "      <td>-0.072150</td>\n",
       "      <td>0.400246</td>\n",
       "      <td>-0.049649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.037652</td>\n",
       "      <td>-0.846167</td>\n",
       "      <td>-1.081584</td>\n",
       "      <td>-0.980918</td>\n",
       "      <td>-0.958864</td>\n",
       "      <td>-0.966187</td>\n",
       "      <td>1.199520</td>\n",
       "      <td>-0.954900</td>\n",
       "      <td>-0.883336</td>\n",
       "      <td>-1.176640</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.624776</td>\n",
       "      <td>0.620867</td>\n",
       "      <td>-0.800200</td>\n",
       "      <td>-0.792394</td>\n",
       "      <td>0.810318</td>\n",
       "      <td>-0.377557</td>\n",
       "      <td>-0.534459</td>\n",
       "      <td>-0.545865</td>\n",
       "      <td>2.446511</td>\n",
       "      <td>-0.517331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.368337</td>\n",
       "      <td>-0.378088</td>\n",
       "      <td>-0.308461</td>\n",
       "      <td>-0.247975</td>\n",
       "      <td>-0.630210</td>\n",
       "      <td>-0.580274</td>\n",
       "      <td>-0.008592</td>\n",
       "      <td>-0.003294</td>\n",
       "      <td>0.053253</td>\n",
       "      <td>-0.095551</td>\n",
       "      <td>...</td>\n",
       "      <td>0.349010</td>\n",
       "      <td>-0.615400</td>\n",
       "      <td>0.547272</td>\n",
       "      <td>0.540320</td>\n",
       "      <td>-0.019989</td>\n",
       "      <td>0.495314</td>\n",
       "      <td>-0.153716</td>\n",
       "      <td>-0.166164</td>\n",
       "      <td>0.400246</td>\n",
       "      <td>-0.150474</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   q05_roll_std_100  q01_roll_std_100  q05_roll_std_10  q01_roll_std_10  \\\n",
       "0          0.473070          0.578964         0.143651         0.199808   \n",
       "1          0.031385          0.103841        -0.056244        -0.247975   \n",
       "2          0.031155          0.125786        -0.056244        -0.157804   \n",
       "3         -1.037652         -0.846167        -1.081584        -0.980918   \n",
       "4         -0.368337         -0.378088        -0.308461        -0.247975   \n",
       "\n",
       "   q05_roll_std_1000  q01_roll_std_1000   q01_log   q99_log  \\\n",
       "0           0.529071           0.512646  0.380333 -0.171774   \n",
       "1           0.077580           0.323945 -0.326368  0.156542   \n",
       "2          -0.231023          -0.018358 -0.174712  0.156542   \n",
       "3          -0.958864          -0.966187  1.199520 -0.954900   \n",
       "4          -0.630210          -0.580274 -0.008592 -0.003294   \n",
       "\n",
       "   q99_roll_mean_10_log  min_roll_std_1000  ...  max_roll_std_10_log  \\\n",
       "0             -0.235943          -0.515151  ...            -0.696964   \n",
       "1              0.121378           0.273865  ...             0.317940   \n",
       "2              0.253136          -0.330997  ...             0.976964   \n",
       "3             -0.883336          -1.176640  ...            -0.624776   \n",
       "4              0.053253          -0.095551  ...             0.349010   \n",
       "\n",
       "   time_per_max_range  max_dist_from_mean  acc_max_log  chg_acc_min_log  \\\n",
       "0            0.444237           -0.241210    -0.243171         1.014980   \n",
       "1           -0.465386            0.271509     0.263658        -0.258143   \n",
       "2           -0.837817            1.150123     1.153133        -0.835552   \n",
       "3            0.620867           -0.800200    -0.792394         0.810318   \n",
       "4           -0.615400            0.547272     0.540320        -0.019989   \n",
       "\n",
       "   chg_acc_max_log  ave_roll_std_1000  ave_roll_std_10  median_25  \\\n",
       "0        -0.850613          -0.220017        -0.190820   0.400246   \n",
       "1        -0.275335          -0.065598        -0.068861   0.400246   \n",
       "2         0.427175          -0.027233        -0.072150   0.400246   \n",
       "3        -0.377557          -0.534459        -0.545865   2.446511   \n",
       "4         0.495314          -0.153716        -0.166164   0.400246   \n",
       "\n",
       "   ave_roll_std_100  \n",
       "0         -0.182965  \n",
       "1         -0.064598  \n",
       "2         -0.049649  \n",
       "3         -0.517331  \n",
       "4         -0.150474  \n",
       "\n",
       "[5 rows x 50 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_seg = test_df['segment_id']\n",
    "x_test = test_df.drop(['segment_id'],axis=1)\n",
    "x_test.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total predicted segments  2624\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seg_id</th>\n",
       "      <th>time_to_failure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>seg_00030f</td>\n",
       "      <td>3.111684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>seg_0012b5</td>\n",
       "      <td>5.850538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>seg_00184e</td>\n",
       "      <td>6.642270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>seg_003339</td>\n",
       "      <td>9.267204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>seg_0042cc</td>\n",
       "      <td>8.048579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>seg_004314</td>\n",
       "      <td>2.436992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>seg_004cd2</td>\n",
       "      <td>8.953513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>seg_004ee5</td>\n",
       "      <td>5.676419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>seg_004f1f</td>\n",
       "      <td>5.461224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>seg_00648a</td>\n",
       "      <td>3.137615</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       seg_id  time_to_failure\n",
       "0  seg_00030f         3.111684\n",
       "1  seg_0012b5         5.850538\n",
       "2  seg_00184e         6.642270\n",
       "3  seg_003339         9.267204\n",
       "4  seg_0042cc         8.048579\n",
       "5  seg_004314         2.436992\n",
       "6  seg_004cd2         8.953513\n",
       "7  seg_004ee5         5.676419\n",
       "8  seg_004f1f         5.461224\n",
       "9  seg_00648a         3.137615"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data_dict = {'seg_id': x_test_seg.values,'time_to_failure': y_test_pred}\n",
    "out_df = pd.DataFrame(data_dict)\n",
    "print('Total predicted segments ',out_df.shape[0])\n",
    "out_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_df.to_csv('lgbm_results.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
