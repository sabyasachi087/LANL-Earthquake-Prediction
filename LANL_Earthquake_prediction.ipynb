{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><font size=5><a href=\"https://www.kaggle.com/c/LANL-Earthquake-Prediction\">LANL Earthquake Prediction</a> <u>(A Kaggle Competition)</u></font></b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><font size=\"4\">About</font></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accoustic data (Sound wave) and its variation with time to impact has been provided. I found certain inconsistency as the data provided has more than one set of experiment (17 to be precise). For each set of experiment the accoustic data and time_to_failure is given and the time will keep on decreasing till the impact. For training only one csv file was provided which requires certain pre processing to split them into experiment (or segment as per the LANL). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><font size=\"4\">Training Data Preparation</font></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test data are given as a csv files. Each file belongs to a particular segment of an experiment and we need to find the time_to_failure, which is nothing but the time remaining till the earthquake hits. This is not aligned with what training data is. Currently a single csv file having multiple experiments (Without Demarcation) is provided. First we need to split the file into individual experiment chunks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are more than one ways to split the training data. I have used the following two :\n",
    "    1. Read the entire csv file in chunks and save them into individual csvs. This will end up in 4000+ files.\n",
    "    2. Read the entire csv file in chunks and comapre the rows till the time_to_failure starts increasing instead of decreasing. The increase of time suggests the impact has happened and the next row belongs to new experiment or segment. This will generate 17 files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My code to split data in the format prescribed in 2nd is slow and could have been <b>much</b> better but I am not going to change as it is just a tool to separate data and not the goal. \n",
    "Do not execute the following script as it will take 3 days to complete. Files are already generated and kept in data_train folder. We will call this experiment data as <b>DATA-II</b> and will be using this for actual training.\n",
    "\n",
    "<b>%load<b> <font color=\"green\">data_splitter.py</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The format prescribed in 1st is fast and will simply split the entire train file into chunks of 150000 rows. This does not consider if the entire segment belong to one experiment or multiple. This will not be used in actual training, however this will come very handy in evaluating model during my initial analysis. We will call this data as <b>DATA-I</b>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> <font size=\"4\">Exploratory Data Analysis <b>(EDA)</b></font> </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Preparation For Training Data</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With DATA-II, we cannot use this data directly for our training purpose as the formats are still not aligned with our test data. Individual files in DATA-II is large and requires to be in test format which only has segments of 150000 rows. We have used train_data_generator.py to split these experiments data into small files. \n",
    "\n",
    "The script loads individual file of DATA-II and randomly picks 150000 rows to generate a chunk. The idea is to do a sampling of the experimental data rather than using exact same copy. This will align our training set with test set. Again do not execute the script as the data is already genertaed and kept under train_data_new folder. We will call this data set as <b>DATA-III</b>\n",
    "\n",
    "<b>%load<b> <font color=\"green\">train_data_generator.py</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>What is going on</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far we have already executed multiple pre processing on the training data, so is it now ready? Well , no actually. The problem is we cannot go on and execute each step every time during our analysis process so we need to somewhow pre process and save the data into file and use that file for all modeling puprposes. So Let's create a class which will read DATA-III and test data and outputs a file that have sampling attributes. Let's dive into the following class code to for better understaning.\n",
    "\n",
    "Since I prefer eclipse for writing code, all classes or scripts found within the notebook is also be found in the file structure.\n",
    "<b>%load<b> <font color=\"green\">accoustic_sampler.py</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "class AccousticSampler:\n",
    "    \n",
    "    def __init__(self, path_data, data_type='train'):\n",
    "        self.path_data = path_data;\n",
    "        self.data_type = data_type;\n",
    "        self.train_data_record_list = []\n",
    "        self.train_modeled_data_filename = 'train_modeled_data_old.csv'\n",
    "        self.test_modeled_data_filename = 'test_modeled_data_old.csv'\n",
    "        self.train_data_columns = ['segment_id', 'acc_mean', 'acc_sd', 'acc_min', 'acc_max', 'chg_acc_min', 'chg_acc_max', 'time_to_failure']\n",
    "        self.test_data_columns = ['segment_id', 'acc_mean', 'acc_sd', 'acc_min', 'acc_max', 'chg_acc_min', 'chg_acc_max']\n",
    "    \n",
    "    def __readFiles(self):\n",
    "        import glob;\n",
    "        files = glob.glob(self.path_data + '/*.csv')   \n",
    "        print('Loading files for path', self.path_data)\n",
    "        for file in files: \n",
    "            print('Loading file', file)    \n",
    "            self.__load_data(file)\n",
    "        self.__saveData()\n",
    "        print('Loading files within path', self.path_data, 'completed successfully')\n",
    "    \n",
    "    def __load_data(self, filename):\n",
    "        seg_name = os.path.basename(filename)\n",
    "        seg_name = seg_name[0:-4]\n",
    "        df = pd.read_csv(filename)\n",
    "        df['acoustic_data'] = pd.to_numeric(df['acoustic_data'], errors='coerce')\n",
    "        df['time_to_failure'] = pd.to_numeric(df['time_to_failure'], errors='coerce')\n",
    "        df['change_in_data'] = df['acoustic_data'].diff()\n",
    "        df = df.dropna(axis=0);\n",
    "        # df['time_to_failure'] = df['time_to_failure'].apply(lambda x: x * 1000000)\n",
    "        if self.data_type == 'train':\n",
    "            self.__record_keeper_train(df, seg_name)\n",
    "        else:\n",
    "            self.__record_keeper_test(df, seg_name)\n",
    "    \n",
    "    def __record_keeper_train(self, sample_df, seg_name):\n",
    "        sample_stats = sample_df.describe()\n",
    "        record = {'segment_id':seg_name, 'acc_mean' : sample_stats['acoustic_data']['mean'], 'acc_sd' : sample_stats['acoustic_data']['std'], 'acc_min' : sample_stats['acoustic_data']['min'], \\\n",
    "                  'acc_max' : sample_stats['acoustic_data']['max'], 'chg_acc_min' : sample_stats['change_in_data']['min'], 'chg_acc_max' : sample_stats['change_in_data']['max'], \\\n",
    "                   'time_to_failure' : sample_stats['time_to_failure']['min']\\\n",
    "                   , 'median_25': sample_stats['acoustic_data']['25%'], 'median_50': sample_stats['acoustic_data']['50%'], 'median_70': sample_stats['acoustic_data']['75%']}\n",
    "        self.train_data_record_list.append(record) \n",
    "        if len(self.train_data_record_list) > 5000:\n",
    "            self.__saveData()\n",
    "    \n",
    "    def __record_keeper_test(self, sample_df, seg_name):\n",
    "        sample_stats = sample_df.describe()\n",
    "        record = {'segment_id':seg_name, 'acc_mean' : sample_stats['acoustic_data']['mean'], 'acc_sd' : sample_stats['acoustic_data']['std'], 'acc_min' : sample_stats['acoustic_data']['min'], \\\n",
    "                  'acc_max' : sample_stats['acoustic_data']['max'], 'chg_acc_min' : sample_stats['change_in_data']['min'], 'chg_acc_max' : sample_stats['change_in_data']['max']}\n",
    "        self.train_data_record_list.append(record) \n",
    "        if len(self.train_data_record_list) > 5000:\n",
    "            self.__saveData()\n",
    "    \n",
    "    def __saveData(self):\n",
    "        record_df = pd.DataFrame(self.train_data_record_list)\n",
    "        if self.data_type == 'train':\n",
    "            record_df.to_csv(self.train_modeled_data_filename, mode='a', index=False)\n",
    "        else:\n",
    "            record_df.to_csv(self.test_modeled_data_filename, mode='a', index=False)\n",
    "        self.train_data_record_list.clear()\n",
    "        print('Flushed intermediate records into file')\n",
    "        \n",
    "    def fit(self):\n",
    "        seg_file = None\n",
    "        if self.data_type == 'train':\n",
    "            seg_file = Path(self.train_modeled_data_filename)\n",
    "        else:\n",
    "            seg_file = Path(self.test_modeled_data_filename)\n",
    "        if seg_file.is_file():\n",
    "                print('Data file already exists ..Fitting completed')\n",
    "        else:\n",
    "            self.__readFiles();\n",
    "            print('Data fitting completed')\n",
    "    \n",
    "    def get(self):\n",
    "        seg_file = None\n",
    "        if self.data_type == 'train':\n",
    "            seg_file = Path(self.train_modeled_data_filename)\n",
    "            if seg_file.is_file():\n",
    "                return pd.read_csv(self.train_modeled_data_filename)\n",
    "            else:\n",
    "                raise ValueError('Execute fit before get .. ') \n",
    "        else:\n",
    "            seg_file = Path(self.test_modeled_data_filename)\n",
    "            if seg_file.is_file():\n",
    "                return pd.read_csv(self.test_modeled_data_filename)\n",
    "            else:\n",
    "                raise ValueError('Execute fit before get .. ') \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above class will read all the csv files for a given folder, find there statisticla values like mean , median , standard deviation etc. save each file as one record. Keep a note on the file name as the same name will be used as segment id within the training and test file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try this class on DATA-I reason being it is small and will help us to understand correlations and other aspects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data file already exists ..Fitting completed\n"
     ]
    }
   ],
   "source": [
    "import accoustic_sampler as acs\n",
    "import pandas as pd\n",
    "\n",
    "sampler = acs.AccousticSampler('D:/PYTHON_WORKSPACES/Kaggles/EarthquakePrediction/LANL_Earthquake/data/train_data_new')\n",
    "sampler.fit()\n",
    "data_df = sampler.get()\n",
    "\n",
    "import data_formatter as dtFrm\n",
    "# This formatter is available within the path and has all formatting techniques used earlier in the notebook. The doTransform parameter \n",
    "# controls weather or not we need to do any logarthmic transformation or not.\n",
    "\n",
    "formatter = dtFrm.LANLDataFormatter(data_df=data_df, data_type='train', doTransform=True, doScale=True)\n",
    "data_df = formatter.transform()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above correlation following attributes looks strong contender :\n",
    "median_70,median_25, chg_acc_min/max , acc_sd and acc_max.\n",
    "We can try some logarthmic transformation and see if this improves correlation or not. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "acc_max                  -0.362961\n",
       "acc_min                   0.382586\n",
       "acc_sd                   -0.498941\n",
       "chg_acc_max              -0.358661\n",
       "chg_acc_min               0.363229\n",
       "median_25                 0.350963\n",
       "median_70                -0.383129\n",
       "time_to_failure           1.000000\n",
       "time_per_max_range        0.366629\n",
       "distance                 -0.376633\n",
       "time_per_max_chg_range    0.371938\n",
       "Name: time_to_failure, dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_trf = pd.DataFrame(data_df);\n",
    "df_trf.corr()['time_to_failure']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the transformations correlations are much better and also suggests a logarthmic relation between the attributes and 'time_to_failure'. Let's first try logistic regression on the given data set and see how it performs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1f50eed6a20>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAELCAYAAADdriHjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzsvWmMpdl53/d7zrvfpfbqfXp6SA5DSLQp2W1ZMQMhFgxBlgUqhhVEQJyYtgQigR0ziQNDShBLFmAg/hDbAuRYoaMEkpzAMpTYoQVHEQ1JduREFHooUiKHM+Rwlt6qa7237vLu55x8eG/VVNdU9Vq3lq7zAwpdt+576z1Vt+t5zvk/m1hrcTgcDodjB3XSC3A4HA7H6cI5BofD4XA8hHMMDofD4XgI5xgcDofD8RDOMTgcDofjIZxjcDgcDsdDOMfgcDgcjodwjsHhcDgcD+Ecg8PhcDgewj/pBTwLS0tL9saNGye9DIfD4ThTvPbaaxvW2uXHXXcmHcONGze4devWSS/D4XA4zhQi8t6TXOekJIfD4XA8hHMMDofD4XgI5xgcDofD8RDOMTgcDofjIZxjcDgcDsdDOMfgcDgcjodwjgEwxlJpgzFump3D4XBMvY5BRN4FhoAGamvtzX3PC/AzwA8AKfBpa+2Xpr2uHfJKs9LPqLQh8BSX5xLiwDuu2zscDsep47gK3P6ktXbjkOf+NPDq5OOPA/9g8u/UMcby3uaY3rhEKcEYS6kNr17oopQcxxIcDofj1HEapKQfAn7RNvwOMCcil4/jxpU2rA0KIl8ReorIV6wNCiptjuP2DofDcSo5jhODBX5dRCzwP1prP7fv+avAnT2P706+tnIMa6PUmpVBjRIwFiLfnRQcDsf55jgcwyettfdF5ALwBRF5w1r7r/c8f5Al/kAUWEQ+A3wG4Pr160eyME8EQaiqCkTAWmI/xBPnHBwOx/ll6lKStfb+5N814J8C37XvkrvAS3seXwPuH/B9PmetvWmtvbm8/NjmgE+2NoF2rFgb5ry3MWJtmNOOFdb5BYfDcY6ZqmMQkbaIdHc+B74P+Oq+yz4P/MfS8N3AtrX2WGQkqy1vrozYzmq0he2s5s2VEVa7tFWHw3F+mbaUdBH4p01GKj7wv1lrf01E/hMAa+3PAf+CJlX1LZp01b845TXtktea9WFBXplG0LI0j2tNGLqUVYfDcT6ZqmOw1r4NfOKAr//cns8t8JenuY7DMMYyymuUZ/FEoTGMcusK3RwOx7nmTA7qOSoCTxF6wtsbI6wVRCwfWuoSeKchi9fhcDhOhnPtGABqo8lKjUUQLLXRJ70kh8PhOFHOtWMoak0/rXlproUfeNRV87ioNW2Ck16ew+FwnAjn2jFYYCYOiEMPEcFGPnmpP1hE4XA4HOeIcy2md6OAV5Y7+EqIfMFXwivLHbqROy04HI7zy7l2DGHo8X0fv8Tl+Zh2HHB5Pub7Pn7Jpao6HI5zzbmWkgDiwOPqTItxXdP2fddy2+FwnHvO9Ymhrg1fvbdNO/a5vtChHft89d42de26qzocjvPLuXYMpTFoY4nD5uAUhz7aWErjHIPD4Ti/nGvHECqFp4S8rAHIyxpPCaE6178Wh8NxzjnXFtD3FR+/OkteGzZHBXlt+PjVWXz/XP9aHA7HOefcB5/nWiHf/coipTGESjmn4HA4zj3n3jFAc3Lwz/fhyeFwOHZx1tDhcDgcD+Ecg8PhcDge4lgcg4h4IvJ7IvKrBzz3aRFZF5EvTz5+7DjW5HA4HI6DOa4Yw2eBrwMzhzz/y9bav3JMa3E4HA7HI5j6iUFErgF/Bvifpn0vh8PhcDw/xyEl/T3grwOPKif+cyLy+yLyKyLy0jGsyeFwOByHMFXHICI/CKxZa197xGX/HLhhrf3DwL8EfuGQ7/UZEbklIrfW19ensFqHw+FwwPRPDJ8EPiUi7wL/GPheEflHey+w1m5aa4vJw38I/NGDvpG19nPW2pvW2pvLy8vTXLPD4XCca6bqGKy1P2GtvWatvQH8CPAb1to/v/caEbm85+GnaILUDofD4TghTqTyWUR+Grhlrf088FdF5FNADWwBnz6JNZ0VjLFoa/FEUEpOejkOh+MFRKw9exOOb968aW/dunXSyzh28krzYDvHWIsS4dJs7AYLORyOJ0ZEXrPW3nzcda7y+YxgjOXBdk7gCe3IJ/CkcRLm7Dl2h8NxunGO4YygrcVYi+81b5nvKYxtZCWHw+E4SpxjOCN4IigRat2Ug9TaoETwxMUZHA7H0eIcwxlBqSamUGnLuKiptOXSbOwC0A6H48hx8xjOEHHgcX2h5bKSHA7HVHGO4YyhlKBwDsHhcEwPJyU5HA6H4yGcY3A4HA7HQzjH4HA4HI6HcI7B4TglGGOptHFFi44TxwWfHY5TgGt34jhNuBODw3HCuHYnjtOGcwyOqXDSsshJ3/9pcO1OHKcNJyU5jpyTlkVO+v5Py952J76nXLsTx4njTgyOI+WkZZGTvv+z4NqdOE4b7sTgOFLel0WaHbrvKYq6Rlt7LBXbJ33/Z8W1O3GcJo7lxCAinoj8noj86gHPRSLyyyLyloh8UURuHMeaHNPhpLvAnvT9nwelhMBTzik4TpzjkpI+y+GznH8U6FlrPwL8XeBvH9OaHFPgpGWRk76/w/EiMHUpSUSuAX8G+FvAf3nAJT8E/NTk818BflZExJ7FmaMO4ORlkZO+v8Nx1jmOE8PfA/46YA55/ipwB8BaWwPbwOIxrMsxRU5aFjnp+zscZ5mpOgYR+UFgzVr72qMuO+BrHzgtiMhnROSWiNxaX18/sjXu5SzlvjscDse0mPaJ4ZPAp0TkXeAfA98rIv9o3zV3gZcARMQHZoGt/d/IWvs5a+1Na+3N5eXlI19oXmlub6Xc2Uq5vZWSV/rI7+FwOBxngak6BmvtT1hrr1lrbwA/AvyGtfbP77vs88BfmHz+w5NrjnXLfhZz3x0Oh2NanEiBm4j8tIh8avLw54FFEXmLJjj948e9nuNuSeAkK4fDcZo5tgI3a+1vAb81+fxv7Pl6Dvz7x7WOgzjOlgRnrV2Dw+E4f7iWGBxf7ruTrBwOx1nAtcSYcBy572e1XcNJYox19QgOxzHjHMMelJKpGmjXRfPpcLKbw3EyOCnpGHHtGp4cJ7s5HCeHOzEcIU8ie7h2DU+Gk90cjpPDOYYj4mlkj2lLVi8CTnZzOE4OJyUdAU72OHqc7OZwnBzuxHAEHLXs4TJxGpzs5nCcDM4xHAFHKXu4TJyHcbKbw3H8OCnpCDgq2cNJUg6H4zTgTgxHxFHIHmc9E8dJYA7Hi4FzDEfI88oeZzkTx0lgDseLg5OSThFnNRPHSWAOx4uFOzHs40nlkGnJJmcxE+csSmBO9nI4Dsc5hj08qRwybdnkrGXinIQE9jyG3cleDsejcVLShCeVQ5xs8kGOWwJ7njGs7v1zOB7PVB2DiMQi8rsi8hUR+ZqI/M0Drvm0iKyLyJcnHz82zTUdhraW2hiA3WluB01xO+5pb2eFHQnspYUW1xdaU9uBP69hd++fw/F4pi0lFcD3WmtHIhIAvy0i/5e19nf2XffL1tq/MuW1PJKqNjzYzvFECAPFfBKglPqAHHKWM4emzXFIYM8bz3Dvn8PxeKZ6YrANo8nDYPJx6rZmxljWhgWXZ2MCX1FUmvvbORe60QfkkLOaOfSisNewA09t2E/r++fmgDtOE1MPPouIB7wGfAT4+9baLx5w2Z8Tke8BvgH8F9baOwd8n88AnwG4fv36ka5xZxfaiQNaoY+2lqLUBP7BfvMsZg69KOwY9gfbOUVd7waPn+Y9OG3vnwuGO04bUw8+W2u1tfY7gGvAd4nIx/dd8s+BG9baPwz8S+AXDvk+n7PW3rTW3lxeXj7SNe7dhSolCOB5H5SR9qKUEHjqxI3KeeQo4hmn5f1zwXDHaeTYspKstX3gt4Dv3/f1TWttMXn4D4E/elxr2uG0yguOwzkthv15ccFwx2lk2llJyyIyN/k8Af4U8Ma+ay7vefgp4OvTXNNhHFdWjcOxl+eNmTgc02DaMYbLwC9M4gwK+CfW2l8VkZ8GbllrPw/8VRH5FFADW8Cnp7ymQzlrhWWOs89RxEwcjqNG7Bk8st68edPeunXrpJdxKnCtHV4M3PvoOA5E5DVr7c3HXedaYjyC0/7H6rJZXhzcadVxmnCO4RBOu9Hdm83iex61bgr0ri+0TqUTczgcZwfXK+kAjjuF8FmKm1w2y8ngCtEc54HHnhhE5A94RLXypP7gheJRbRcwHKm89KwnE9fa4fg57adIh+OoeBIp6Qcn//7lyb+/NPn3PwTSI1/RKeAwo1vVhnvD4sgMw/PIQS6b5Xhx0p3jPPFYx2CtfQ9ARD5prf3knqd+XET+DfDT01rcSXGQ0b3QjVgbFkdqGJ63Idxpa+3wInMWhxE5HM/K0wSf2yLy71hrfxtARP4E0J7Osk6eOPC4NpdQGkOoFFY4csNwFHKQy2Y5Hpx05zhPPI1j+FHgfxaR2cnjPvCXjn5Jp4P9evKFbnTkhsHJQWcH9145zhNP7Bista8BnxCRGZrCuO3pLetkOUhPXhsWu3LSURoGJwedHdx75TgvPHG6qoh8duIUhsB/LyJfEpHvm97STo7DUkEDX3FtLuHSbMy1ueTIMlJelIZw5wH3XjnOA09Tx/CXrLUD4PuAC8BfBP67qazqhDmssVlVG+72Mx5s59ztZ081a9jhcDjOCk/jGHa2SD8A/C/W2q/s+doLxf423GVtmG8FPBh8sOitrg1FpSkq7YqeHA7HC8HTBJ9fE5FfB14BfkJEuoCZzrJOnh09eVzWrA8LVgc5q4OC64stfK+RlwZ5wZurA7bGFQAXZiJeXmy7oieHw3GmeZoTw48CPw78MWttCoQ0chIAIvLtR7y2U8HmqCTyFd04mJwSMoy1lJVmfVgwyCu6sU839umNS1b6mTs5OByOM80TOwZrrbHWfmkyiW1n8trv77nklw556Zliby+cvUFopYTLcwllbRlmFYU2zCcBnlL4ntq9ptLm1PYrcn1+HA7Hk3CU3VU/EG8QkRj410A0udevWGt/ct81EfCLNCM9N4H/wFr77hGu64l5XO2Cr4Rr8wlX5hI8EW73UtJhvhukNsYSPGZW9Enh+vw4HI4n5Si7qx60DS2A77XWfgL4DuD7ReS7913zo0DPWvsR4O8Cf/sI1/TEHNRRdad2Ye8s6MtzCVHg4fuKK3MJc0nIMK8Z5jXz7ZDLc8mpS2V0A+cdDsfTMNV5DLYZDzeaPAwmH/ut0Q8BPzX5/FeAnxURscc8Wu6wXjiBrw4taooDj1cvdrmx1HQGOa357a7Pj8PheBqO8sRQHvRFEfFE5MvAGvAFa+0X911yFbgDYK2tgW1g8QjX9UR4IgiQlTXG2IdaXjyqqEkpIQo8osA7lU4B3MB5h8PxdDxN5fOf3dMnCRGZE5F/b+extXa/RLTzdW2t/Q7gGvBdIvLx/d/6oJcdcP/PiMgtEbm1vr7+pMt+YkptKGvDna2Mt9ZGjIr6hemFs78uo9L2hfnZHA7H0fM0J4af3NsfaZKd9JOPuP4hJtf/FvD9+566C7wEICI+MAtsHfD6z1lrb1prby4vLz/Fsh/PjgbfiX0+crHD9YWEwFOE3osz4G6nLuOlhRbXF1ou8OxwOA7laSzfQdc+MkYhIssiMjf5PAH+FPDGvss+D/yFyec/DPzGycUXFEqEOPR3vz5Nnid99Fleu18Sc+mrDofjIJ4m+HxLRP4O8PdppJ7/DHjtMa+5DPyCiHg0juWfWGt/VUR+Grhlrf088PPAL4nIWzQnhR952h/ieTmJXvtPkz66U1OxE+84itTT05C+uv/ncjgcpwN50s25iLSB/5Zm1w/w68DfstaOp7S2Q7l586a9devWkX7P4zSUxlhub6WTtt6NI6q0PXAa3EG1Fe9Pknv0a4/i/tPiNDgmh+O8ISKvWWtvPu66p5nHMKZpifFCcpy99p80ffSguRD3tzMAkjB45GuP4v7Tws1PdjhON0+TlfSFnXjB5PG8iPzf01nWyXBcvfafNH30oLkQYgHLc6WennT66mHzLk5rKxGH47zxNMHnpZ0+SQDW2h7NXIZzwVEGap80ffQgA+55TcX186SennT66kk7JofD8WieJvhsROS6tfY2gIjc4OA2GGeS/YHQvY/LidRxlHr4k0hXh80ZjgOP64H3XLLXSY6pdPOTHY7TzdM4hv8G+G0R+VeTx98DfObol3T87A+EzrUC+mmFmUgblTZ0Iv/I9XClBIXsnkYOMtD7DfjOejxpZK+juP9J4OYnOxynl6cJPv+aiNykcQZfBv5PIJvWwo6L/YHQstJ89d42Ly+2SHyfvKy5NyiYufDoYO+jThyPMnpPkp2zY8BftEyeo3BMLuXV4Th6ntgxiMiPAZ+laW3xZeC7gf8P+N7pLO140NaitcH3PIyxiBK0aQwvQDgxvEWtSUJ/Vw8X+/7Ofb/UNNcK2BqXu3URV+aSAw3402TnuEyeD/KiOUqH47TwNFLSZ4E/BvyOtfZPisjHgL85nWUdH1VtWBnkKIHQ95iLfTwlmEnmTFlpljoh1sK4qHcN/91+dqDUlJc1t97ZIgk8gkBhraWqDa9e7H7AgD9N2uhJp5ieNpyjdDimx9OI1Lm1NodmuI619g3g35rOso4HYyxrw4JL3QilhLLSPBgWfNvlGdJC89bqiNtbGUoJF2diXlpocW0uoZ9Wu7MNPIG1QYGSRuq51894Y3XAVlriKSHyPdaGBZX+4Hjsp8nOOY2ZPCfZUsOlvDoc0+NpTgx3J3UM/wz4goj0gPvTWdbxoK0lq5ohO7VpDO1s4hP6Ct8TXlpIiHwPYxsHcn2hhebhnfuO1JSVNVtpBViS0CP0hM1RyXInPPT+T5Odc9oyeU5axjmJNiYOx3nhaYLPf3by6U+JyG/SdEH9tams6pgQCyv9nHFRE/qKcVFze8vgIWyOK64vtnYDpDuyzX6DZIzlQjeiNk1NQCvy+PBSh6w2FGXNuFJcmIkPzSB6muycnWt3Th/Pm5X0rJwGGee0OUqH40XimSa4WWv/1eOvOv1oa7HW4vsKbS3Doib2hVbks51V3NlKeWUynW0n4Kyxu/2KdgzSy0tt/InDiAKF6cL9fkruKy53E64+xmAelp1zUMbNNGoqnpbTEu9wKa8Ox3SY6mjPs0DoeyxEjVyktaGqDeOiQhvL/e2cShuuzCVcnIl3A847zewCXz1kkK4ttHaN9sWZhOVuRDv0H2pz/aRG7CCpJvTUI3fqz5O6+TSvPU0yzknWYjgcLyrn2jEEnuLCTERvXFLWmru9DG0MW2nJQjviylzC1bkYbaE3Liexh8Yg78Qc9s+AvjaXkNcaT+ShcZ97Db0AS/ucxl4Ok2ouz8aH7tTL6tlPEk8bL3AyjsPxYnOuHYNSwsuLjQz07taYhXaArzy284phXnFhNiIOfYZZhcHSippf12HSSV5p3tsYszYsALgwE/HyYnt3p+8p0LXlwSDnbi/j6nxyYI3DYVINcOBOXSzPrPk/a7wg9BSXZ2OAY2k86Hh2XBGg42k5144BJrv8hRZFrWlHPrHvcb+foa1pqo3LxiB76tHSiTGW+/2MflbSjZtfa29cEk4K3LKyZlTU3N/OCD1FNw7whAON8GFSTeCpA3fqVnhmzX9/gd+TvPbAE4ZyhWWnkZPOHnOcTaaa1iIiL4nIb4rI10XkayLy2QOu+XdFZFtEvjz5+BvTXNNBBJ4iCX2wYK1ltuVT1oZBVnFnK0NbS20so7w+tBuptpZaG0Sa4Tf+ZBe9k+e/OS7RxhD5Hp4S+lmJ8oSy1h+ocXhU99ODZjc/SY3DYTUHOwV+tzfH3OtnjPLqkfGCvSeMduQTeNIYHjce9NTh3ivHszLtE0MN/DVr7ZdEpAu8JiJfsNa+vu+6/8da+4NTXsuhKCVcnksYFRVvPBhS1RoQQt8QeEIr9PGVUNZNIPog6WTnmF7VhlJplDTB4J1rFzshg6wiLWsiX9EKfG5vpBjbOKbLeyQlYyyeEq7NJVjhAxLA/oDr4zT/vNKs9DMqbR66106B35XZmF5WUVaGle2cP3J9/lDJ4bRkJDkej3uvHM/KVB2DtXYFWJl8PhSRrwNXgf2O4cQJPUU7Cvgj1+ZYHRUIlvVxSRx4rA8Lrs4lWCZG+QCjWWqDNpZ8YlznWgEvLbS4OBPvXmOMZaEVsj4q6A0LblzscH2hja9kV1I6KB01CB5/sDssddMYy3ubY3rjcjdzqdSGVy90dw1HOw5IIh9jLFmlCfzD73eUGUlO+54upyl7zHG2OLYYw2R+w3cCXzzg6X9bRL5CU0n9X1lrv3Zc69php5VCFPn4WdU4hFFFpQ21aSqklagD/6jq2nC3lxL7io9e7FBoja4tFzoRq4Pm6P6gn6N27K21GBECeb+dQ1HXVBOn8KSB4L2Gdedn2G9kK21YGxR0Yx8lQqk1q9s5NxbbzWlmb7EeFl998GfcuY9YsMIH6jieJSNpWtq3czbv47LHHM/KsTgGEekA/zvwn1trB/ue/hLwsrV2JCI/QNNy49UDvsdnmMx/uH79+pGvcWd3ZSedVfOyJg4U726OsRaMgW+7MtM4EMNDMs3drZR3NsbktWa+FSICaaFZGeSEvmKxE2Ex9DNNWRs8JYSeoK1hfVhwsRvtSk9lrYmC91t8Z1VFXmti33voD3qvYa20AQuBrx6qedDW7urJRa3Zzhrnk5WavNJEgfdYw7Fzn6ys2RyXLHZCksA/sI7jSZlW5bQLtH4QVwToeBam7hhEJKBxCv+rtfb/2P/8Xkdhrf0XIvI/iMiStXZj33WfAz4HcPPmzSOPnu3dXfkevL46YmNQEgaKjyy3mW8HvL4y4NJsjK/UrvG9388QsWR1jS9NW42i0tTGstgJ6Y1L7m2nDEY1UajISs2o1OSlRhTMxgEzsc+FmZgHg5zVQcHmuOBCN0Ybw/3tHGssge/t3rPShpV+hu8JnhUebBd4Sri+2N6Vjva2y+jGHu9upASeTBoCRmyOS7px8EjDsWPAPQVppYl9xbjQdEL/wDqOJ2Ua2vdpaNNxWnFFgI6nZaqOQUQE+Hng69bav3PINZeAVWutFZHvosmU2pzmug5iJ+B7ZSamrDVX5mM6kU8r9MkrzRurAy52YpJJ0PZuL2WxFXKvl+EroaotXgCDvESAhU7E+qAgqw2VNqRVzeqwIvKEJArpdD0G4wprmlPK6nZOJ/a5OBPx+v0B31odMyorPrTUYVDUzCvZNfi1NtzZyohDhULYGJUstEPM5LSzNii4vpAQT+ZHBJ5irhUQ+orAVxOnY3cN8WGGY8eAB6LQxtIKfdKyRpRgavPMhnwa2vdROhsnRznOO9M+MXwS+I+APxCRL0++9l8D1wGstT8H/DDwn4pITTMR7kesPd7eyXslCGMsRW2IfZ8ygMpYNkcFw7zGE8VSt2JUaIZ5xb2tFBGIg4BW5JMWjVPQxrI5LCmNRiwoBXGgqHRTM1HWTeX0TOxzYTbC84T7/Zw4bNHLSi7NRNyuaxbDgHqSQrs5LklLzfX5hDBQbGcFw7wp0BNgc1Tw8lKLcVZRaY3vvx+/iH2PK3MJka8IJ47NWh5piI15X4YytnGaeVkjQFlp5DkM+TS076NyNk6Ocjimn5X02/Do7Zq19meBn53mOh7FB0Z71npXHurEHt9cHVHWhiRQLCYB31wbcbEb0Qo99MRwVsbSDhTfXMmYbYdEvqLQmq1hybXFFp4SqlrzYFAwKmtagUcSKBBhO60oOobVYU5e1dzpZczEPqujgsT3GGQ1WhviQGGA9XFJWtasDQusBQvMJgHjsuar97YZjisK3cQxbix18JXgeYrLk4BxVurHGuK9xrGoNFlpiX3F2rDYzby60I0otXnmwraj0L737+yf19mcpBzlTimO08S5r3yutHko4GssVNqijWEzzfGwfPRyl4szMf20YjzI0e2QpW5EP22yli52IjZT0BaKqgkEd6OAMtIYbYj8APHgymzC1jDnXq7RIlycjbFY/t+3N7k+H5NWjez03uaYUluGtiL0FbUBrQ1X5hNmY5+8MsSBhwUWWyEb45Ky0hgsSegTBopvPhiSV5pXljpcm28K4Z6khcVe41gb2M4qqsqwPBtxoRvRifzdU8fzGs3n0b4P29k/T1vyk8r7d6cUx2njXDuGncKv1UFBLy1Z6kbc76cEPnx0aYay0tzpZdyYbxNHPonnMUhLCq3ZHJeUlSGvat6uDSv9lHFRs9yNSUKPtKzxfMVsK6AV+tzrZyCGmSSkHVmMtgQC1liKusaKMJd4aBuhgNoY7vdzuonPYjskLSq2hgVlbbDAcjdmVFSsjXKshcVuxL1+jlSmaZNhLJujkutzhjtbKQj4ImhruTgT042DAw36jqMMlM/6sCCeNAL0lbA+LJlrhWjT7GyNffI4w1HuiB+1s3+etuQnkffvguaO08i5dQw7f5Chr7i+2OK9jTH/5hvr9LKSq7MtfE9xsRszm/hktd6tZai1ZZCX+F7NbBxggCuzEYEnjEtNLy1R0gzuudCNuDKb4ClhZTvHUx6t0KM2mnc3xsS1x7jUPOjnZEWN8hRZoVnohAyKGt8T8spwtz8mKzSVtixUNcZCZ1kh1lJoSxR4GGMwk7YcaanpFzUzsU+S+Kz0MtKyQkTopTW/f3ebb786wytLnYeMZl41MtrqoEAkB6ATBXhKSEKfQqe8szEi9JsTw3w7fKzRNMYyLmvWJ40Fj2JHfNjO/mnrQPZzEnn/rjrZcRo5t45h7x+kUk0r7GFRkXgeaal5d2PE1+706bZCFjsh80nAxqjgbj/n4myENob1YU5pLO2w+TVe6MZsjkuSoNH1I7+Re761Oeb25ghthAszMe3YY21QcG0+Ab8xlm+uDJltBfTSktq0uTqX8F42pqg09/oVsS+kpWFcaDZGOV+53eMjF7pUBuZbAWueIi1K8tIwzEsswo3FNnVluNPLeGd9hOfBcidmJg7YHBXEvsfLi+3diugH2znRxFHe76fc2cq4PNPMmTDG4iF4EyNpJ07IGPvIWMXc223oAAAgAElEQVRKP+NuLyP0hUuzyUNV3s9qcA/b2cOzNxOEw1uRTFP/d9XJjtPIuXUMe/8gjbHc3hqTloaljs/WuOBeL+XGUoeX5xI20or30hSroBV6DLOm42o/zfE9j964pLaWTqBIAo926NMW4eJsRFoatscl40Iz3w7YGBdsDQ3X5ltcmYt5/f6Q272U2IMLMwmXZhPWhzlz3YCiTlAI2+OmyM1XgrWWdticEEalRoyhjDxaviBK6CYBs+2QrVHJMCu578EgLfA9RRIo0knw+aKKqfT7UtCOo1SiEJrWHYNxTWUaKWq21aTSznci0qJmfVTwYJATeIpr862Hit12Gvat9DNEIAoUoafYGBVcmUueK9UVDt/Z71Ryl/WkV9VETnoSI3uQzh8Eaur6v6tOdpxGzq1j2PmDXOlnbIxy3tkYo0Sx0m+mtt3vZ1xbSthMS6DZidpamE8C7vRStsY525nm26/OIAJF1VQTX1+MSYvG2XxrfcxM4lFoy6XZBGMNYSCkuWW5EzDMK2bbPu2REPkem6OCawsJC+2QhTjCn/cY5RW+r1jr5dTWMpMExIFP5PuNwVNCf1QRekJWGG4sJvgIw7TiN9ZWudRNuDzfYq7dFN9ZY4j8cLe+YcdoetJ0gr29NWJzVLE+zJiLQ/7Q9Tl645LNUfN7sFh6aU1vXGLF8mByInh5oYXnKWYSn61RSW0M68OSl+aT3d28Npay0o/t3rp3d37Ybv2wrKa5VsBX723v7rw/fnX2A0V7B/WTOkiCujaXTF3/f1zDRIfjJDi3jmGHWhs2hgVJqBikFb2sZHU7Z1xq7qyndKOQNK9RntAKFd9aK0jLknGusZ6wNSopSkMSeUS+YrVf4ikYFjXjsmalL9ztpcy3QhTw8lILr5PQTRT/7PfuESlFP6tZbAsWgyBcmW/jKcWFmZCv3etzsRORVTWbo5KtYc71pQ7zScjKYMxmWhBahed3WRsWbOclc1HAoNBYK2yOCqJIcfOVBe5t5ryzMWJtVLDYjZhvh0ATcBYLeVnz1oMRtTHc62foWcvvfGuLV5fbbI1Lytrw+v1tagOvLLW5MpewMSrJy5og6FCWmt98Y4vLs/GkEV8zlOjSpKq70hZt4crcwTvi/bvzuVZAP60O3a3vz2oyxtJPKy51IzbGJbU1vH5/wB+6Nks3Dh4KTO+doneYzl9O4jbT0v8PO6W41FXHSXNuHcNO64i1Qcbd7Yy3HgxZG2bNztkYbix2GOYVtzdG9POaV5ZbfGs9Y5zVDPIKX4FvFNtpyTgvSWKfK7MtRrXGWsubKwO6sU9eaKLIQ2uNFsXWuOLSrM9ba2Oy0lBiuDqX0B9VBL7lwxc6fPuVWbbTknv9lCT0yCrNhZmYbhTQy0qM0by3OWSQ1/TSGk9Zwr7PbOLTG5Ws9wuuLLS4ttBo+v1RxXBUYYGbNxa4sdgmDjxWBzlb4+YkUBvD6iDnwmzMINdcNJaitkDFm2tDfE/x0nyLJPC4tz3GU02JelUZmGRXbUxOV61JzKVUhqI2lNpwcSY+cJzp3gZ9e3fneVXz5Ts9Xlls0478J9qt7wwd6uc1ceChreL2xpgv3TZcX2hRa0sn9qkNu7GPq/MJl2biRoKqNKLe75cVKjU1/f+wU8pOg0KXuuo4Sc6tY6i04U4vZZSXfP3eAH+Stz8qS1INLy8KC7MxZWmoq5r3NlI2RzkXu0kTrBaP0PcojWVrVKEHOWlR045CrG3aeM/ETQuJQDzSqqYbKYpa8876aGJshLVhjh2XXOz4fGipzWI74K21IRvDgjhUtMKAXppxaSbi5cUOm6Ocu73RZNCPohs3mU3DtOJDSy2MtqyMStqhRzcOqLSh2/KYa/l4gcdsKyQMPHxPsbaZcm0uxvMVVWnopRVx2GQ7deOQN1a3aXk+SMVHL3VRIrRinyUdszEqyQpNL62YawWMi4q8rHfjIIHvoRAuzzbjTT0R7B57upOttDEssJPHlTEkYbS7k36wnU/qL5r5ETu7dQwHyk1im69nZUU3ClkdFMShRxJ6WNvMnujEe9NwDZ7QVKEnPq/fHzSpuKqRoHz/4Il5R7GLP+iUklUV97czAiUoAeH5a0Ucjmfh3DoGYyz9cUWghCgQeqOacakJRBF6wsp2RlY0geggCCCtGBU122mJ7/vMhRAooZSarbRgqROxPqrACsNSI9Zwp58xF4VoDL5qprq1Qp87Wxmbw4Isr5kJfXp5zea45vWVIdtZhTVNCmor9mmHHmWlGWQ1rSjAF0UchLTDik4csDrMURi2s5LNUUUS+VxVgtaWlX6GB2ggrZuAcFU3HV3nY59xUfLOVvO9LU2Vczfx6WcZd7dSZmOfl5ba9McV/aykE/tEgWJrWLAxLllqx7y0mNBPK3799TV8BR9a7jAuNbaoEJrAtDaWO9spYsGb9G3aGpfc62UEXjMkKfCEB5s5rcBjY1yigCRsTlr3+ylX5hIESIumy6s1Fis0QfK83q3SHpcVK9sFDyRHiXBtvkk9TkIfKMjK5lomGVZh4JHmNVujkpcXW7tB635aMfOYJoNP8n/ssNcdlI2EbXpt3evnuw7qpYWEqzZxqauOY+XcOgalhPlWyKAo6ac120VN6AnDvMSIYlyAsYZBobkQ+QzSGmsNhbWIqVkpCjpFwCCvmGlFXJpLWB+VbKUlsS9YGiM2yGqMtix0QrJak9ea2djDmoBxXrAyzKi0IJFQlB53eiPaUYhXaBgWDMqahVZAFAgXuwFvjAtCD1BNp9MmMmHItWFtmNMOPV693GU2ChFPkRUVnTikqA2zic/GqCDyhY2B8ObaiKKsWZpJWGqH+L5C14bAa+SgxZmY2Pf4yIUIYw2ep/jm6oi5dsTyTEzoC+9sjCiqxgDOJUEjT6UlF7oRl2dC0qrmjZUhSiD0PeZin6/eS7k8GzVylII7W2NeXmyz2A7JKs0orwmUECj4/bsD6lrzyoUOl2Zj7mylCKA8AWv5yp0+n7g2i68Ubz4YAnBxNmpiR6OyGY7UDam0YakTIiIUlcHaJiGg1obKGJQSQv99yWZcvB9LeJYK7cdlMx2UjXShG/GVu30SX5FEPmlR8a3VMR9bngGeLDDt4hOOo+DcOoYmzTLhdl8TeZY0LxnmGgRiDyLfIy0Msd9kKomx5AZaAWzmmk4cIL6a9DJSrA5yIt/j7nZOUWoWWhGF1uRG44nQDhNqY3l3Y0Tke2R5TW5A18JMpBDlEwUeG6OCxA/oFzm9UcGg0Hx4qd1USJea3qhkphNybTbhTm9EXhkUsNQKScKAOPQoSotKYLkT8m5esjrIWemlLM403WGHheViN+JCN+QbaxW3N1PWBhlJoHhgIAwUH77QYVxWvLs5Jg48PnShw7dd6TLIKoZFxeqgwiLc2Uy5upCwEAf4Cr5+f8CHL3YYBR4bXsHrD5qutEszMbU2rI0LtrMSEbi9lbLSz5qg/aDg1QsdPnZxBiXC2xsj3lwZoScnmTdWthkVFaHv44sQ+KqZjmdz1ocFVpjo9Yp24GPD5jQhNPfZMbyXZxMuzMSsD4vdtNvZ2Gc7r/FFaMfBobGEJzW6T1rNvP80kteaOGi6426lJUoaB/2NtQGdJHxszGG/M3qemRnHjXNop4tz6xiUEmZbAXffzlgflizOJMRhxfa4oJfVLHVjxmNNXWvSsp70JrIMreApaIew3i/IK01dZ3z9PkSTKWjtyMdgKbXm9maKpzzK0nJ5MWGQaeZiRejDg0FBVpYEfsRMDP2sJCtK7mwZhllJXtdcmGkz1wq53cvQ1nJ5rsX6MGeQV8y348bIbefMtyPaUYAouNtLCXxFrg1ZaVEepIVhY5gxFwdcv9BmWGiK2rLUCtHWsjbIEQlY7kZ4ori7laKUbU48ccDmsOAP7vR588GAVuRzoZtwtzdmbZRzeTZmWGhub464u5lhrcG/MounFNZaVkfNjIsg8LjfS1ndLrgybxhmFUqESls8gc1JIHwuCfjm6hALxL5Hf1zyYLtirh0xJ4rNQrPUDSnKGs9rag1CXyFKYawlDDx6oxJL0+Qw8BRX5hNCT+3OkUjmPd5cHRAoodAWjOXttTHXl1uEnvdQLOFR1dsHTdEz5smrmfeeRnyErLQgcG0+oagNK72M7aJieSbB2MNjDvud0Siv+NLt3kPzQ05rENv1ijp9nFvHUNeGt9ZG3FhocXU24d4gZ5DV5JUGa7nXywh9Dz8QYqswRtOOA/pZTVVbiiLFWsFYSGsww5yFdsil2QREuL01Jq8MtYFuAhrDvY2UxU5AaRpNu9SGMAjItaEelXgotG3aW2+nFQbwVPOHU9SaNK95rxqRG81sFPGJl2ZYH1fUWoMIpTWkmcb3hdBX9EYVg7winrTgHhWWODBsDgpqDVEgVIFiY7ugMpbZxGcuCfBFuL1ZIyjmOxEfvdRlbVDQG1dcW2ixnVbc2RrjK8vV2Yi0rBgNa97bzDDW0E8rtvOayqQUlWE7rXhrdYQxhusLbT683KaX1awOUl5Z6tAKfa4vtNkaF7y9OaLWTVvwyIe1UU6pm8ymstYUxuPO5pheWrAa+1yabbE5rpiJPRJfEfg+g6xkY1zwsUvNCSfwFWuDvKngto0hr3UTa5lJAiwwqhpnfEXHXJtr7RqmtKi510u5v50TB+qh6u29GUR7p+gJUNWG2n84m0lsk/Rw2K5YPOHGUsJX7pTklcFYuLKQYCevCzxFOWn9Ee3rars3mG2MpZdWeCIkk5/jOIPYT7P7d72iTifn1jGUxqCNZa4V0W5FpJNMobyyBL5gscy3Am5vjag0lBWooKnYjXwYFU3Rm1iYbYO10E8LMIYw9OhnBcoKrcBnKQnZLiGtSsJACDyPft7ELOaTCCuw2k9R0uwuo8AjDH1qq8kry2aaU9Wacalph3CvlzGIGoM/2wq5ttClqA3ro4xRVjAXR0SekAGjoqIohTj06YQ+46zm/lbOqCybwruZmMV2yLwXUBrN+ignLw39tKYdelxrtbCmSUf1QwWlJfYUY2rmWhHLMwnbacHdfkrLFy7PddgalXxrdcjybEQn9OkmIZ1Q8a21lLVRzr1+Slkb3t0YYQ28tNhmmBf00ooPLytCD7RpaiYawUqYiX22RgXfWB1Oso8Mse9R1JoPL7dYGZR4pjH4C62A9pJPWmru9XPSsiYKVHMC6yQUpebdzRH3+xnDvOkh5Ssh8tVE1sq5MpdQ1YYv3+1jrWU7q4iDiLVh4xCyouZOVRMFHpGnJicudqfolbpJ1S1qs1uTcbefPbQr3hm/umNAPREW2jEfu2yauRda840HIzYHJYoxBovQJDFcmUse2lXvDWZbmHQMbhogKpFj67/0tLt/1yvqdHJuHUOoFJ4S0qpiJvbxlSIOfUJPYRRUlWaQFhQl5HWT2bO5rfE9UB74PmgNSqAyUNeNcFHXFZWtCAWssrRjxdq4ZiHxKWvBWqE/LsEaxIAnzdhMbZtdclU3zfJiXzDWJ8sLlPLxEMZ5wdsbFRhLEnqMiopxWXN1IWZ7VLI9KprsJV/x9uqQb6wOGVaayBNmkhCxliBsptJpA3Nx0Mx0sJZBVrExqFGT3P0/8eoiG8OSWlve2xxhDBgMK72cQVaSVU2PqI8ttFieDfjW+pjLMwkWYbEr9NIC30TUtWV5LqAyhuWZgI1hyUwcMC5qLs4mrI+KplajNFxfSFgfl43EpATP9wgEEk9ohT6DcUlVWV5Z7iA0rTY2hjlFbRhkFa8stbHaNLGd0hIHijhQ9NOmRkMJZIXm3Y2UtKoY5hXbWUGloZsEtAOPu1sZeW1I84oHowIFLHZitrOK9zZTtDG8tzGmKGuMCC/NtwgDhdF2tx257ykCT3F1LgGaXfHKoOlDtbMrfmdjtOsQ9ko9V+YSRnnFmw+GrI9y5pOQ2XbTpwuET7w0R+irD+yq9waztW5OG/NJsOssjqP/0rPs/g/KzpLJ9zJyeB8ux3SZ9mjPl4BfBC4BBvictfZn9l0jwM8APwCkwKettV+a5roAfF/xkQsdfv2r93l3Y4Sxlk7oURlFVho8MawOKjTgKwgspBbEgFEw1xJ6Y4s2UNeQVc3QnAKIfaikCVSXVmNLQ8/CYsdnVNT4vuDXHmmtySpDb5w1A3CaWjFGqSEOoR1EBCGAYpRX9IvmJoHn8e7aiM1h2Wjtlaa2Qugpylrzu7d7WG3otmIudWO20oK1YU4SeMwojwdphrEgMzDOK4ZZTlraZvyn55HrGhHho5e6FKXhjdVtFjoh97YyfM/j8nyLcVazNsgQ1ezoh3lNpS1KNWm8rcBjeTamNpatcUkvLYk8RVpVKGl2lgvtmG7sEwc+ryy3WGhHZHnJrXd7KIGLMzELrZB7/TEbaYnvKa4tJszGASuDDIslDnzuTuZX3Nka0w59ytrysaszXO7GZGWN58H1+YQbC23e3hzTH5d86EIjYd3vZzzoj4h9QYU+X3xnE98X+nmCqSGrdFP8t53y9ZUBSjy+8+VZlGrmfVd1U3yYFoaXFhOUet8Qa9NUfudlzfqo5MZSG9+DsjZ87d6ASzMRSeQznwS7BjT0FN044BPXZtkYxoShR1bVLHRDQs8j8NWhu+q9wezLcwlrw4JxcXz9l55l978/O2tHkrvXz44s3uAC20/PtE8MNfDXrLVfEpEu8JqIfMFa+/qea/408Ork448D/2Dy71QxxtIbl8Shz/XFNnlRcn9QNmmSsU/g+xRlRaGbH0IUUEIgEChIwgixBXltyWqIg2ZQT11DocHUjUPxqYjDgNrU1Dok0yVtz6MTeVg0eVmQF02Q1BOoNFR1c4/Kq6FWVLUl0zXlxPnUtSYMIFKN4Xpnc4ixisS3jApLx/fIlI+pa1YGGcvtgI1xk9W0UqT4yoIobm9UKM9jkBV4nsd8O2KpY0jLmi+9u8WrF7sgINLsftPCkFcaYy0zLZ+VXs39rcapzcRNwH1jWJJ40E0iiqrZqZfakpY1i5O51INxyXZZE/iKDj6Br6g0LLZD/qCfUWlNEoVc7US8tzFmmJf0U81c7HO/lxOIh6+EtKrxBLbTirTWDDLNTFLTCn3evD9AX9RgFRuDgoVOzL3tlKo2aGvQusn4mW35dOKAxW7E1qgkLWrKzNINPTzPpxUpfvft3kRq8klCxe2NDKUEK011eFlbylrTCr3dCXkXuhF3tlL6WYm10Bs3WUYfutDhXj/DU8JMq/l99LKK2STYbWqoraWbhKyPS9aHTYKDtbDUifAmFdo7MuZ+doLZgae4HnhTN4h7je6zdordO2Dp3iRLbef1zxtvcIHtZ2Paoz1XgJXJ50MR+TpwFdjrGH4I+MXJnOffEZE5Ebk8ee3UaBrGpYzzmk7s4ymPqta0koAo9BlmBeMKxlVzvaLZzRsLnZaPUqA8n0RVWAtioZc3xyI1GbmZV1BbKKuKTIOSFN/zGKRNt9RL3RhfgaXkwbDEM1DUUNE4hzi0mFqzVhoiAd8DXUOum+8/8jVLcci4MlR1jSdNm28tikBZlPLQ2rI+zDHiTdI0MwZpRY1F1xAHgud5eMAgbQrLZiKfr9/vM8xryqpmJglZ3U5JggBPLLUVilozLGuWZyKGaUWuNevbGXllMbHP0oziQT/j/iDjQ8sdXllqCt16WdX8MoHVUUErUCy0QrpxI8PEgTDbivDFsr6dcr+X4nnCS0stQuWxlZasDlK+7eosi+2IrXGJ5wm/994Wm6OS3kjxsauzgGVrXLHYDhFpTlKr/ZoHgwIBfBkxkwRsjguCSf1CVWuS0Gd7kJNXlvE45/JsRGU0V+bbXJqPudPL6KUFYqE00PdLKqOZSyJi32OxHeJLUw/zzsaQpU5MHPlcFrizlTHfCjCmSRfeaVk+SitCJdzvZ40cM8i5NBMBUGuLiNCNm3jK2jBjO6tZ7kTc7WcPGbr9O+NH1V/srRZ/1hbjBxndZ60UV0pQk9J433t/XvnOKUJZeaYCQxfYfjaOLcYgIjeA7wS+uO+pq8CdPY/vTr72kGMQkc8AnwG4fv36c6/HGMvGKKefVQyzmjD0QTwqY+n1G5liLlFoY8gmhrgl4AVQ1ZbtrCAOIC9hXDSnCs37A659mpOD58GgAgzc26qIggpPQSvymGn7pGlNbSy+BeWD1I3dVKqJXYxKg1IQhT5VUSMeeKZ5XtcasLRCjxzFMC1Qnkc39lCeoigMpamIfEU7CSjLgv6oRAOzLR/lw6CqmQ0UxjbzKHJdsz0GUYqVfkZlLOvjisATFtohbd8DmgFB2mjeWhvy7vqIduTjKyg1rI9yZnYcVmXJKsNSJ2ZtmBIp4dUrLfK601RaRyGvLLX4xtqIO72Ud9dTZmKPOAoaecwXOnFAEviM8oqlVsCl2YTv+cgyW2nFV+5uszEsWB+UFMaixHBvM6UVeVxfTLg4E3NtocWX3umR1ZpAKeJQ8WCQc3874yNLbWZaMXd7I15fGdAom80JwFcw1w6YG4csJCHiCfe3MgZZSTvyiUOPYaFZ65dE/v/P3pv8WJamaV6/bzrTHexem3x2j4jMjKosFTV0p4BuNrDvf4EFa1iwZskfwIoFagmEkJDY0IhesGCDmgZ1N9CVVV2VlVkZmTH4ZG7jHc/4TSy+Y+4enhGRQ2dUhRR5pFCYm1+/dszs3vf93ud53udRDN7zLz++4tWm5dOrhk3r+M7JhH/nwZwi1xxPMx4fTpjkA94HXm5arvYDLkR6H5jkmqrQnISMp6sGgeCwMuOmNrzcJOff5SSjyvXnsi2+zCDwq8wKb40ZjyYZZaZ/qWnhu++fLyu6v+mm+BdNHLdTBPz6IU+/I7Z/8+tvpTEIIabA/wz85zHG7bt//QX/5BeG5BjjPwb+McAPfvCDLxiif5NLMskUz1YNWsJRpTmYZPykWdEOCYYwEjIJMZmF4gOvje2UVCA8uUoQ0O2N375sHemEHxJsSoiAhxzwQfJiXSOCAh9QBmJIZHaMifDWOm0hay2ZFIKIIsTIINLinSViHVR5UtUsJhP23cCmC9SD47jKOShzGut5salxLtLZBHENQ5Lldj3Mi4gLgeA9fQSh5evUuceHJS/WHQ+WJU3v+aNHSz673NM6x7p2rOqOVe3orKPQepyUHK2zTHKDzGC1a/nJmeDpqqUfPJ0NVFnCy2eF5m/OdkgtmGaKZaXxMRH381JzvpFc7nrW7UDXBbI8WVb8s48uOZzkzHLFT88HIgHvI2Wh2fWOPng+vqjZtQ4hJM9We6RQnB4YEIJZrlFaMikzXmwalBTcmRc0Q/pF3jSWk2nOxXZAacG//PQmbcb3nvuLisOJYdsl2OhknnNQGv76bMvVtk/7IdOcwQd+fLbm6c2eJ4dT3j+ZopVkOcn4y+cbXq07lBHj4qDjbJsSBWMEhWBepnzvymhe7XoKLRl8JFfqc9kWvfW82LTkSiKE+JxB4LvqpduCrgTUvafQksZ6qlzxVy82PFqUaCWwo3LryXLyWt309vVVRdco+RsV3nf5BjG+oX5TaOl3IUi/+fW1NwYhhCE1hf8xxvhPvuAhz4FHb/35IfDy674vKQWHE00zWHKTYKSA4HLfcL13GAVKRZROsI6M4ELaK4gIylyPeHUq6IZU1NuYoKDbGPo6pEahgYzUIISAWSZY1w4fA1pFtICoUlNITj4Jnso0HE1zHhwVnK976j5w9zRHK8XLmxpJpBkiSsK2sTw5KpGbnkWRkRuJ857VxhLHqWcI6b4CEaEEUkY2raNQEhcTyd4NgVkuWXWWT64cMQqUDPgAfW/JjMK3jnmpGGLGrE4qpcOJwo9wwPVu4GimaHqLUoIh1NS9Z9cObHrLUZXxYJEW/g6KjKZPVhjnu55JphBE9q1jcJ6TecHzVc2qGXiYlSwmBT95uWHdWqalHlU4AqNSETFK8mhZUmjFrvM4P3C1G+h8YN1olpOc3gU+vDsjkwJFCjn6/oM5n101xAjTQjK4wNmm5XRW8MFRxdXecjLLiTGw6Rz71nEwzclUEixs2oFtZ8lVgvSSd5NPhoJCsGkHPr7cUeWGh8sCISO5kux7nxrxuk2hR0ridZri6sGNarXA/cOKs3VHIBICDNbTW88nV3vOdz3T8TVZ5fq1QeCrTcf9eYEjkklJFLcpd2kZsMqS0SMxNfTPbhou9x2X2x7rAh/em/Pe8YQnoyPv7XVbdN91pP23LbpvE+ghRJ6tmvR6He/51znx/y4E6Te/vm5VkgD+W+DHMcb/6kse9k+B/0wI8T+RSOfN180vQHph51pzMs3Z9Y5/9bNLNo1l0/XkJp30WxuwDuYTOCgyNp1DjTnMvXO0fWoWNqZGMHLIhPE/Q4KXbj9X5amJDB6u9gNFoTkqNcEL9r2lsw5EakJCpeeNHjZtzwNf8g++c8KPXm6ICG6agXvLkrNtjxEQfKDzkefrZBR3OCtY1QOeQNtDZtK0oxUED0MPQkcOJxopInmm6TbJEkQKsDGx7rsQqDLBR+c1pTGUZsPxJGfVDHS9ZXCBLFf0wWFtCihalppZqSk0dE6w6yy7dgAhEQiUYlQPBbSWSAWfnjWAZ7W3PLeeSW44nBqkUpRG8r2TGa+yFFZ0vW24bgdudgP7ITArFJ3TdINDRMFykrOcGOajJcb5xjErM1zTc133rFvHQWXwIfBq17NqB0oteHJY8eioZNM6ut7TDgkOqXvP4dRwcpBzMsupe8fpPPlEVSbJjx8fV0y8Qgv45LLhYJKkoloKKq2YlIpd5/jhZys+vDdlojVn6xYj02ng/rLA+oiLka6z9M7z8VVPjHA6jywnBhHhqDLUncVHKLXgxRjHerMfaJ2j6zzvnUxfGwSeb1qeXtdEEhTz4Z0pwOtC3g0OJdMUtmosmXR0NqQsCgE2BK73PZmSr2NgIRXd21Cktx1pfxtF95YbaZwbpxtBZmSS30r5azWfd21H4KuXDH93pevrnhj+A+A/Bv5SCGAP8jcAACAASURBVPHn4+f+C+AxQIzxvwH+N5JU9Wckuep/8jXfE5AIt3uLgjKT/PTVDiEiPjjW+6QZNSZBPwPQDCBwTDKDDx5vPcEnOWqIcNOnKeHdy5J+wJ40NfQOiGnq8BEKo+kGT2HUa+O9wSeewY9qKKPhdFZiDHQ+8N5RxbNVj/c+hQIJiRKSbecYXMA7SzvArt8jBOy79DzRknITxuYVZZpcDirDi1XPlLQY1Q2J25AyolWS5xqjET6QK0HTe85Dz7bpsd4jhUIhmJQaIxWzqcZoxRACfYDKCPYttL0jyyTOCVBJ3pobyaYeWNc9N/uB66aDEJnkitOZIVcas0hwn3UJ7pJS8nyTQoOawaOFpBWRg9xgtKAfPErAzd7Re8Gm6bnZ9xyUKcr0zrxEiMg01zR94P3jguPK8OcvNvz4bEvTe75zOqVQisJYXq57mmjZXgwphS8Eqkxzf1GwnGRY7/nofIeWkifHU+re8tHFnlerBhsiZaGoCsWqtrTWs6l7/urFGucCyigmI0yz6SruH1QUWvLZpuNs3dFYx/1FwdOrmpN5SZUpBufZdI7KaD692ifoSwie3TSEkIKejBL80eNDBuf5+WXN42WJVIkz+ucfXfH9ezOslExy9Zpj8BHeP6p4tmrpXUAJyWFlXiuf3o6BhTehSE+OKiAFXt3UaUflNym4X5Tcd7HruXdQsGosvfW8HDx/7/Hy137+20bzO4XSr3593aqk/4sv5hDefkwE/tOv8z6+6Ep2AZpOW9ZNy6q2rPdJD2oj2D5NAVokTmBdB/ZdspIo9MgljI1hlkE/jIoklVRDkKCjyozkM4mrkCJNA1JA3Tn2vUNgycyb5iFjaiYxccsIAh9fNTxfdxAEQqSIzLYfGIJACNi0CYOKSYmKdVCaN7BUIDUjQSLRQ4qt5mo3MDGRzlp0hJ1LstkYUuPwAaLzRCFw0XPTDhRWM60MmcqxQ6TWkBlNrgTTzKA1FEons72NZdt5dq0jNqnRlU4RQ0CINDGcrVo6G6j7nk3rMFKx7z3/8HunKCdoh8AsS6qqp9cNLqbmcTwzrOq0uZwZjZaKe0dF4mlIDXheZlzvLYHAsjQUmSbXaUfDusi0UHx81fHh3RkPFiWfXjX89cs1EciM4niW0dnAVdeTaSiNxvnIxxd7pBBcNwNhTHprBsvFtuOPH6cltKt9zyeXNZ9c1hxNHZvWcrPvMRoyZTgQgn5w3JlXtINniJ4ffnaDVoLaOu7McqyPIBMMJaRh13jKXHK5a7ncdJSF4cW6RiGZ5ZrjacHTdcuHdxwROCg1eaY533ZUmcaFZDWPgPeWE753MiOKBFs+FYLepeK8kXaUKqfXiVHyc5YetxyDiIKrfY8Pkd4GTmY5s8L8wvvtq9RObxfsW+I8G6GuaWHSQmZMcmuj5S8891ddXxYE9TuF0ldf39rNZykF00Lxz/5mzcdXLYMLKA1xSBJTSSJpSzPuFpAKviTtKhQyncbFyCmMB3LykB4TSAUWUmMpq6Qmaob0f6NgOzgyBZlKDaZ1qRE5ATKhOhQazrY9SgmIgnbw9D6SyQRjBZcW427ZeEH64hrIRFq060be4nZ68TIVzYMq4csWSdsnniNT6d68T/cvZVJGhZD2GXo7EDNYaM2yzLiJA4+mEwaXyJS6tRxm5Wt83obIJBO0Q5pGcg3T3EAU7G2kv27YdRbrAq9u+nFK8njh+ac/fMa/+8ER3797wL1lyWKVMys0m9Zyueupu3Sy9RFypfFESqO4bhx3ZpJ5mXE6TfDPurZY5znfdkzykstNz4NlxSxT9IMlhMhPXm5prCfPDJmE802PkYpFqfjed44oC81hZfjRyx2bdqDMFL11XOws1/WGRWWIIXI8Tzsch2WBPBV89HLLpu7ZjFPdurVM8kjvLVpITqY56wbsqx2fXbfcW5bUneNSwM3o53Q8z3h62bDrHZNC03SOi2bgoZZsGk+uAy5I/uhxRTN4juY588xwVQ+0vcWHSBSRGFPSXjuS7I+PJhSjXPfWBqRznt1o6Z5rzdE0xcC+belxOkty2perBqMkRgqcTMl45bFCv1XAv+qk7lzg+U1DbiQiviHO7y0K/GhxolXaLFfq14OR3v66bwdBwe8USr/s+tY2hqZ3/Jvna2IUTHPFpUyKjkwlfX8knZqbPsFJgje7DA6SZTbpB3jLJ0hSMdUjaZyPk0UhoVSK1nvakFRKmYNcwbLS1L1LfkwOZvnIWYx+TDc7sASWZdqLkKSiPZkpzvceOUJTMaYGcPt2FMDN8PmGcQt3WZ8a2vnGISLkKtkQtC6dEKNInEQ77mX0t9/nPt2A9wNCQe/a0bMIPrpsUUSCkBSZIo7W2MJD7RyTwuCFZ5YLpIpkUiQ4RUvqzrKp066HIjUzZwUyg0Wh0Urw0fmOyXjyrXvHdd3T9h4pBd57JplhWhoutmnqWDcDV/XAWZHx3dMJJ5OMdTtQ5Yrvnk6oMoXzkT97uubZTcu0zLje9eRacv+wYpIl5Y/16bf8fN3x/fszBp+W3wKG48rw/1zV5DqZDTat5dm64brumGQZd0dF0LzUrGrLpNDctD11nwjxXSMJeDbNwHsnU5aTHC0FvbO8XLXUFx4tBXdDQT04TqYZQ4hMhSAQyZTgurbkBkoteXRUcVP3zArDPDNkmeIP7s35N8/XbOuBzKSgqJv9QIhwXScO43t3ZkgpKIziOydTHixLROT1LoQSgufr9nOn7YtdzyRX4+clPkSOJhlnmzEg6bB67T777kn9bN1yf1HiQ+TlpuXFuk0wmQ+jxDZgxrCpbvD46DBKcm9R/sq7Fu9+3cF5Xl13TDNNZtTvFEq/5PpWNoYQIp9c7bne93QupK1WIxDREMJA89YuQRxP47cy1FsyeURiiKSJIM8gU4JZpTidZFzWbrTs9ggJzvs0LZB+6AJoPax2jtank7oedxe6ITWYciSMrU+7El14c+ofRrO0ME4DcuwAt4jpu5xHeOtjR5o2zPj5zr/5mJiIdxNSQ8zG7w+SoikDWueZ9B7h0xd9dm3RCFwE5xzPrltmpaS1kVIrMi2QQVIMDi0k29oRnUcbzck8Y3CBfmzGUqepqR4cWmhermp+ftVQaM3JPGfw8PSqoTSKqtRURvNy3XCxaVh3BhUDbRQstcFHWNUdP37lee+oep309pOXOx4uC7oQuNpaHixKOpdOlJvdwB8+mBMRzIqM5VRzepDzatXjXMArSVUYNr1Pv3ujaAbH04saRhnwR+sWoyVnq5r37szZDx4pJXmMVMbgbGQIkZkBrTQuwtmmpx080yKjGULyCSIV27sHFU1vYQwvCiFtpd1fVIQQ+U454WI3oGSyIP+Pfu8UrdPH69ZyMs2Y5BIlU9BSlWnuHOQoUlLhg2VJlenP7ULcnuyNknTO432gzBJEpJWkGyybxvNwWaKF4GLfs+scp7McOU4OT44mvyBrdSHyfNUyWM9lPXB3lo+Z3p7r/UC5VG+S9azH33Ji42uw6R0vN+3rNMAv4wne/brZuHzY+4AN8RuvUPq7tvH4VjYG6wOvVh3remDTWCJQ9wEtoMoMzWCZZLyWNZ5vLFKmE71/57kcqajPSs3hNKdzASc1j48K7BD45GbHtvfY8TRejvLXWxx/MxZELd6c/LPxt+L8SASTmkLgTbGuhyRZdEAp3hR1QTrtRztaefD5qUHxZnqwb33+7e9Hk5qAHx8TeNOQbADXgfPJ6mFRSbohIJUmRoeSiot1hxA5mU4eUqs6FTUpYNV6apuw5BzHsHasm8R/qPF7HiMJOJ5EXm0HWh9ZlBlXdYd1cZxqArk0NMOADZHKpMI3uEAIgQfLdFrfd5anNw3r1tL0qdBUxnGxT7GnzRBQIjIrDCfTnKsQeLHp2DcWIeHObMa+S3sa53XH1GYclJp5qWltAAQnk4Iud7xcdWx6n7K+XeCjy5qruufOQcmdecm6TaFA0zwR9g+XJc9WLWWusD7lhN/se06nM7Y6Nb3cGHKdIMhMSWaZRsjI4cTw958s2fWeJ0cVWkhWbXo9+wifXO3ZNAPb1nLTDFjrUUqw7VKM609fDWRScFkPLErNvMqxPjDN9euT/WfXNWbE+l9tO+6JZCPSu2T6KGVqTq82LdZHvA/0PnC57Wms53CSMSs+b+R3tm7JtKAsNLIZ2PSOo2nG1Wj90VrHw+UEN0bQPlgUr5P1Prnac7UbUPJNGuDzVcN7h5PPQVfwxTsMZaZ5uCg/t+n9Tby+CST5t7IxhBA537Vc7weu6378nGdWGRZVTu/rcb8g4dS98+k05jzrOqYCxhtZqpZJleEDzDOVtp6t4+m6JTeKKYLaO7Y+FdxbSCrTUMr0HAeFpu4cdjTSKwz0IRHQwadflNGJnM4UNDZNFIRRQeWSmimKVFwjaQpQIkFTfvyzIEFDb1+R1HBu31qFSNLbUiS+RYx/f/tYSPdhdLLH3nVgdOJLOudxEdb7BDdFIrNcIRAMQSFEKlAuJMhu26efXyHSzdU2fX+ZTpvjrzYJAomx43o7oEQgSolEc7Gpk6wWKJQBMWCkIkRS0+8S0bppelxw3NSObnBkSjLNVAq/IXELB6VBypHr6S2rbsAIyV8/X/HxdY1SkuWu4O8/WnLlA79/d0auFX/6eMG/+viaq12kd45784xtZ+lcINcCozWZUin3WyX7cAl03tOHyLw03D0o+PS6wUfP5S4FH91fFNR9YNen7eTcKG5qm+AZF/HC89H5nu/fn9PZQCZh33seHVYIKfj0as8PP72h7QNSRZohcT6TTJFrTVUq+j7w5GjC03XHh0ZxubfMT9NUIEVKknt8WKZFReCz67QIKITgaGKIDkwhuHNQ0Nl04s+k4Lqx9NbxF8/X/ODJ4etdgpQlEXl8VGGkJNOKwQYyJbk7L5hkKu3IhMh+cOxay1/uB5BwXOXUQ7KCn5c5dW/58asd01EJcgtd3V5ftsPwbgP5bV2/rRP+N8XG41vZGCB53V/sBnpncS45lk6KjPdO57TWc1n3GCnY9o5pnrGc5kgR+enZlsEm3sDFNEVImV6Iznlm8yrZSneWznqM1PQ2YUD5aLM9+KRMyhUgU4yo9fF1o7kz0/Qujqe8NGkIPxbQLMFWhU1BO0MYlVAhkheJO3ARxJAmh9sYY0Eqevt3u8Jb1y3c5OLY9MYucMulmJGMtiMJL0KCuCQJ8kImdRbAtovMygRZkSuCCEwzzdqFMYTHEJWjtWkRy4xCFu3gsBRUpUmGcT6waTvqTtLaMMJmfpxqPFoIpqVBK6j7iBaOSWVSg/KRy13yb7rc90lpJdPEKARkvaNUkqgi235AIFhOc5bTnKc3Lc+vN9Sd4+SgSDJXIp9e7/nT95bcOygxSvLsukZIQZklWer13rFuLDFGBh8Z3BvIb1kVPFxKmj6wHyzTPG2Kn606vnc6Q4zRpJ3zPKoqfBwoswznAwrY9455rti5wHGVZJyXu55cK07mOcvKIKTgRy83rPcDf/5iM3JQgnkp2Q3J2XbbDrCXlJnizsERCli1yQqjHRyZUQzjKn82Ftsy12OxzRFCcLFLE/d+jLGNRIpMcj7uPDw+mjDYwMt18sq6NcnTSqJH7mJZGc42Ha31aCn54HRGpiTWBz46347ThcYYwZlt8BEWkwmD9WzatPhXZYrc/KINOfziDsPXVVi/7IQfwhjgRFJ1/Spf/5ti4/GtbAzbznK1H3h+0xBFZFFqJuPWaK4iOlPIWrBuHUWmOJhkvH9UctVYpmXGXg5IJBlwUCYYYpIZtr2j7nxa3vKBGJLXS5lL2i7gJNyfazadx6gkO7Xu9o1rGAZHEJArRWaSDfa+d7SDY1CpMM9LQ+9BakcQabOZAM7CfKaZKkntHPsY0kSSGxaFJgpoB4/wA9fuy382GujGj0uVGtneJZgnk4y5DKmphVHOKmS6t4E3MlE3Ng0hYbADtYNMeNqQ3qRhxK1vZbSSNIXkGcwKw+AF686hTVI0ZTp5RnV9aqoxpt2FMpd0NrJuAjEGHiwrvns65WcXa56vOvphnO5Gc0JFUnoNMtD3jn2ILEtDnhv63nK969NWdT2wad3ofuoo9cB8jEF1PvLXL7e01vHsumFWpZ2IWWaIlaB3A5dbl3iQXLNuBupu4GRecnow46AS5GrG4UTzcFHwv//1BWWhWO0tH96Z8+y6pRs88yLjyUnF//vxiut9z8vdwE09JKnuNOdskwwGT2c5R5XhsrHIXUdwkYt9zyxPNu+t86yuepohMPSBKlfkStC7wMtNk7iAkCa7l+vudSE9KHXiMyTs24FmcFzXyexv21paG7h7kCEFPDwsebHqmGRwUOYjhCOIMaYsa63Ix7yJl+uWfWsRSvAnDxfkmfp84fZwuR84nuUMPmJdYGM9DxcFy8Jw06aFyXyUMGspaQf7hcl2X2Uk+Nu4vuyEfzrLebZquNimk9jpLOfJ8eSXQkLfFBuPb11jcC7w0fmeO7OCzCT7h9V+YFllRAIv1h1d58iMQEbFrDJMM831buB823NvkVN3Eh8lzkdKI+msw0YxbkU7fvpqoMgkJ/OCwQV2I7Z9PMvIM82hSRvVmRR0OqBlZJorrq1jVhicd0gUTZ98hTIlqTKJFrCYZHTO03ZwWVsUibAtMnDWY5WkMJpFIelD+rd3xsWp822Ld5Fma+nj5wlpQeIuCpVgJD1CUv34d0qOaqwI+Qj7pKNwKuZCQtuOsFN4w0dMBFzVUGVwZ5FzXXvq0cso+jey3mYkRE4rQx88ZxtPoeGgNOwFWAvTQhCylIHR+YCJka5J4Uc2BCZG01nHRxc7rtYDRkM7JLXVrXhAAvPy7TdnxBOxzlFbz7ZzXO+7dLJVElRksJbLGqQSiFglyXLwbFtLpiWDjcxLRe8Mp4uCeZFRqh2tSzYUmQKpBdf1QLXqqHINwlIVFUjJcpqxbSytdXROMisUzgWu9j1X+5bzbc9hmbEoDdum53zXMzjP4AXlrnvNJcSYSO19aznbtByUhnZwSUEX02ssLdIIuuiZIPnRyy29jZzOMv7g4QFPjqvXhanuk7rr1aZPNhm7njuzjF0fyLRiv+tZKclHr/Zs2gStIeBmv0eNr9l95xBvhRFBsgp5te2QJKuP94+nmDyVottTtoyJ2J8UghjSzs/DwwqtFUeVoBkc9+fp+T67rrE+fmGy3W/j+qJc79tG9kUn/KYb+Oxqz6q1zIr0fa3bAbOWvPfW9vgXXd8UG49vXWMYQqBzjigimzptVOpRohhCMkib5Jp9a3mxThbNeaY5W9dIBfcOJnxq9+yapGaJAtatY3ADi1nOetcnb3opqTLDJIucziVtb1lOc1wU7FvHg0XG3XnO1a7j48sGfCrih1XOEDRNZxEkq4TlpODVqk3Th7kNaoFcW+a5RkmNMZGbxmOdI6LIDcyyjEfLgjLL2DU9Poo0AVWO8zq+/plk4/+VAm0Sweiso3MJwpLjAlQcVVGIlBdhtERJEo4dE8ykFWBf9wx6n6aJg0nG4bTEZJbzTWSWG1ZNh+xigtdcmjIuvU2wUkyy3FfblH2NSIS7FCm5zUjofbLgUFKRKUmZa4YQqPctQQS6PjW3W0nxuC/IqvbMK0VnHXmWsWsceZ48lOal5tmqZhgiDxYVg7M8W3U4b5kWhlmu+cnZlgeHFefblroP1J3FhZQZfXxQIkSgyDVVAfPCsN5bMpmceuve4oJnWRk2taO4rzia5nx6WfPxxZblJOd0XnJnUVFf7iBGehvZMFAWmv1gMVJyXQ8URvNXL7c8OprwyeWeSaaS4sx6nq87Tg9yAjAvJdM8pzKKy31PoRVKCWaj7cg0Tz5ZP3m55eCDDK0kl/uBfXfrtAofHE0otOSy7rneDhxONatmYN+7VDBjygaZ5IrlxGCU4nLXczRVTPI0ebxct3gXuG56Si25aR035zuu9wN//GiBUZKLXY8LAU9KWawHTwiBg8rw6HDCJNO0zuPGzehX2y0n05z3TiZk43b3/UX5K0M3v+x6GyZ6O9f77XjWt0/4+85ytu3ovacdAg+WanTeDYmH/BUgob8tCOyrrm9dY9AIbmqbxr1Fzq5zKSc3wIPFhDvznN1gWXee2rq0iSwlfe8pi4xcKh4dTumGLTEmGCIuclZ1itQ8D5GpkXgEDxclu3pA6KQmubOs+M7JlL94tiZTkv0Q2LQJ021DpChS3sBBqZkWGUJpZrmmdwFLeuPth8D9RZWsD8YXjJbQ2MjECBbVlOu6o+kjIjj8mJe8afpU+JXAKMOBGegszCsQQpCrVCiNUZRGsbUuZVCPCxzWJcWUNjA1CSKIIUVIzqeaXePRMqYCzxsZ77xIPjzd4Hi1bulDxA4OVRqMUGTKsetGqapIiqQwBhUJBb1NsFWWpSIvBWgZ8UKSSziYFdSDpzBpDyX6iI8CrQxFtDSjJbrhjZRXSvA+0gs4yQXOSAIwySUSSW8LrveW/TDQDZ5pIbm3mPCd4ymX9cCLTcPDo4q693x23dCPP5zPbhoe9JZcJ4fYXeuYZwpkUvBMMkW8leIqybSIvNw0/MXTFYJ034OL/PyiQYtE8t6Zl5zvLL21vDhvKTPFJDPMckXtHN57zlYNz65rjFYURpBnmklu2HWO+/OcTev4k0eL5A92XdP2jihAq2Sip1TiDIZRZfX4qKLQikxLWmvZtp5pocm04qAwtL3jYjvgfUQSqArDxzc1R5OMV5uOP3gwxxOYV+m5B+vJjGLXDbxctex6S+/geJqlr73t+Nef3aCV5N5BQZVpHh+WvNx0fG9R4GJEj83wuh6wPjAvDVoJzncdm85yte85KAzn2x7r00Tzb6vmeRsmkuLzud7OhdeKqNsTfjekpnD/oGDVWrqh42LbcWdeEEcTwK+ChH4hT+PvcPHuW9cYhBI8XOb8+bNrdrXDE5kVGYuJ4XSacV1bjJAcTgyX245MK757XLGqDO0QkEbQt4ngLDJFZgyFjjw6NHRjStlJlaOz5NO96R1/cDhn13syIbja9RxVmuerjssx1etwanAusB0Cj5bpxSwlrHY99eDYD4528FRGMcs0lZEwzfjOyZSbpmfdWDrbsZiWzAuTYJ0uqXkSUdeTG0lsBLNMse48B5VG9SlFTYmE/3Z+dHcNESHToh4infpvjQI1qagqCcqkle313uFDUilZ/waWynXSrU9zkU73o0xQa82+99jgcePjb8UiUiauYXprRcsby/LBMco6I5n2HEyy5BUlIz4IprkgywvUYHE+sGre+FXNi9TcBtJUUxWKItNsOkcIsOk6buoOrRWVStLjTEkklhDhzjQZuIHHBcH//dMLpplBjrzPy03HNFecrQeW00gMAh8s/+LThmmmIQqmlWZRGD68d8CT4wmfXdX8L//fDa2FEB25lMQYmeWSzjnaIXC57+iHZJ0CsCgz7o724NfbARcjm02b7lVJMiNY7QbmlWJWGjKt0NLT2MCkSJYZYRqZ5Jqzm5anNzUiCiaZZjHLudx2DD7weFniiJytWj692HO2LZEIrvYDxzODaFMjrYeQXLZ85HzdpSW+/YCWgherhlwnyNVZz8+udrSDp+4T+e99slo5mWZoKWgHx49ebjmd5eQm7R08OppwMS4epv0Jx4ttz/RYs24sk0ynQ8rI+9w5yJmV5nVR/yo1zy9TEr0NE1kfXj+m6R2rxlKPyzcPxwyKznmiSByZMenfPF+1FMZy/yBZoH/ZvXwTJKpvX9+6xtAPnrNNx9PLmtp5REzkzvm65ffuT6lXLVIpHh9OOJ0l47V/8OExzkb+j59ckkvBg6MJ973jbOc4mhiMlhxWmmbwDC5Q9x4fA+frFhEDQ4gsq4yt9TxbtWRGcTJP26zb3hGCSFJU62ldYFEVPD4u+XncU69r6sFRSDiY5Dw5mrDuLJGkSd90nllh2HYuvVGtZ5JJXDA453ixblnVjg/uTKi0w2jN93JNFwS7pmXTBqyzhBiY5YpZkRGiw8UMlMMhkT5542uV4J5cizFbwtNZXvvmE9NJn5BO/kbALJcURqK04GSSY4xiW/c8XXW4EF/Ldgc38iRjo6iH5EZbaFhUipvap+1z8Sav4kmpMTpDK0sUESNFggGHAaJIkEZnESI1ljITCBc5meao0W57P3oSEQ2rzuObgS6PPDmqKIzkcJqx6TyXjeXZOtHrJ9OM3kv6JmnvQxAQAvves+0Geus4muvkluoC3iTb6PNVRz/1/IPvHlN3jqu652KfjOcuthalFXMZ+OB0irWBKoOLbc+k0BidgpKKTHO96+mtR2rBwmhW+wGpBE3bo9BIIvsuIEXkSvUcljnLUlHkmpNZQaUUrU9Kl3/98Q0+wjxXKY+a5Pn081dbeu/Zto5mCGyHtCRYKOhdZFEpdp1gVXd8elWzyBVRJAXN06ua+8uKfWd5fDTh6c2ej8/3PL1pKIzCh0BnAxfbnj98MMNHwctNx9ObPZXRGCVYlBnt4PngeJyKx1S3W5VUa5MX1NE042LXY0Ng8IHTWYEUAqnEV6p5fpVC/DYRrETauI4xcl2npMNpoT+niCq0QstEGBdG8WhZcTzNebSsvjDT4vb6pkhU376+VY2h6R0/fLri6VWDFIpKR1oLWkjyTLEwGQ8OSwptkvVDSA6eHxxOyYxiVmo+uawJAl7ctPz77885nGRc7nte3jQsq5zFxND3Se4qiNRdYN+nlf6J0fginbYro1BakFmJC55SZdxfaP7eoyWPFiUWmD3WVAYG65IBnoDzXcfpQcnxNONs3XEUNfNJzqI01NZj/UA9BBalJpMZV/XArNC0nSUJYhWLMktFTCgOCkUUmkwK9oPHh0iRZzypdArj2fcUWnB3qqm7gVXvaVz6Huo2FerMJMksEZYTiUAxeEdjI90Q0nNqxfmuT4ZmRCa5IMQMFyIxOlb7SDdAVYxLgCFxDGUuGJzHepjlAjsuwjU2smkGlhPBz8giaQAAIABJREFU8TxhvTZ6LlYd28YzKRVHZdrZljGQaUMUsF93KQ40g9Px56aNJs8Fp1phvccHCCEtRGkEs0Kzrh2bJi319dZxUObMq1SUV/XA4CNKRTob6QbLfkiRr52F3rYsZ9kIYXmu9h0PDyvCWMhCjDxYFFzuew6nKY+ht0nWW4w2Fusm+ZtcbFsUEi3hwbzkuu7TnoESHE4SNOpxZCLFpHYOtr3lo4uG04OcbkhE+dEkJyOSa0ltHRc7x/NNQ6Elv3/3gF3vsCEipGQ5kVgbcCFyvu8pdJoQd4OlbhNwOOSaw0JzuR9w3nOxadgPHq0Eg008klYKISSZliwnCiNTauBRSIU3hmRHX5qWdgh8b7QIf70gJxMsdTzNEAh6G8i04A/vHxBjxI1BVyEmj6UQvjgX+1ctxG8TwSGm5DznA1f7gWmhOZ7mZFpR928Cit4ljh+PORa3pPoXTSffFInq29e3pjGEEHm+auidSwTZ1DBsLXOjUUSMEmSF4r1ixotVR9sOuJhggk9vWuQIdXz3zox5aZjlW7RUrJpkhHZ3UfInjw64qW0i0AQcz3MGG/j4smHXOvRUMM0ELgoa67k7m/DU7Tkuc+aZ5vigQEhBnifZqVaCn77aIoXChkCMgsEFhIgYrVi3ln3nuKgtf3jvgKbvuHdQMQwOqRXRRwSOItMMIZIZRecCEwGXdcfUSI5mJdtmYNs7ZplmXmhcjBwUkof5hOsx7rF3nizTqCFwUGnq3tLeTgnjKb9xMClSsQloJiJQ5Apn00ZsY3vaIeKBeaGZ5ZALQW1hWiTl0+m8JCK52DZkSiGlQstIHwdypQje411EjqE8mdJEEelGZ8/t3pHpVJS3rSVXEhfTRLbvA4+XObWLiODZNp7FJFl6K5nUTU3r6UYjud4H5nlyJz3IFXUnWTUD1guMktzUHQSJkFAqmVL9xukkjjkdhNTkLrcDZa5RVvBnn654vu7YN467i5JtY6lyzTRzzAvFthk4muVopVntem72LbvOcb3vKYxmkoHQipODitZ6jqbgSFPLstI8Wk6Z5BlPx4xp6wOb1qKV5PFhyeAjT68b1l2Coure432kMBItk4eUkJJ5lraeL7cDRksutx2FlNzUPQLBJDeYieB82xLrgVzAru2RQtLpwPGsYN97BufJtaQwAqLAxYBSku+eTllMMmaF5qNXO6rMcDJPAozn64ZpkYjr42nO+abjYpekn8fTjMNJxkFlWLfJuaB3gXmh+PS6wVqPVJIHy/IXcrHh1yvE7xLBIURyXZObtKD3rpy0MIqHi5IhBDIpX1uTfNV08k2RqL59fWsaQz04zjYd+z5wvuk433R8etWgtWI50dw/nLBvPH/8ZEGhFM9WgkeHFQ+WJWfrDh8DmVIURo367WQFUGWSXGuWk4wHh1MOSsvxNOPnlw1CRG7qgQfLnHXjmeeC1kqij1zuWw6qnEeLCX/y+IDCGA4qzZ15wZPlhPN9z7bpuGksx9OCSGRSGq52HT7AYNMJJsTIzX7gk8sdsyrjwUEBEl6sO1ofRojK4UKKA11OMu7MCnqXYJpt46gyRYwp0e6mSdPNvo+0voeY7JZLJam9RwhoXaQZF9luG4JRiai+P69obKAZAk3vGYJHBEGhJUWW3pS9hcE5zjswSqBkTBOUlCkEyQ4IkRRU+Rh1WVnFpnPpzSaSUsYHycFEMy8MP73cseoGdrWl9QEVAosyT03UKJaF4WrfY5RmaAaKXNEOgYhiXVvqvmPwaaciZUwnjN67SG8dnY3J8LCzrJqE+UsBs9xwf5Fzvbe0vSc3YGQis0MfkBkMA5gscTeZTMtkJ7MMlOCnrzbYAHdmGVoJXm0HeusxSrLrO1aNBSIPlyWD9VgfGHw6nW6bHqUUy5ni0bLkbN3inMdogwspErZ2Hms9gw/kqmRWZigFP9r1LCtDZyPbpqe1njJLhG6IgUIJnI3YmOTUmYSbuicK0vQANNZjhKCzkdZafAy40ffLxbRrUveWWW4wRnJqNBf7Hg08XJY8WJRIKbk3zVnNLFrCxW7gx2c7tu3A0TTnbNViXVLsPTosIcLTm5ofvdxyMss5neUcTjJerlpcCGwbS20dlVEUZopR4nPTQAjJaRX43BQC/EIhfpuDMCOUJWUyCHy1SWaO78pJ320Cp7Oci13/ldPJrypR/dv0T/q6E9z+O+AfARcxxj/8gr//D4H/Ffhk/NQ/iTH+l7/t+wghcjX+cqaFZN30nG9bpIhoIjEk7kGMapU7i4JFZTieF4QQE0EbP/+LOJlmr618q0y9NjSTUiT1RmV4dtPiQwra+cH7JZe7nn0XUBLujjnB2ki0kLgQuTsvef9kSmEU97Wk6S1H05y68yymBiVk2iGIcFUPKGBwkWmmcQhyo7huBqQQr7MepJD0g0Mqycms4OHhhGmueL5qWRYFE63Zdh6RO96/M+VgZxmc52zdUrfJFC2ThrPtQCQR6vs2WXcUIhXSKodCSU4OktSxVArTOYpCoCI0Q2TbpS3u3CQH2calDXAXIqVJuwaZjngb6MbwGa0EWiqEiMzKDK16rBdEpSikxJjU2J6tWjb1QKEVfQwsyxQ8czjV5FLxwemMj6/3ZFpT5RLrFau6x4Z0SpYSHiwnrBtPYQRaS5RMiWuLXHHTONZNTz84Bs9rua6IUA+W632SJ7uY5L23RSHTkmWpudwNIJKRYhCaxqY86tykxncyz6hbR54rvPe4EPizp2ueHJdoIsZI6i5lYciY/J3eO6mYlJr3jib87HzH0+uaq72nUtAMHWWuyJTgdJrx/Kahs57zfcfBzqTvD3h4NGVd39DZSBRwf1EgUGxbx6PDAlWlez2dZmS5Zr0fqDtLMOBtIPiINLcktMfawHWTmvr7RjArpjxcligpsd6zbgbmuWJWZdyZ5wQE81zxaj+QaZmW3kQkEPje3Wni5QaH3QTuL0qqPOPZqqEePLkR5EpwXfecbzuUJDVMI3FdRGTwYt3w/tGUEFNBHWz4nPR031k2bSL1T+cpo7sYF+S+6pT/RVPBbZ15F6J6uWkBPmdA+EXTyS+TqP5tk9Nf98Tw3wP/NfA/fMVj/nmM8R99nTfhY6SzyfjrZ+f7hAcLidI6OTlqlfJvR8LIKJm858dCH2OyML0zL5Ksz0WyqeIH7x3iY+Ryl4JKOuuT+dd+oLOB37szocoNu9Yy+MCj5RQl0olxazQhRn7/7ozKaE7nRTIck29G0g9P5/x7Hxzx2dWe/YjVH88Lvnsy5WrX44jsesfdWYmLnnlVcL7pmGVpBf9PHh1ATJ75l/XArnepmok0OZSFZio00yqwHzzb2rPrLdNCoY0i2MjLdc+8zAgxkOeaWYxY75Ndt04y0irPKLXk+3cXrFrLh3dnfHa552cXW853A15AmSW8ve0gGF4TyXZ0bF2UEu/TG3iSGyalZttadjFQGcndRUHTKjadfY2Ley9wPr5+I+a5xLYRKQPzPGOeGYROZKeWSQr588uas1WdvJ4UXOIQ3hMx3J8VzCeaXR9YNYknaMYdhW3ncD6R3pUGZRL0RAi4AO1gWVaaTKUkvrqzlEWOUILZJMM5i5aK/RCIIbJynrBPBCZCjtbVglmmuez7ZC2+s5zMc7rB09uUJ6G0RBtY1ymC9vkmkGeKoY8cTyXX+55cSqyL3F/knG17LpuBXGs6mxp+ZhTWBf7FTy/xxNeLaWfrjlmZ4UNgOSlYTHIOp4ah9/zobIMPgSgFD6Yln143LCaapvMcVgVaWvJMUZYGIyRVnmw1qkVOP7rLPlhOuPdewek05+W6p8wUYYwVrDvHi23H1bans5bjScZNbWkHy72DEiVEMu/zgd4m3i5tPDuMFBxMM6zzVLmmt54rn/LYiXAyK4g+8nzdYMaGrYCLTcedg5xJnor27Un+9uPEi0jiOwqnL5oKjJZpGnkHohJDcuH9VWCiL5Oo/l2Q0193gtv/KYR47+v8Gr/KJSJc1wNGJMOvH34W0nJTnkihTeM4nQaOphl6lMW9Jp1cYFFmKRaT9CI7meWjb3z6pUwyjfXhta98MgBL5GuVQZVrQp/sFcpcczpNcZV3pgWPjydfuoyTZYp/+N0TZrlh3w/UvWPXudemeIVRHE5ylrM8EZ2Dw3mLySrmBSgh+cn5luNZzsNcczrP2baegyJy96DkTx8vESHyN/8/e+/xK2l2pvn9jvl8+Lg+b7oyLEPX5JBtRoIwAgQIaAhaaSHttBpAC+20198wgCBIs9BCm9lqIQy0kUYOLbTE5rCbbBbZxTLp87qwn/++c44WJ+6trGJWFdmsItldfFdVyMjIuDcijnnf5/k9FwVp1bEpazpjWGwsaaDoIoM1+mY20e4Aean2J71JrOjx/oHv3J1wMskonqwodyiRvUFC0XppYmcgDAxF7eg671FQEpLQf1muth2TNCTSDmelB98Z0Fh0FFE2HUVnaHpD0fhe/iASbJuWcaw5Hsc4B9uiYpn7zOZ13bKfJtRNR9M59gcB40iRRxKEDx+qqo5Qw7oyDKMe2Yldq8izrurGILUf9gbS+ww6g1ccWUdvINLeLzKLI+ZZSBIrni8rvnY0pO46itpyvq2IlGa9Y3pc5t5XonpBZwybsmaQRhxmIUJ47tAkCxgnAb84y4m0QEmF7S2rqqXYQegGsSZUXhLqgCSQzNIYpMNYTzydpzHDNGBbt2zqjoETvHaY8rPnBc5a0kRxoEJ6HHnVoLW/VWjg37xzwfEk4jLvyGtvCC3qjkjD3X0/HH50WeKwOKeYpxGhltyaJLx2NKAzjodVgVYKKSR5YwgDf/uZDUKk9BLYnz9dczJPcCbkg6uW989z9kaGrndESjK4O/UkgN5yldccjhOssZxvajrr+HqkqTuLMb71Nk5CtJQo6TeUDxcFDxcFVWsZxZrW+MVdKcG2MewNopubBXjVU9GYm8U/i5T/M/vxJLii7vjhwyXHI9/66XpLrz/aBJSSN+2kpu9vEup+1bLWI0V6az/31vFF1u/DjOHPhBB/DTwF/ivn3N9+0f+AE17Wtqk6trWXlCqlaXaqiXGmuXcw8MPBF4ZInwwR/7RrnpQCuWs1hdrzWy7yhm3VMko0B4OI0U5bfZn75vzBKOb2PCP6nOvgJA35zp0pH17l/PjJGodkEGmGcUBetvzJKzMCrfjgooBIMohC0kCxFi3vXeSUnWWWxQwSTaT9x+jrJ2MQnpVjhY9/vD1NON+GrCrDomkYaM08S6i7jt72xNozwaepNyVNIs3pLGZv6I1IB8OIOJD8h9885i/evWSZd9S9AeFPUmkk6TtBlPWUrcM6kEqirMXssqWds1xsPY4kDjRa+fmIqDsutz068B9XI3yfOK8NYSCxQjIMBQ+vKoSAVGs657MVTM8NKmLbBZgOQq0ZS09DLVtHqCWDyJ9e88bsYIWKRMOzrqfr/Wwl0oLJwGE6n97n8H6LKFJsy5511XAy9r//Vw8G3J0N2NQNq6Dn7jxlWXXotWRVdQxiiZCaKBDUnSUIAiIlqXYk3700JIsC2t4yzhRNZ1HS8mztZyEn44jXj4Y8XpT0wlC1hkXR3kS7DsOQi9rDqg7HIauqJwk0sZQcTkP6znI0CgiUZpJq3nma43D0TpJoyU8erxhEmk3d81qQUbUdm7on1oKr3Ptv0qji60cjklCThsp7dbQ/9Ewzrxxalx0Hg5jeATiWZUcsfbutaHs+uCx4vCh5/6rkZJ5xa5Zysal4sqpxCCapV/396OGa1/YyXtnP6Hqf5fDTJ+vdd8GLK0aJ9ga0cMBsEDJPQ6JA8f5FQTQUrMue1va8d7GlbA1503N7mpKGmufriv1hfDNgvspbYu0VYXXrCbev74Pho1uBdY5l5cGEgfaDeuscTW9pevuxls+dQFG0PRfbhottw5VoP7cddH0zMcbeIESyOPitDKd/1xvDD4G7zrlcCPHnwP8EvP6yBwoh/jnwzwHu3Lnza/0j11P/1hh6azDALFPULRjrKabjWHN3mv2SXO3FHfmzducXlQVpqHnzcMjjVcU8DZFScnfqJZWv/Jq0RWsdl0VLHCiSUDNJJVe5P21ZIfj26ZQPLkte2c98u6P3/Kdv3Jrwd8839LtTkGf7C+ZpxNvHE6yAp6uKrjM0JvooH2BRUjYdzgnu7yfgUq62NYMw9BjpwOcxz5KA79yf8+o85cFVwarqUVLw06cbLvOGKJS8PZsQXeT84vmauvXOz71RwhuHIT+7KEikoDWOGEfVG5rOkGgJ+IW6aDsCJcjb3vsm+t6fZoUjjr25LA0kwjkcktkwIlGSzjo+vCpwRtAaTxOtW1BYkjCmdX74val8poVW9qZlOE5Cqs5Q5RbjlGdYbb2EtbeWQAuv8Aq98igKBcu8I9byZmCuBLx6OGIQaaaDgFljGCUBv7jY0huHMV4VZRwMAsksCwkCz9HZG0VcrBuWRcOr+xnn64pQKvLOsO17LJJBJDgce8Dcs3XjPSixz4joekvfg9GeKXU4itgfRQhX0zkYRZLHVxVPlyUOGKYRg1BineFoHHv1koRl2bGsWqzxSW9tD40x7GcJ0U5+eTgMaazldJaQRpqLTUPTGvZHEW8eDjmcJPzk6ZqyMQRSeBDgskKQMEkDfvxkTRIotPQKsyeLglePhuidNPyN4wHPVg2rqueDyw2BcoRK+4yI3vL6wZAs1tStoWx6vnY45P58wJO1T5uLQ99W2lQtZ5uKp8uCD68qpknIOAuZZxHvnue8eezbgvu7k3xrvdw7bw153RFoyTwLb3IcrHPkVYvW0rvFHZxtaq+O6izfOh2T7g6ZL37Hr/L2xqjXduZTsySuv/fXN5MkDDgW8HRdcwQ33KkvcwD9O90YnHObF/77Xwsh/lshxJ5z7vIlj/2XwL8E+N73vvcSdfJnV9MZzjctm7pHS9jUPXXvsc2TLGSaRb/RMOeTygKtFH98b75zFn/0Afkk/fHz6lpal4R+HqKkNzqNYsUoCphlEVVvSXZxhbM0ZFm2TJKAsuk5naYgoWw7ihb+/TcOCUP/Gu7tEraOJgk/erRiXRneOBpyby/j8aJkWfgv28ko4bxoKOoerQWBaKjanst1RaQk4zSk6jycsGh6nBMEUvJ3ZznOwSiNGYYS4xxxqDmZZmSx5nzTUnWGQPss69Z4D4CXZtpdprO/8RnrF+JJouh3+dOv7KVM04i67dm2PcI5nm28yKDudoPiqvXYcgHb2pBogzEGkCgMg9gP0Mve0BtLoBUXmxopHG1vGMYhTeLlsFpCFCqE7VEKtjVsSj9/GsXeDCet43Ac8+3bE8od+E0JwaNFSVG1SAtlYyk7w7ZsqRpLbeGPbo+pO8uzZcMwUqyV5C9+cUHZWb8BJpqgE9iqZ55pHIIPLnLSUDAb+HZkv5PYRlIyzAKGoeZs27LIW5SWpFKyaVqucs/NkhLO1xXpPGWWRQgkOMmqarHOofCegweLgmXp52gORxIGtF1PFGgiJVhUHfMs5HSWcL5pfHJe3ePWNc/XNYu8pe4MZdsxigNuT1OK1vB06WNRL7YtxlrePc+JAsU0CdBCsCr9YHicaDaVN9sdjPwN4W+f9YzigLzpEE7wZFX6sKWRz4o+2zRgHUEgeP8i3yHOJbGWGGcZRNJnmPfebBcHvh38cFGS1x3vPNsyywKyKGAUawLlCbCrsuXDi5zLot3lpiiyWDILvbHu2gD34rzwxe+xVoq6Mz6zfOecPpkkv7ROvPh4ax1RoDgcRB4SqD/dLPdF1e90YxBCHAFnzjknhPhjPHXh6ov+d7yOu+d0Ens1krPkdUuiFXGg2RulPN/UlG3PSIef/4SfUl8G/Or6JgLwxuGQnz7d0BrLMA745umYKPBuS/Cu0CRURDrmcBTT9Ian65phrJFCcHeeMk4/+vmub0TDOOB4HCOFIwlinm9qTiYJbW/5zp0Jcaj58LLgf3vnOc3Wh0rsDxI2bU+Y17x30fOt0zE/e7ZlfxCybQzOWvrOoAK4M03IEuUztFtD3vYMkmgnY9Q4Y/nJ0y115/ETgRDUvcX69Rul/KC4M9DZnkkSEoeSOPKKpTjW6FBS9462q7nKe3IvBiGQDi0FsfZDVqEkWRSShYo264nDgKeLkrzssNYrpTwbR+Dw/obTWXZjZIyl40PjW1lCWHZKR1ZlzyAKeLDyBsS2s3x4VfF07WNJz7bemJZFimEsWZWCTgvKziJMz9Wm5XAiiLUmSzVB6bOz48D7Si7XNWmsmQ00OEPT9QTC8ebRyMdyWj/wLntDs/MlPFpVLLcN+8OY42nMk2XFh5cFWiru7vwMq6pBS8nbdyY8XlU3WdrH4xiHn81ta7+xJIFmVfd0fcur+0Nuz1Ksczxe1rvnLolDH0N1b5bwsOpIA4lJQ+YSfvyo4Wjs21NPlgXP1zXCWubjlChUjK2fAx1NUs63DY8vaxZVy6YSCAHvPLOcb2vePBwxTUOmacDfPl2zKTo65/H3l5uG072EWRpxlle897ykx6G1ZBAr3r80dLvNYFs3DOKAURowjQN+8njNwTDkg8sCIeDBouTOPKVdWr57d0rZ9Pybn58TSMEgVKyqnsfLDZGUHE0NJ9OYW5PUz3Y+0f+/6VrsNgWcYxBrHI4fPlz6ECH5UVTp9ePzumNZeqWgdXDrt+SG/rLlqv8K+GfAnhDiMfBf43lmOOf+O+A/Af4LIUQPVMB/6pz7tW8Dv0o1xnBZtDy4yHn3omBZOirdk1nYVi1XeXujb/5N6ouGX714E9FK8s3TMdMsZBQFN1fQlw3KjXEUrb9uD+OAtjfU3cudoFIKTqcp55uG9y5y6s4wiDRlYzjfNnztKOL2LOHNwxH7k4ht2fFwWdH3MM8imtbx3tn2xltwMok5W+Z0WJRVZLuTnXUwS3xKXhopqsbwxvGInz1bsy5rb74LFePERz2GqcUYCJU3+CnpWz239wYY60hDD4AoW0O+g/7NM58FIGND1XvOk5KOONLEgW8NtZ1HV4xiH1PphJcsJxFILFoFOOPzqbNQMslCjiYpzsCq7hjFIZeF//mvKbIIaHpDLxwPFgWvbiqkdPzt0y1Yh1KC+/sDzjaN78WHkpiQno6i8229h6uKo1HMUZVQ1L1HsjjBJNGUTc/RKCJvLGkQ0hpL1xvO8hbnWoKd87wzjkXZ8P5FjtQQKv8zPrgqmKQBkdZs6pazrd8AjRMIvBt9kgacTv1iP0g066LHdIaitxxFAW3fc3eWEQea2SjiKm+83yP1pFWtBRKJxfJgUTJMAm9a05rG9OyNYtIw4Omq5J1n690w26IDf8K+uz/gaJpxPIpJwoCzTctcBhSNodlhyPeHET8/86f5RdHQ9pb5KCaLFL11PF8XCOX4y/eXHI8jnq38MGjhGl47GFDMe7a1YT7wLd7X9jP2BhEXm4Ynq4rzvEILL+2WAtZlzzQVPF1XFE2HNY4sDXi8KHmwKAkkpGmANb6Vyu6k/8nv2fX3+PGypGh6BrFmloZcFS1KCJJdt+JFOuzBMOKHD5cefri7SZ1vG+58Bl7ji6ovW5X0n33On/83eDnrl1pKCEzveP8s54cPliy2PQqvRe96x/mm4q2T0Y2J5fetPu8m8rJBed2bHWLcM2SUksxjT/d8WaWR5uu3RjxZVcwGvq12MIo427Qcjlp6YxFS0HbWM342NVGgOFvXjLOAZ8uSw1HMouqJpaDoHadT30YpGo/pOEhDDicpx+OYcRpyua350YMlWaSZDhMoGlrrlTX39zO2jWFTNr4P1DkCpZhnAdZaDocpk0xztqqorcU6z7Ep2h6UIlOKVEBnvBosi3yuxvX8YtM5EIqy6Yi0d/tO0oi89lmqUeBP7GanulqXHXnvKYNK+aS6QPucibzy4D+LYBYFLMqOnzxec38vBRwHo5h13bEqGs7yBuEcdevptFJIhOwRKiB2jsY42l3PvAwV9w8HbIqOJNDcmWc0xmJ6y4dXBY2B989y9ocRYSD43t0ZdWv52bnjfFsTGg3SsW076g7qzmGsYVV2rMqWvUHM8STGCcnZtmFvGHN/PkBJ4fv2xuKEYhBLys6QVz1/d1Xw/dMZIFhXLYGOAEfTWWKt2NYdTsCTZUWwaZmkmmRn3pylIV3f8+Flwbb2Hhut4fmmYX8QUjXGz20CxSsDnwq3yFveebKi6jqqzvHeeU7dWU5GMW+cjLi/N2CSeYT5WV4jERSNxRjL+bom0JJRrNlWPe9d5Agl+I+/e0wWBpznDdY4ztY14Ai0wFjLpvXD9W3dM4g9bdhYy8/OtmzKjrxpWZQdbWtxWqCl48GiJgo1VWs4HMYvdVzHgeLeLAPn0fFCeNzL9eC6t47HO7x+qBXzQcjROCbZbQRSiBv8xpeNyvhdD59/K2Wco7WGp+uSsu5ojKdsmgaS0DCMYl4/GH1pebBfRH3eTeSTfx5r5fujiWfNWOeHkS9TMlw7KuMdqngQKQKtdtAwwck44WxTczTxZru281+6g1HMqmqRCGaDiH9yZ8pl0fDoqvLJdNqnfZ2ta8JAoAJJusv07Y1ffJNQkgSS00nMJL3+OArPVwotiJ05Tgfc38uYDGKWeUOT9HRG7U5yPVUPkfJZwRKftayUH9RlIYziiNYYTqYpB8OI7DIn0L51sW0sm7qltxYpHYuyIw40B6OAk0lMpDXLouVbt4b+9No5T2LFK0NU5m9nQjq2dU/eGFbFFR9c5B4F7mBd9zxZGc53+vck0FjnXd9ZFBEIgQ40yQ61kMW+Vx0sa05GIf/0tTltb3jn2ZZQCR5e5SB8e+7eXsYgDqg6w7ppwTnSMKDpO8pOsix6sJJYx4Tau/cDCVmsOJ1kxKGgbCxXRbMzTVqiUDKLNV1n6WxPFoWAwHY+9e1OoPzQ3zmscazKFic8ajwLJU1ree0wY13tuEpNx9tHQxrj+KsPF17Zlmi2reGqbKl6y37gW4Nnmwatmp0na5A5AAAgAElEQVTBUTCIfSuztt78eHuWIpTw+HLhvSzbpqNte05mCc+WNauyJW873jgcs6k79kcxApgPIsrWMkok+4OI9y9y/3tWvm3z4UXJtu7IQoUUcDTN2B94Ndi27BnHIY+WBc/WlfcmzVKaXtAbrwr71umENAo+1WugtbxxThtjaDrvT3qyrHi+rpkPwhs67MUu2wU+4kWJ3ffVCvePd/j82yprfSjPtmzJO3MTbL9rDyOd485e/Ht7Y/j71IstqM59JJ37LEelAKZZQNkYjDNeebLrNT/fNIRKs+o7EJLv3JkghAfvvV/k/NGdCUoK5ql32g5Szbbs2N/JWCOpWVU1f/NwSaAlrx5mzNKYWRYRhJJXwiGXm2bnPPfI62EacraqWGxqHi5Lbk38XMMKwfN1wztnOefLiixWHA1jir5nGgc+A8BZ6hYQoKRvZZxvG7JQk0WKu/PUB8mMQ67KhlALHl36eYCWHu+8Kls6Y5gkIW1v+flzj8FOtaLpHUJ7lk+soFrUSOfFAcNEs206b75SmnfPNkgh2RuG3JkPKJqObdsziwJa481dMtLspRFagxHwzdMxx6ME4xx//WjN3Sjg6aKi7nouc38D60xHrAKerAtOREZeS378ZM1i60+0OMso8bLXujN8cFUinSWLQ07GMQZB5wyiVygpKHf+jWXZkwWKOzOvQHq6qhnHAcYYWqO4LHpGqc+s/uGDFUXds647BDDJAg6HEUIqtFQMBxJxHfcnBcLC4TjdzW+8Eul4HPONW2NuzzO08Avy5aYhb3osXmpsnEM4Qd4blkWzw7h4LEfTG2ItiAKNtV7iLaQjv+x5uq4YRRpjLV87HHE68fPEh1clRyOP1Ai1YFG0LMue1hiiXXpfFEoOhiFRIHnn0ZrDUUQcauLIf4c6Yz0OpK1IArWLtfVryLXXwKfRiY/d9K9v+J2xtNay3mWEu9339vrvV51hloU7Vpm9CQp6sqq+dPfzV2JjkFKgAstPn29oOz/hvk70GkWKuwdDQvG7Y59/WfV5LaiXOSojo8hCjbGex3M4ijnb+MfEgSKYJJzlDbcmvs+/LFra3qCE5C8/WCCFj2G8O015zxY8X1YMkgDhHMnONDdIQs8Wqi0ns5i6d5S1ZZgGfOvWiN54g9HjZU1eG1oHrx2OKDpD24MwjtJaFkVLYw1RD6UxYC1v3fZDwlXZUaiOvDEoJWl2KOTzbUMYCs6sQEhIIz+/mCYB20wxSkMeXvrTIF2PUoIPF6V3weaSxvRcWki0Quxc80Gg+NZpRBSEFK1v06ShYpCEBEqxyFsCpQiEINYCiyLWguNRSt52vHuRo7XA4BhHIWVr2R8lTNOQ/+/Bkm3dcbVtqY0F51hte7q2pzSOILFsyp7DgWHb9MRaM0kFvXNUTc841mSRv4XkVUPvNE3ndfHTLGJV9nz3zoD3zgvq3jDJIsZpSN1Y0jji7UlMXveUO+ZR0RpGiSYOPDzvKm9462jE47XPcTa9Yz5OuNg0OAdVYxDSk1AFPnfjn35tzo8frbHg2V3jndx12xAov2nfizNWVcO67Hh47k/mF3lL2Pdc5DVH44Sm9/Lm42nCK/MhF9ua/+Pdc6yFd55tmaQh26pjnoY8WdZ8/86MJNLcnWdcbGuqtmdRdggET5YVVdtRtv0Oj9JyfzLA7fw+xjr2h55OUHcBAsGHlwWDKPCAwFDybO2zM6KdQvDa9Ap8bCG/vqEDRFpxdx568qry7v/eWKqm5/m2QTi/fs0yP4+4lrt+2e7nr8TGoIQAq3BWEoWGpvkodObOPOH1gxFRqH6nmNsvqz6rBfUyymSg5A5u5k85ZneSOZ541hNCME5CIi15uKhukCJnuWcJvX444NYk4d3dMDrUklcPUp4tav7ubEvZdpQG0lCyP0oYxBHHsW+JGBznm47LoiEQkASCaBjukCWWDDBpQBMI+qKlbjxFtWwtuvQpagGQBJrBRFHUiiermlGiKeueJPBGr7wyXBUtWRTgjGPbGs7WNbEWNH2HkI4wDCmblqb3GQyn0wGb0gc3FUXLK/tDlBR8/daITdkRK8HTVUOsBEIYhJMo5UOFEILn25pt3QGCQaSREpSssQhOxx7WeDCNmSYhTxcVs0RzVXiZp1Qe4lZ3lkXesml7tFSMtECr62S/jqzT3J0mLMt+x8MqORhEoAWqMvSRxhqfs+x22Aq98xesax8V2ltHUXdcFR1JpDgcDPmz1+Y8WVZIAe9flgySgE1tqXZ+FyEF80EMzrvZN7k3cYVK0PT4W1UgiZXkedXyzZMRidQ8XpdEUrI3CAHJqmho+vomLtMYj73ftj1xKIm0Ylt1HovuoG49HDCrDOu64+GypGwtgRA7VZ1jEEms8LOVHz9d8aexb9O8e55zMIwo2p5AeJz52abB7TKzN2XHw8uCt26NmKUB9+YpbdezNB6XkmiPLvewQ09URsD7VyV38K1cHB9byJ+tqpsF3u02B2M9jfg6mOjBVcl75zkXecPRMPYOdCk42+xakOFvB839ldgYnICTaUQWKvKm80Nnu1OUWLi9NyAO9JfqJPx9rE/D/X7MfGf9aUdLwa2JP6WNkgDn3A17f28Ysy47RKjZNj1N71tQUSCxxvHOky3rykPrpllCayymF1zmFX90Z8R+lnB3mvJkU/FsXZJFimIXerRqWvZHIUmo+NrBgPcucn7yaE3ZWv/8jaE2hrjvmcQB714U3JknKKmZDiRneccgDhnGAY+XNWkgiQKNFD297TnbGhSCQMIgCdkUjQ/XMY556lEjed2Qt74PLnqLA7ZNT6QlPz/PcUbwtcMBaeJ4tiopG29ifL6sGaUhUiniwNI7izWWSlqSyKNGJlm4gyJ27I9jrINv3pnydO1nM9u652AQIiScb2uP2R5670bdGhI0t/dTbk8zvwnGAUo46q4nDjRSCfLaO7df2RtireWDq5JZFjDLYkZxQGMtt2cJ//bB2osWjEML53lNVUNnHK8djbxyaRDx86dbZkNFJDNGicdGaDz6WuCojCPREolgHAnSRDNKAjatZZL4JLzjWcJ8GNL0hsY4tBDcnif8nz875+m64mTsW4PvnuXcmUbUVuxS/DSvH02ZpBFKQtc5yrbnL99f0Fu721T8Z7YzPVJKltuWLNZ8eFnR9hccjT26ZJp5DMb/+s5z/ubJhr63pJEmP98wjDS9tazLnv/nvSukEGybHusE3zwZ8drRkOSy4J3n/gC0N/RQzEHspaZHo5hnG68ktDuO2oOrgl9cuBvwntj9zsAP3IUQHI9jb2oLfKriZd4w20WmGudYVx1H4wS9G0Z/WWvWV2JjUEJwkCWczlOuippxIqlbSxZ6d+Qwlp8Zu/ePtX4V3O8nw0qk8LJLLQSdsfziPEcJQW8de1nIINEs8s7jmzvLt25PebIqqbqYHz5Yk2hFmXcQ+FNh1VqWoiMMajpjSYOAJoSqswRKMIz9sFQLwbtnOU83Feu68aoXISlFzyQO2csibs9Tis7y+tGQorFcbmpe2U9JQs229kC2eBfGY/FD7UhJlBKkcUCsBUsnkCi06umM8S5nLVld02wtYOFiW3GQxRRScHc2wFjLRd4wjjXfOjlk0/R8cJkzzTRd7/+OAKZxSGUN27pnkXu5Zaj80HVbG+5ONfuDiFuTmIdXJQ/igr9+tEZJLyC4N88QUmGt4dG6ZJ5G7A8S7u0PiWPNo0vvQrdO8P37UwaRd6w/XBRsK0vR9WSRRgqJsYZNaSl3BkFjLYkWFHWHk5LLTUWsJdumZxhptNYoAcNIczrNGCcBz9c1y93geZ5FvHYwoLeGZ67hw0XO4TDGCT/ozuuOb9wa88reACc8w+z9q5ztuiJNI+jg/v4QKRx545VZSgriKCR0jixQDKKAb5yMebisWWwawkDRFpbWGIZRsBsudwzjmGXh893jJOB4EpPXhlXV4ITj/l5GUbVcbmsu1jW3ZykS7wU5y2teP0jZH0Rs644PL7aczLwHaLFtWdUdoZLcmqU8XpUoJZkkIXvDCLOTvF+riPK6Y1G0vH+Ze7psHND2Xhp8d55hbIcEbk0SwM8PksB7JMDf7p4sS6JAcjDykMyHVyW3pp8dFfqb1ldiY5BScDhJePt4zHvP1/Q49iYhJ9Mhp7OUaeyHnV/F+lVMeZ/2mNcPR2xrg8MyjLOdftujBfYHAZvGL7xpGJAGiluT1rN5Eh+wgoW86Xhlb0CiFefrBinZ5QRYLjYlUbhLv8Kfru5PBzxdVGSRZJrEsPGhRfujmEGk6YxvA0SBl2q+OhsyykK2ZYOxlnXRUfYOIfDJcL1FCEEaSKrWMMlCOmNwTiOEIJSerLpatMwyzVAJGiNwtmcyDBlHAeuyYRSnhEqSxAqrBK8fDzHOIpSkE4YuVFzmLc41TFKNiDWHw9ibzGqfzvb2saTsLY8WJaMkYFX1dNby6kG2yxHwiPdpFlHUHZum9y74JOSyaFjmHW8eDql7y2wQMYw0Uno202sHI55vKhb5DmioJeuqJ9vJJmdJSNVYDoaas23DKq+wDqySpEry8+fbnaEN7u5lSCG4NU2YD0ImoWaYaP71357dDGQPxxHPNxWRVoShJg08dPLuCwiIuvNGvLNNwyLv2BuFHI9iLJbLvGOcpP5UrCR12zEdhNw/HHiXf2eZpAFvnYx5tCh4cNlzPPbxusaCkYI3Dke8f5mTRpq684ayRdmx2LZcbBqUhNW2JW97Xp+nRFLzi/MNzgiqxvJoWWKMYV313FO+3RmHistt5YOrlOR0moFwDHaE1s4YpAw/5kMwxpLXPSfjlKuiQQCXxU6GbR2tsRxNEu+W3ikI97KQx6uSdsdcOhl7Cfndeca27rg1ST6Xs/ab1FdiYwC4ymt++nSNwbEsLHXb0tqC79yfghT/KOcLv2r9Kqa8lz0mjTTfvevbHtdDsr1hhBKC55uaq6IHZ3nzeMjzdcXxOGVbt4DmrWlMoDSJ1vziIufrJ2PmQ59xsSg65knAq/t7HI8Tzrc1V7k3hmkpmKYhiyLACsfRNGNTthSdoV9XnExTIh3gnKFpnEdYOIiDgLeOx3xwUXCxrmm1YOMcw1gzjDRXZYdU8PbxiCzWPLzI+fCqpDDeuxAGYHEIqdhPFJ1VjCLFVdXRdhbjCtZ1T6JD2s7jNaZZRBIqamPZNoZ4p0d3TpJFkk3bEynJMNTsDWI65/jJ4zWDWHN/f8C6bPjgsmIQKuJQcjRKaIx/nixUzIcxaSQ537ScrRoGseRwnPFwUVD3PvCo6rxp8O7hgG1jqNue6SAmVPDeeYlUklD4n0tJeO+iIhCghEZIy+NFye1RRBxJLnOPxRglIU3f83xVkcV6d1oOkAg2Oyz6k1VNFiucEERKEirF144GRLse+bXwYZQEfP/ujMerEmt8OlvTW56tvfLojZMRV9uGtRDcm2dUnQfUDWLNyTRFOkHZOu7MU0ZpRKQNWRjwZ6/NKGtDHCnevygxfc8i97fiZdHyfNswigNS7Z3/XWtxuqc3hsOJ7+03vWW1C64qdp+9LFK0vfMo8UjyrdsTzjY1jxeVR9GkAWa32Ad6xzTCo/azyKP2r/KWi41Xemml2FQdf/14xffuzjgaxzy4KjjfNGA9DmRZ9pxtGsKgY5oEXvDwJR9kvxIbQ133/C8/fk7ZGYRSBNLSO8hChTGw2LaIw9/1q/yHWWmkeWVv8Eu3iXvzjP1hxOW2wQG3pxnfPp3inOPRVUHeGZalp7ZWneHpsuJ4knBnmt4oNq4//Nu6R8sOnD9hhoHm3jxhWVkiLVjHkjQKCYVjEIeAY1X2vHk84LX9Ac/WNcMoQCuQUhJGElFLlPRSytvzjGHcIKVkssvt/sX5ljTSREbSO8u2sTTGIZVlU4NWUDaOrjWMk5BQCb59OuZi07IuOyyCV/czjLPIxvD6YcbDy5Is0QQCxklEYyxZFPBsVTAaBJytG3oLoTI8X5X8xS+uEM4xGyecBDFCCd488C2cvUHIsjRkkeJ02nG+aSjbjlXd8cpBxqLoETjypiMNQy8GAOZZTKg1QvrWzLbu2FiHtR4zvml6UiUJA8sw8Zh2KxyPryrE1OFQWHyk7H6qSELvgF5VPW8fD/m3D5c839SESrCXxf5mZnzOdPLCHO9F4YNWklf3h1zmDVL6tL9xGhBI71EwO1RG1ztuTxMirUhDjQAOxzFV31N2lnGiUWlAGnk5sdb+/ZwnHT94uGWcaKIwoO4No1hxMAowxkub86ZjL4g5nWbcnqdUbe9bjYEfem92ctz7g5Sv3Rlye54Ra+VRG7vXcn/Pty2t85ve6STx6G8BB4OIxS7E6PYs9kFP0hN7D0YZbedbRqfTFC0Fd2YJWkkeLcqbdmfTGZ62hu/emf7Ddj7/vlTee7ldZxxZoCETlE3LsmzI65ZBqj/VEfyH+vx62W1CSn8Sy0L9sU3DZ1K05K3lcOSzfI31rs/9YXSTA/BiHU/8wLroDKui47XDjIdXgkHqSLSi7hKazl/t90YRz9Z+XvGLs5KyM/ROEitBpH3iV14bplkIQrCsWp6ta5JAMYpDNnXLg8scY3wv/em6QgnJ3jCia3oq4ziZx6Rx4N21W8v+wGd4F41PFnvzaOTBfQhWRefDbAY+EbDqelZVvzt1OyaZQCtJWfWAYJJqrvKGD64KjDXMBgmut5xta+7NE7516v0jAuhtRxzs4mZbw/4opG7973qaehll3RmiQLHZIUmQgtb0FKXPRe6sYbtrWaWhZJIGKAGJ8yjrru9YbC1ZpFlVPbOB9pLbAIresSp6HI6ibSkaw9dvjXGP1qzqFmOdD4TSikXR8b17ntP1yXjNa+HDxbYhCSXGcoPLUFJwMvbJg2ebmnXdczIJuDVNeXhV0nWWUGvuzCKS0A+Mq8Zgesu2NaSh5o1bY8re8GxVU7cdXQ9xqP2cMQo4HqW8dTIkkJLe+XCqLA7JIhDCS0yddbx57BHjWkrOt83NTE5J/x5mkf/kSgRN3+PER7ia6cCnCk5STRpqjiYJy6JlkkZevmodD5clTe8PTHfm6Y2vIQoVxyOfB9+03in9ZddXYmMYaK/OqJuWVeHT1ZQPreJsU6PFyx3Bf6jfvH4JXS69lPD5pqbpDPvDiFGsvds3fPnHMQ4Urx8MuTfPblL1qrrnBw8XXBYtZdujRUTdeRVLFEgkME41q7InCxVPtx1v3xpyPIp50OdEWpGEBmt9PzgIPNNpGAd0xvH2rRHrsqd3jrNNzSQKCLPIE2aVYhQrllvLJNOoQKCs4DL3G0wQKNrOgbU8vCpJIsWjxxWx3mHGA4VSijePM4qmY38Qs207QqVYFi1F7SFMwyTyqXCBQiI4GvnsgG63qF5LiK1zDOKAw1HEouhQEvaHET99uvUKFuVzJpyFf+f1Oc453j8vyGLF41jxl+9dclm0HI8S3tgfcLatebaqCbVHgRdNQ9X5eVAUaiyOVdERSXbYa0sgJe9e5AwjzSwLuDWPMVZgrWWYhkzjkLNNzbNVhdixfzpj6XrfcumtxTlHpBSXdcs4CdmKjkkakEYBsVaEWtF2Fms9GPF0N4C9PXecbxs2VcdV4cnC59sagINRQt30CCF47TCjaAx5C9u6xVhJ1dXM0ohAKSZpyF4a0vYrms7zooaBxkn4J7enJJHmyar6JS/B6SR5qbpPCUEQyJv53Ov73KC7687ww3JJUfcY63i6qnwuSKzBOZ6tKm5P0x2s0TumrXUoJX8ra9VXYmMIQ8XXjyf8Xz+/oOwtfQfDQHA0zRglIf0XAM/7Q/3qlUaa7975aDah1Ofz5aUUH0OWR4Hi+/fn/ODBgm3tF4y676nankEcc2eSsGktVddza5wQhy2h0ryyP6DqLOuqI9GaOydeefLa4ZAk8NGcF3mLVIowdMyzyEsp91KklORVT6oFcaw527Qooeg6x8nOzRsIwdW2ZZgobx4UkmkaUjaGrve5BPtDHxoVB55Y+tpRyl99sKBzPplubxSxLFreOBpyWXQeBy4Ed/dSHP4Efb5tPiYh3h9E3J6mVL3hctv4GEzrOJklhMpHYC6KDov3APTO8s7TktZY9kcxdeew+PCkb9wa8+bJGGscz9a1b5dYy7Jo2ZQ9qZbsZSHruiVSEqv8IDnqBfNZxt4g5EeP10xijQHGofcxrMuOp+saKeAbt8ZE2hu6bk0SrHWcrRvsLggnVBKlfFBOZyxOeFHCs7WX7GopOX5hAHsiBO9f5RwMQjaNAbxXQSBIIsXpNKG1juOxJgokPz/LEc7t0Bwhf/N4xZ0dhv5gFPN0VXM4Cqk7x/4gYlX3COkX/2vg3bWX4MWbwcvUfZ86n7sz5cmy5OGyJNCC23PPFjPa0faWou39zdZB1ZpPpRd8GfWV2BiazrCqOv70lRll19O1HXEU8r27U6YDn/L0VR4+/y7q02YTv04N44BX9gb+pnBeMJMhe6OEV/YTqg6SANIw4P5+RrRW7A1DTiZT9ocRf/N4xdmmIVaSeJAwCAKQ0PSOYaj8wpQEnM4zvnE65tYsYVn0NF3PXz1cMsQb/UaJ924cTnwOwDQJKFtD21qKxnA0jYlD5RU+wCgNGUQBNnRsqp5bk5Q4ULxyMGRddWSRYFtb7s1TjIVZahnGCf/Bm4fs77KPpRQcSfExCfHxbmA61PImatYB67KjMRYtFW8expxOUt6/8CA6i19wnIX9sRcNRFoxzmLmWYjF55cfDUM+vKoYxgopPe/q+aZhmIV0zvHG8ZBl2fDG0ZhBrFkVHa/spUgJbe9Y1b13v0t2pjfDj5+sORrHdL3jYByThZq9QchlXvvsdGPZH0TsDyKe7wKAlJJ89870l7ILyqbn4aLg6aqiaA0Hw4iDUYrA5yNMk4DeOF4Z+XbT6TThYBSDEzxZVYRK0m4cq6JlnAQcjxNuTyR1Y7l/4Gmyee0HxDhYFC3Hk497CV68GVyf6DtjP/OznUYejGitYx0HKCF2OdGCo3HE3Xl2M2f7IlH+v0p9JTaGzliWeYNB8p3bUx4vK6qdi/Tbt6dfSXPb70P9pohyKQXHk4THi5JRrInDiK8djniwKKlbr46ZZhGtgVcPBkRKIRC8fjTmj+/vcZXX/N/vXfDBRcnPnq85HMYorRhnAVJBU1v2hxFvn4wIpGBd5kzSkH/3tX2K2rCqW6q6p24txvoW2WLbEGlJGEqebmpWZc9JpHn9MOPBRQHW+yf2BxrjfNYEzrfLBI7XjgY8XlYIJ9kbaqRIOJ0ltNanDQaBXyg+S2Z8fbu6vzfg2crTOsc7KWTdGRZFx5vHQ370aEPfewXN1w9HVL3lcBgSasnhKOKdpxt/IneO43FM1RtCKZDaa/inWYhwlqu85XCUcH+eIYTgbFWjleJwGDEbhDy4KsibHlfD2bZhWbbcm6VoIRAaD4sb7XJHrCALJFJKZmmIVuqlm8F1lU3PDx8ukbBLMPTZK4GSjNKQUaS5NUu5Pct2ucsWISWnEy8dPRzHN2qj821D3XmUxdEk5vGyQkvfwlmWHYH0v5eLvOHhVcnpNOH4BS/B9ef5Rf7Y5zGNAiWJQs1cS5ZlR9m2WAen0/RjctTf9qH1K7ExBEqSJXqHFk4RQrCtDHvDiMNR/JU0t/1jqThQ3JtnIPCyyEAxTjxp9N40Qyj/vn7y5AWwqjpePxxxbz7gvYsCY3zE5+uHGcui5/4sJdCag0FM3RnePBpSdobzjYfx3d5LkTicA618qH0YKL5xOmKRd/zRHeUxIjiq1vHWrRHLvCMIFFIpvnN7tMse9ulm1joeL0qElbx5a8Cm6jmdJAzT8KVsnM/bWK917y/+zGXrpY/jJOD79zU/erhgXTcsio47s5T5IOaNoyFpqKlan2inlGNd+ZjL3viDludrSTqv5uX7d6dIpeitZT6IORh6f0XZ+nnJBxc5oZKMdkDCVdVxiuNonND3lqerikGsGaVDL/e1Htv+WRG41jqerj2qY5SESAE/feZDIceJNwpKKW8Sz+7sOgPqhQ2yaVtEqDgceVjk3iDidJZijbsxFTq85yUKFEmkuRNptlXHyUu8BC/jj30W0+hFA+k0CXAi4GTHjvpd1ldiY4gCxbdPJ5yta5Rw3Jpl7GUBx5OUt47GhF+iUeQP9eWX1pLTqUcZF43v8d7bG7z0lHa9kHY7yFmgFFkYcDz2w88klGihqPsWJf2CEQaKxnhcwjQN2R9EnG9q+t7hJF6WqCTWbjyGe7cAtL3jZJowS0PypmeW+tlBqCX9bgidhpqq64EQgUd+T1O1g7VZ1k1PlgR/bzbOJzePNNQcjWOWRYuWgqNxwusHQ1478FBE74fwZq0k0hyOIyKlmCS9j6yMFB9eeUd0GvlM5SzSOCE4nSQePzNOON82lE3Ps413FYeBZF16d/XROGYYKU7Gfmjb7V6e3m3ecaj9+yg/u3VidoE4ofYL8CAJub+X4ZyH88lPZCO/+Lu49uB8cJlzmbf09qNbZdP59tw3bo1ZlR3G+PS0aRLcDJk/zUvwMv7Y571vX0by429aX3aC2/8A/EfAuXPuGy/5cwH8C+DPgRL4z51zP/yiX4eUgrdOJiDgp0+3CAFHo4Tv3p3e5B//of5h16/75VI7JpS1DicdQvowp0Ecsp96aeHxrgXQG4uW3sl6vm0Qwi+o12a+823Dtu5YlD3DWHG2bni8qEgjyb35AKzjKvc6+FuzlPNNjcUjmt8+GXGZN6yqDuEcw8RHjF5uGwIlb1Q4FveFsHGkFNydZ4RKUnY9h1nMnf3shvp5JlvazhCHmmkSULWGvSxifxTzp/c93uLw+Yb/94MF1nVMs4hv3hr73Anhb2aBktwJFHVvPA4j1Gwbj6yoO8s00VzuUNJaypuN5GWqns97D5WSTNPgpg0TaMUfnU6IQvW5n4M00rx1PPY4a375VimlYBQHGOc4nvjXeH3w+LQh8Kfxxz7vZ/mikx9/0xJfUpKmf1SFfC8AAAncSURBVHIh/j0gB/7HT9kY/hz4L/Ebw58A/8I59yef97zf+9733A9+8INf+/VY62g6cxNK8/sczPOH+vLrGmx2vmloe+MhZpOYJNBM0oBV2f1Sn/gamfziotPvEtXAsa57iqrj0aLYwRmVXxgkbMserX0LZryT6N6epny4KDjf1AzigCfLEnY+hGkS+OHvJ/KAv4iy1t1goV+UX+ZNf7NASiE4GEa/1N/ve8t7F/6Ald2gINwvtUusdTxclATKs7T8vMNxa5pwNIo/9ry/Tl/+k++hD72xN7eVL6sN87L3/rNe06/7s/w2SgjxV865733u477MjWH3Qu4B//OnbAz/PfC/O+f+1e7/fw78M+fcs896zr/vxvCH+kN9sq4XSPCnvWud+bUZ71dZCDrj+Ub/f3v3HiNXWYdx/Pu0S68iLSmg0HJrgIoEWuIFUAxySRBJwUQSCUIRDFHuXpASEkgwmkaMSAJKGq6JDZUWhEJqpcFaryACcqmoVAp0QaQK1AICtv35x/sumRlndme2O/POMs8n2ezMmTNznpmdPb9z3nPO+w50ebB5y1ae3vA6M6ZOZFy+OGpLwLTJ43hx05tVp+hO2G7sOwdQ0/KDLZtTV93Tp05kl5oV6EirtxIbN3bMkO+72ZVf7UBQ07Yfz+RxfXVft9nPe6Se107dmAmaLwyljzHsBqyvuN+fpw1aGMxGSu31EbWPNbN7X9t8MEap2+U0pu/WqhXn3uP7/m+F8c51Ha/+B3KX0TsNsgIdSY2a4IZ638023bXSxDfc5pRua4aB7szUitKFod4nV3cXRtJZwFkAu+++ezszmbWkXvfle0ybXHfLu9EKY9L4dPFdia3Mdq+QR/tKsheVLgz9wIyK+9OBF+rNGBELgYWQmpLaH82secPd8q7kFah1i9JHX5cBpyk5BNg41PEFs241ZowGPe/ebLRo9+mqtwJHANMk9QOXA9sBRMR1wHLSGUlrSaerfqGdeczMbGhtLQwRcfIQjwdwTjszmJlZa0o3JZmZWZdxYTAzsyouDGZmVqXtVz63g6QNwLPDfPo04J8jGGekOFdrnKs1ztW8bswEI5Nrj4jYaaiZRmVh2BaS/tDMJeGd5lytca7WOFfzujETdDaXm5LMzKyKC4OZmVXpxcKwsHSABpyrNc7VGudqXjdmgg7m6rljDGZmNrhe3GMwM7NB9FRhkHSspL9IWitpfuk8AJJmSFol6UlJayRdUDrTAEljJT0i6Z7SWSpJmiJpqaQ/58/t0C7I9JX893tC0q2SJhTMcqOklyQ9UTFtR0krJT2Vf0/tgkxX5r/hY5J+ImlKJzM1ylXx2NclhaRp3ZJL0nl5HbZG0nfatfyeKQySxgLXAp8C9gdOlrR/2VQAbAa+FhEfAA4BzumSXAAXAE+WDlHH1cCKiJgFHEThjJJ2A84HPpRHKhwLfK5gpJuBY2umzQfui4h9gPvy/dKZVgIHRMSBwF+BSzqcCernQtIM4BjguU4Hym6mJpekTwInAAdGxAeB77Zr4T1TGICPAGsj4umIeBtYTPqQi4qIv0fEw/n2JtJKbreyqUDSdODTwPWls1SS9F7gE8ANABHxdkS8WjYVkDqknCipD5hEg3FFOiEifgm8XDP5BOCWfPsW4MTSmSLi3ojYnO/eTxqPpaMafFYAVwHfoMHAYe3WINeXgQUR8Vae56V2Lb+XCkOjYUS7Rh4few7wQNkkAHyf9I+xtXSQGnsDG4CbcjPX9ZImlwwUEc+Ttt6eIw1LuzEi7i2ZqY5dBsY6yb93Lpyn1hnAT0uHAJA0F3g+Ih4tnaXGvsDhkh6QtFrSh9u1oF4qDE0PI1qCpPcAtwMXRsS/C2c5HngpIh4qmaOBPuBg4IcRMQd4nc43i1TJ7fUnAHsBuwKTJX2+ZKbRRNKlpCbVRV2QZRJwKXBZ6Sx19AFTSU3OFwG3SWrLqFC9VBiaHka00yRtRyoKiyLijtJ5gI8BcyU9Q2pyO1LSj8pGekc/0B8RA3tVS0mFoqSjgXURsSEi/gvcARxWOFOtf0h6P0D+3bZmiFZImgccD5wS3XHu/ExSgX80f/+nAw9Lel/RVEk/cEckvyftzbflwHgvFYYHgX0k7SVpHOng4LLCmcgV/wbgyYj4Xuk8ABFxSURMj4g9SZ/TzyOiK7aAI+JFYL2k/fKko4A/FYwEqQnpEEmT8t/zKLrvoP0yYF6+PQ+4q2AWIJ0lCFwMzI2IN0rnAYiIxyNi54jYM3//+4GD8/eutDuBIwEk7QuMo02d/fVMYcgHuc4Ffkb6p70tItaUTQWkrfNTSVvlf8w/x5UO1eXOAxZJegyYDXy7ZJi897IUeBh4nPR/Vezq2Tyk7u+A/ST1SzoTWAAcI+kp0tk2C7og0zXA9sDK/L2/rpOZBslVXINcNwJ751NYFwPz2rWX5SufzcysSs/sMZiZWXNcGMzMrIoLg5mZVXFhMDOzKi4MZmZWxYXBzMyquDDYqJW73z47395V0tI2LuvE4fZ6K2lWPk//EUkzB5lv+UDX05JeG25Ws23lwmCj2RTgbICIeCEiPtvGZZ1I6q59uM+9KyLmRMTfGs0UEccNt6fY3K282YhwYbDRbAEwM2+NLxkY1ETS6ZLulHS3pHWSzpX01bzFfr+kHfN8MyWtkPSQpF9JmlVvIZIOA+YCV+ZlzZQ0O7/WwCAzdQe+yVexXwh8UdKqPO3OvMw1ks6qmPeZ2kFhJB2hioGSJF0j6fSK+S+T9GvgpGbfj9lQ+koHMNsG80kDvczOXZZXjjR3AKkL8wnAWuDiiJgj6SrgNFK34guBL0XEU5I+CvyA3BdNpYj4raRlwD0RsRQgd8dxXkSslnQFcDmpANQ+d3nu6uG1iBgYWOWMiHhZ0kTgQUm3R8S/hvkZvBkRH8+Z7mvm/ZgNxYXB3q1W5YGPNknaCNydpz8OHJi7OT8MWFLRc/H4Zl5Y0g7AlIhYnSfdAixpIdv5kj6Tb88A9gGGWxh+nDMN+/2Y1XJhsHertypub624v5X0vR8DvBoRszsZStIRpG66D42INyT9grRX08hmqpt8a+d9Pf8u8n7s3cnHGGw020TqnbNleTCkdZJOgtT9uaSDmllWRGwEXpF0eH7sVGB1oyfW2AF4JReFWaRBVwbzLLC/pPF5T+WoEXo/Zg25MNioldvlf5MPOl85jJc4BThT0qPAGgYfA3wxcFHFKafzSAejB7r+vqLJZa4A+vLzvkka67ihiFgP3AY8Rhrh7JERej9mDbnbbTMzq+I9BjMzq+KDz2YVlAamP6lm8pKI+FYTz72WNCJfpasj4qaRymfWCW5KMjOzKm5KMjOzKi4MZmZWxYXBzMyquDCYmVkVFwYzM6vyPylyWP4zftcEAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_trf.plot(kind=\"scatter\", x=\"time_to_failure\", y=\"acc_sd\", alpha=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc_max</th>\n",
       "      <th>acc_min</th>\n",
       "      <th>acc_sd</th>\n",
       "      <th>chg_acc_max</th>\n",
       "      <th>chg_acc_min</th>\n",
       "      <th>median_25</th>\n",
       "      <th>median_70</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>73731</th>\n",
       "      <td>0.203594</td>\n",
       "      <td>0.731466</td>\n",
       "      <td>0.074961</td>\n",
       "      <td>0.152748</td>\n",
       "      <td>0.875071</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69150</th>\n",
       "      <td>0.325084</td>\n",
       "      <td>0.645540</td>\n",
       "      <td>0.122468</td>\n",
       "      <td>0.234890</td>\n",
       "      <td>0.775959</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124492</th>\n",
       "      <td>0.114456</td>\n",
       "      <td>0.856364</td>\n",
       "      <td>0.033070</td>\n",
       "      <td>0.043394</td>\n",
       "      <td>0.972661</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12942</th>\n",
       "      <td>0.247521</td>\n",
       "      <td>0.719396</td>\n",
       "      <td>0.122816</td>\n",
       "      <td>0.144861</td>\n",
       "      <td>0.827910</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52037</th>\n",
       "      <td>0.421990</td>\n",
       "      <td>0.580020</td>\n",
       "      <td>0.286318</td>\n",
       "      <td>0.351844</td>\n",
       "      <td>0.675659</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         acc_max   acc_min    acc_sd  chg_acc_max  chg_acc_min  median_25  \\\n",
       "73731   0.203594  0.731466  0.074961     0.152748     0.875071   0.833333   \n",
       "69150   0.325084  0.645540  0.122468     0.234890     0.775959   0.833333   \n",
       "124492  0.114456  0.856364  0.033070     0.043394     0.972661   0.833333   \n",
       "12942   0.247521  0.719396  0.122816     0.144861     0.827910   0.833333   \n",
       "52037   0.421990  0.580020  0.286318     0.351844     0.675659   0.833333   \n",
       "\n",
       "        median_70  \n",
       "73731    0.000000  \n",
       "69150    0.166667  \n",
       "124492   0.000000  \n",
       "12942    0.000000  \n",
       "52037    0.166667  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Splitting data into test and train\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_set, test_set = train_test_split(df_trf, test_size=0.1, random_state=42)\n",
    "# Separate output from inputs\n",
    "y_train = train_set['time_to_failure']\n",
    "x_train_seg = train_set['segment_id']\n",
    "x_train = train_set.drop(['time_to_failure'], axis=1)\n",
    "x_train = x_train.drop(['segment_id'], axis=1)\n",
    "\n",
    "\n",
    "y_test = test_set['time_to_failure']\n",
    "x_test_seg = test_set['segment_id']\n",
    "x_test = test_set.drop(['time_to_failure'], axis=1)\n",
    "x_test = x_test.drop(['segment_id'], axis=1)\n",
    "\n",
    "x_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\ptc\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 200 candidates, totalling 600 fits\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import reciprocal, uniform\n",
    "\n",
    "param_distributions = {\"gamma\": reciprocal(0.0001, 0.1), \"C\": uniform(1, 50), \"kernel\":['rbf','poly','linear','sigmoid'] \n",
    "                       ,\"max_iter\":[500000],\"degree\":uniform(3, 10),\"tol\":[0.001,0.01,0.0001],\"epsilon\":[0.1,0.01,0.001]}\n",
    "rnd_search_cv = RandomizedSearchCV(SVR(), param_distributions, n_iter=200, verbose=2,n_jobs=4, random_state=7)\n",
    "rnd_search_cv.fit(x_train, y_train)\n",
    "rnd_search_cv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVR(C=8.31993941811405, cache_size=200, coef0=0.0, degree=3, epsilon=0.1,\n",
       "  gamma=0.015751320499779724, kernel='rbf', max_iter=-1, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svReg = SVR(C=8.31993941811405, cache_size=200, coef0=0.0, degree=3, epsilon=0.1,\n",
    "  gamma=0.015751320499779724, kernel='rbf', max_iter=-1, shrinking=True,\n",
    "  tol=0.001, verbose=False)\n",
    "svReg.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3620526238839221"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check score for the test cases\n",
    "svReg.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Score is not very high but then this is a sample case with very few data points. Now we will use DATA-III for our actual training purpose.\n",
    "\n",
    "<b>NOTE: </b><i>We will be using the class within the path and not within the notebook. Only difference is the name of the file that the class treats as train data. For the class within this notebook the filename is train_modeled_data_old.csv and for the class within path it is train_modeled_data.csv. Same goes for the test data file.</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data file already exists ..Fitting completed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc_max</th>\n",
       "      <th>acc_mean</th>\n",
       "      <th>acc_min</th>\n",
       "      <th>acc_sd</th>\n",
       "      <th>chg_acc_max</th>\n",
       "      <th>chg_acc_min</th>\n",
       "      <th>median_25</th>\n",
       "      <th>median_50</th>\n",
       "      <th>median_70</th>\n",
       "      <th>segment_id</th>\n",
       "      <th>time_to_failure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>177.0</td>\n",
       "      <td>4.388199606653555</td>\n",
       "      <td>-142.0</td>\n",
       "      <td>13.704960870433874</td>\n",
       "      <td>54.0</td>\n",
       "      <td>-58.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>seg_000</td>\n",
       "      <td>0.27319883152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>120.0</td>\n",
       "      <td>4.68458948631621</td>\n",
       "      <td>-89.0</td>\n",
       "      <td>5.752406145638193</td>\n",
       "      <td>43.0</td>\n",
       "      <td>-45.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>seg_001</td>\n",
       "      <td>1.1796968053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>121.0</td>\n",
       "      <td>4.404168083361667</td>\n",
       "      <td>-121.0</td>\n",
       "      <td>7.697446640219251</td>\n",
       "      <td>48.0</td>\n",
       "      <td>-48.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>seg_0010</td>\n",
       "      <td>0.25729589012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>139.0</td>\n",
       "      <td>4.37621920730691</td>\n",
       "      <td>-153.0</td>\n",
       "      <td>7.511764610066801</td>\n",
       "      <td>39.0</td>\n",
       "      <td>-38.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>seg_00100</td>\n",
       "      <td>0.99249705282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>142.0</td>\n",
       "      <td>4.971872395746525</td>\n",
       "      <td>-144.0</td>\n",
       "      <td>6.355934086624004</td>\n",
       "      <td>77.0</td>\n",
       "      <td>-50.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>seg_00101</td>\n",
       "      <td>1.2499962564</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  acc_max           acc_mean acc_min              acc_sd chg_acc_max  \\\n",
       "0   177.0  4.388199606653555  -142.0  13.704960870433874        54.0   \n",
       "1   120.0   4.68458948631621   -89.0   5.752406145638193        43.0   \n",
       "2   121.0  4.404168083361667  -121.0   7.697446640219251        48.0   \n",
       "3   139.0   4.37621920730691  -153.0   7.511764610066801        39.0   \n",
       "4   142.0  4.971872395746525  -144.0   6.355934086624004        77.0   \n",
       "\n",
       "  chg_acc_min median_25 median_50 median_70 segment_id time_to_failure  \n",
       "0       -58.0       0.0       4.0       9.0    seg_000   0.27319883152  \n",
       "1       -45.0       2.0       5.0       7.0    seg_001    1.1796968053  \n",
       "2       -48.0       1.0       4.0       7.0   seg_0010   0.25729589012  \n",
       "3       -38.0       2.0       4.0       7.0  seg_00100   0.99249705282  \n",
       "4       -50.0       3.0       5.0       7.0  seg_00101    1.2499962564  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import accoustic_sampler as acs\n",
    "# Create object with the directory path having training files\n",
    "sampler = acs.AccousticSampler('D:/PYTHON_WORKSPACES/Kaggles/EarthquakePrediction/LANL_Earthquake/data/train_data_new')\n",
    "sampler.fit()\n",
    "train_df = sampler.get()\n",
    "train_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc_max</th>\n",
       "      <th>acc_mean</th>\n",
       "      <th>acc_min</th>\n",
       "      <th>acc_sd</th>\n",
       "      <th>chg_acc_max</th>\n",
       "      <th>chg_acc_min</th>\n",
       "      <th>median_25</th>\n",
       "      <th>median_50</th>\n",
       "      <th>median_70</th>\n",
       "      <th>segment_id</th>\n",
       "      <th>time_to_failure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>177.0</td>\n",
       "      <td>4.388200</td>\n",
       "      <td>-142.0</td>\n",
       "      <td>13.704961</td>\n",
       "      <td>54.0</td>\n",
       "      <td>-58.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>seg_000</td>\n",
       "      <td>0.273199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>120.0</td>\n",
       "      <td>4.684589</td>\n",
       "      <td>-89.0</td>\n",
       "      <td>5.752406</td>\n",
       "      <td>43.0</td>\n",
       "      <td>-45.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>seg_001</td>\n",
       "      <td>1.179697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>121.0</td>\n",
       "      <td>4.404168</td>\n",
       "      <td>-121.0</td>\n",
       "      <td>7.697447</td>\n",
       "      <td>48.0</td>\n",
       "      <td>-48.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>seg_0010</td>\n",
       "      <td>0.257296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>139.0</td>\n",
       "      <td>4.376219</td>\n",
       "      <td>-153.0</td>\n",
       "      <td>7.511765</td>\n",
       "      <td>39.0</td>\n",
       "      <td>-38.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>seg_00100</td>\n",
       "      <td>0.992497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>142.0</td>\n",
       "      <td>4.971872</td>\n",
       "      <td>-144.0</td>\n",
       "      <td>6.355934</td>\n",
       "      <td>77.0</td>\n",
       "      <td>-50.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>seg_00101</td>\n",
       "      <td>1.249996</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   acc_max  acc_mean  acc_min     acc_sd  chg_acc_max  chg_acc_min  median_25  \\\n",
       "0    177.0  4.388200   -142.0  13.704961         54.0        -58.0        0.0   \n",
       "1    120.0  4.684589    -89.0   5.752406         43.0        -45.0        2.0   \n",
       "2    121.0  4.404168   -121.0   7.697447         48.0        -48.0        1.0   \n",
       "3    139.0  4.376219   -153.0   7.511765         39.0        -38.0        2.0   \n",
       "4    142.0  4.971872   -144.0   6.355934         77.0        -50.0        3.0   \n",
       "\n",
       "   median_50  median_70 segment_id  time_to_failure  \n",
       "0        4.0        9.0    seg_000         0.273199  \n",
       "1        5.0        7.0    seg_001         1.179697  \n",
       "2        4.0        7.0   seg_0010         0.257296  \n",
       "3        4.0        7.0  seg_00100         0.992497  \n",
       "4        5.0        7.0  seg_00101         1.249996  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Adjust all null or empty fields\n",
    "train_df['acc_max'] = pd.to_numeric(train_df['acc_max'], errors='coerce')\n",
    "train_df['acc_mean'] = pd.to_numeric(train_df['acc_mean'], errors='coerce')\n",
    "train_df['acc_min'] = pd.to_numeric(train_df['acc_min'], errors='coerce')\n",
    "train_df['acc_sd'] = pd.to_numeric(train_df['acc_sd'], errors='coerce')\n",
    "train_df['chg_acc_max'] = pd.to_numeric(train_df['chg_acc_max'], errors='coerce')\n",
    "train_df['chg_acc_min'] = pd.to_numeric(train_df['chg_acc_min'], errors='coerce')\n",
    "train_df['median_25'] = pd.to_numeric(train_df['median_25'], errors='coerce')\n",
    "train_df['median_50'] = pd.to_numeric(train_df['median_50'], errors='coerce')\n",
    "train_df['median_70'] = pd.to_numeric(train_df['median_70'], errors='coerce')\n",
    "train_df['time_to_failure'] = pd.to_numeric(train_df['time_to_failure'], errors='coerce') \n",
    "\n",
    "train_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc_max</th>\n",
       "      <th>acc_mean</th>\n",
       "      <th>acc_min</th>\n",
       "      <th>acc_sd</th>\n",
       "      <th>chg_acc_max</th>\n",
       "      <th>chg_acc_min</th>\n",
       "      <th>median_25</th>\n",
       "      <th>median_50</th>\n",
       "      <th>median_70</th>\n",
       "      <th>time_to_failure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>acc_max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.010459</td>\n",
       "      <td>-0.957949</td>\n",
       "      <td>0.966339</td>\n",
       "      <td>0.975047</td>\n",
       "      <td>-0.963828</td>\n",
       "      <td>-0.374825</td>\n",
       "      <td>-0.016228</td>\n",
       "      <td>0.389353</td>\n",
       "      <td>-0.187054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acc_mean</th>\n",
       "      <td>0.010459</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.003771</td>\n",
       "      <td>0.007734</td>\n",
       "      <td>0.006219</td>\n",
       "      <td>-0.013236</td>\n",
       "      <td>0.517504</td>\n",
       "      <td>0.793778</td>\n",
       "      <td>0.514364</td>\n",
       "      <td>-0.027074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acc_min</th>\n",
       "      <td>-0.957949</td>\n",
       "      <td>-0.003771</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.965153</td>\n",
       "      <td>-0.958507</td>\n",
       "      <td>0.941507</td>\n",
       "      <td>0.372881</td>\n",
       "      <td>0.024360</td>\n",
       "      <td>-0.382099</td>\n",
       "      <td>0.192182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acc_sd</th>\n",
       "      <td>0.966339</td>\n",
       "      <td>0.007734</td>\n",
       "      <td>-0.965153</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.960570</td>\n",
       "      <td>-0.941114</td>\n",
       "      <td>-0.407656</td>\n",
       "      <td>-0.019972</td>\n",
       "      <td>0.421228</td>\n",
       "      <td>-0.216132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chg_acc_max</th>\n",
       "      <td>0.975047</td>\n",
       "      <td>0.006219</td>\n",
       "      <td>-0.958507</td>\n",
       "      <td>0.960570</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.952955</td>\n",
       "      <td>-0.377067</td>\n",
       "      <td>-0.019818</td>\n",
       "      <td>0.388945</td>\n",
       "      <td>-0.194269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chg_acc_min</th>\n",
       "      <td>-0.963828</td>\n",
       "      <td>-0.013236</td>\n",
       "      <td>0.941507</td>\n",
       "      <td>-0.941114</td>\n",
       "      <td>-0.952955</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.357506</td>\n",
       "      <td>0.014549</td>\n",
       "      <td>-0.376322</td>\n",
       "      <td>0.189902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>median_25</th>\n",
       "      <td>-0.374825</td>\n",
       "      <td>0.517504</td>\n",
       "      <td>0.372881</td>\n",
       "      <td>-0.407656</td>\n",
       "      <td>-0.377067</td>\n",
       "      <td>0.357506</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.437623</td>\n",
       "      <td>-0.094731</td>\n",
       "      <td>0.351010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>median_50</th>\n",
       "      <td>-0.016228</td>\n",
       "      <td>0.793778</td>\n",
       "      <td>0.024360</td>\n",
       "      <td>-0.019972</td>\n",
       "      <td>-0.019818</td>\n",
       "      <td>0.014549</td>\n",
       "      <td>0.437623</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.398355</td>\n",
       "      <td>-0.005877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>median_70</th>\n",
       "      <td>0.389353</td>\n",
       "      <td>0.514364</td>\n",
       "      <td>-0.382099</td>\n",
       "      <td>0.421228</td>\n",
       "      <td>0.388945</td>\n",
       "      <td>-0.376322</td>\n",
       "      <td>-0.094731</td>\n",
       "      <td>0.398355</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.381781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time_to_failure</th>\n",
       "      <td>-0.187054</td>\n",
       "      <td>-0.027074</td>\n",
       "      <td>0.192182</td>\n",
       "      <td>-0.216132</td>\n",
       "      <td>-0.194269</td>\n",
       "      <td>0.189902</td>\n",
       "      <td>0.351010</td>\n",
       "      <td>-0.005877</td>\n",
       "      <td>-0.381781</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  acc_max  acc_mean   acc_min    acc_sd  chg_acc_max  \\\n",
       "acc_max          1.000000  0.010459 -0.957949  0.966339     0.975047   \n",
       "acc_mean         0.010459  1.000000 -0.003771  0.007734     0.006219   \n",
       "acc_min         -0.957949 -0.003771  1.000000 -0.965153    -0.958507   \n",
       "acc_sd           0.966339  0.007734 -0.965153  1.000000     0.960570   \n",
       "chg_acc_max      0.975047  0.006219 -0.958507  0.960570     1.000000   \n",
       "chg_acc_min     -0.963828 -0.013236  0.941507 -0.941114    -0.952955   \n",
       "median_25       -0.374825  0.517504  0.372881 -0.407656    -0.377067   \n",
       "median_50       -0.016228  0.793778  0.024360 -0.019972    -0.019818   \n",
       "median_70        0.389353  0.514364 -0.382099  0.421228     0.388945   \n",
       "time_to_failure -0.187054 -0.027074  0.192182 -0.216132    -0.194269   \n",
       "\n",
       "                 chg_acc_min  median_25  median_50  median_70  time_to_failure  \n",
       "acc_max            -0.963828  -0.374825  -0.016228   0.389353        -0.187054  \n",
       "acc_mean           -0.013236   0.517504   0.793778   0.514364        -0.027074  \n",
       "acc_min             0.941507   0.372881   0.024360  -0.382099         0.192182  \n",
       "acc_sd             -0.941114  -0.407656  -0.019972   0.421228        -0.216132  \n",
       "chg_acc_max        -0.952955  -0.377067  -0.019818   0.388945        -0.194269  \n",
       "chg_acc_min         1.000000   0.357506   0.014549  -0.376322         0.189902  \n",
       "median_25           0.357506   1.000000   0.437623  -0.094731         0.351010  \n",
       "median_50           0.014549   0.437623   1.000000   0.398355        -0.005877  \n",
       "median_70          -0.376322  -0.094731   0.398355   1.000000        -0.381781  \n",
       "time_to_failure     0.189902   0.351010  -0.005877  -0.381781         1.000000  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc_max 1\n",
      "acc_mean 1\n",
      "acc_min 1\n",
      "acc_sd 1\n",
      "chg_acc_max 1\n",
      "chg_acc_min 1\n",
      "median_25 1\n",
      "median_50 1\n",
      "median_70 1\n"
     ]
    }
   ],
   "source": [
    "#Check for NAN columns\n",
    "import utility as util\n",
    "columns_numeric = ['acc_max','acc_mean','acc_min','acc_sd','chg_acc_max','chg_acc_min','median_25','median_50','median_70']\n",
    "util.checkNaNColumns(columns_numeric,train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc_max 0\n",
      "acc_mean 0\n",
      "acc_min 0\n",
      "acc_sd 0\n",
      "chg_acc_max 0\n",
      "chg_acc_min 0\n",
      "median_25 0\n",
      "median_50 0\n",
      "median_70 0\n"
     ]
    }
   ],
   "source": [
    "# Remove all NAN columns\n",
    "train_df = train_df.dropna()\n",
    "util.checkNaNColumns(columns_numeric,train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc_max</th>\n",
       "      <th>acc_mean</th>\n",
       "      <th>acc_min</th>\n",
       "      <th>acc_sd</th>\n",
       "      <th>chg_acc_max</th>\n",
       "      <th>chg_acc_min</th>\n",
       "      <th>median_25</th>\n",
       "      <th>median_50</th>\n",
       "      <th>median_70</th>\n",
       "      <th>time_to_failure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>acc_max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.004031</td>\n",
       "      <td>-0.951767</td>\n",
       "      <td>0.885793</td>\n",
       "      <td>0.946427</td>\n",
       "      <td>-0.942081</td>\n",
       "      <td>-0.420476</td>\n",
       "      <td>-0.033080</td>\n",
       "      <td>0.411226</td>\n",
       "      <td>-0.364006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acc_mean</th>\n",
       "      <td>-0.004031</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.013047</td>\n",
       "      <td>-0.007453</td>\n",
       "      <td>-0.007342</td>\n",
       "      <td>0.003002</td>\n",
       "      <td>0.517504</td>\n",
       "      <td>0.793778</td>\n",
       "      <td>0.514364</td>\n",
       "      <td>-0.027074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acc_min</th>\n",
       "      <td>-0.951767</td>\n",
       "      <td>0.013047</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.888018</td>\n",
       "      <td>-0.942059</td>\n",
       "      <td>0.939312</td>\n",
       "      <td>0.429060</td>\n",
       "      <td>0.044998</td>\n",
       "      <td>-0.412485</td>\n",
       "      <td>0.384561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acc_sd</th>\n",
       "      <td>0.885793</td>\n",
       "      <td>-0.007453</td>\n",
       "      <td>-0.888018</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.871678</td>\n",
       "      <td>-0.871991</td>\n",
       "      <td>-0.556041</td>\n",
       "      <td>-0.044575</td>\n",
       "      <td>0.541773</td>\n",
       "      <td>-0.498726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chg_acc_max</th>\n",
       "      <td>0.946427</td>\n",
       "      <td>-0.007342</td>\n",
       "      <td>-0.942059</td>\n",
       "      <td>0.871678</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.929071</td>\n",
       "      <td>-0.413311</td>\n",
       "      <td>-0.035188</td>\n",
       "      <td>0.402426</td>\n",
       "      <td>-0.358404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chg_acc_min</th>\n",
       "      <td>-0.942081</td>\n",
       "      <td>0.003002</td>\n",
       "      <td>0.939312</td>\n",
       "      <td>-0.871991</td>\n",
       "      <td>-0.929071</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.411640</td>\n",
       "      <td>0.032257</td>\n",
       "      <td>-0.403573</td>\n",
       "      <td>0.363730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>median_25</th>\n",
       "      <td>-0.420476</td>\n",
       "      <td>0.517504</td>\n",
       "      <td>0.429060</td>\n",
       "      <td>-0.556041</td>\n",
       "      <td>-0.413311</td>\n",
       "      <td>0.411640</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.437623</td>\n",
       "      <td>-0.094731</td>\n",
       "      <td>0.351010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>median_50</th>\n",
       "      <td>-0.033080</td>\n",
       "      <td>0.793778</td>\n",
       "      <td>0.044998</td>\n",
       "      <td>-0.044575</td>\n",
       "      <td>-0.035188</td>\n",
       "      <td>0.032257</td>\n",
       "      <td>0.437623</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.398355</td>\n",
       "      <td>-0.005877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>median_70</th>\n",
       "      <td>0.411226</td>\n",
       "      <td>0.514364</td>\n",
       "      <td>-0.412485</td>\n",
       "      <td>0.541773</td>\n",
       "      <td>0.402426</td>\n",
       "      <td>-0.403573</td>\n",
       "      <td>-0.094731</td>\n",
       "      <td>0.398355</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.381781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time_to_failure</th>\n",
       "      <td>-0.364006</td>\n",
       "      <td>-0.027074</td>\n",
       "      <td>0.384561</td>\n",
       "      <td>-0.498726</td>\n",
       "      <td>-0.358404</td>\n",
       "      <td>0.363730</td>\n",
       "      <td>0.351010</td>\n",
       "      <td>-0.005877</td>\n",
       "      <td>-0.381781</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  acc_max  acc_mean   acc_min    acc_sd  chg_acc_max  \\\n",
       "acc_max          1.000000 -0.004031 -0.951767  0.885793     0.946427   \n",
       "acc_mean        -0.004031  1.000000  0.013047 -0.007453    -0.007342   \n",
       "acc_min         -0.951767  0.013047  1.000000 -0.888018    -0.942059   \n",
       "acc_sd           0.885793 -0.007453 -0.888018  1.000000     0.871678   \n",
       "chg_acc_max      0.946427 -0.007342 -0.942059  0.871678     1.000000   \n",
       "chg_acc_min     -0.942081  0.003002  0.939312 -0.871991    -0.929071   \n",
       "median_25       -0.420476  0.517504  0.429060 -0.556041    -0.413311   \n",
       "median_50       -0.033080  0.793778  0.044998 -0.044575    -0.035188   \n",
       "median_70        0.411226  0.514364 -0.412485  0.541773     0.402426   \n",
       "time_to_failure -0.364006 -0.027074  0.384561 -0.498726    -0.358404   \n",
       "\n",
       "                 chg_acc_min  median_25  median_50  median_70  time_to_failure  \n",
       "acc_max            -0.942081  -0.420476  -0.033080   0.411226        -0.364006  \n",
       "acc_mean            0.003002   0.517504   0.793778   0.514364        -0.027074  \n",
       "acc_min             0.939312   0.429060   0.044998  -0.412485         0.384561  \n",
       "acc_sd             -0.871991  -0.556041  -0.044575   0.541773        -0.498726  \n",
       "chg_acc_max        -0.929071  -0.413311  -0.035188   0.402426        -0.358404  \n",
       "chg_acc_min         1.000000   0.411640   0.032257  -0.403573         0.363730  \n",
       "median_25           0.411640   1.000000   0.437623  -0.094731         0.351010  \n",
       "median_50           0.032257   0.437623   1.000000   0.398355        -0.005877  \n",
       "median_70          -0.403573  -0.094731   0.398355   1.000000        -0.381781  \n",
       "time_to_failure     0.363730   0.351010  -0.005877  -0.381781         1.000000  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using log transformation as did previously\n",
    "train_df['acc_sd'] = train_df['acc_sd'].apply(lambda x:np.log(x))\n",
    "train_df['chg_acc_max'] = train_df['chg_acc_max'].apply(lambda x:np.log(x))\n",
    "train_df['chg_acc_min'] = train_df['chg_acc_min'].apply(lambda x: np.log(x) if x>0  else -1*np.log(-1*x))\n",
    "train_df['acc_min'] = train_df['acc_min'].apply(lambda x: np.log(x) if x>0  else -1*np.log(-1*x))\n",
    "train_df['acc_max'] = train_df['acc_max'].apply(lambda x: np.log(x) if x>0  else -1*np.log(-1*x))\n",
    "train_df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing Attributes which are not corelated\n",
    "train_df = train_df.drop(['acc_mean','median_50'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data file already exists ..Fitting completed\n",
      "Transformation completed ... \n",
      "Dropping columns  ['acc_mean', 'median_50', 'auc'] ...\n",
      "Min Max Scaler applied ... \n"
     ]
    }
   ],
   "source": [
    "import accoustic_sampler as acs\n",
    "import data_formatter as dtFrm\n",
    "import numpy as np\n",
    "\n",
    "sampler = acs.AccousticSampler('D:/PYTHON_WORKSPACES/Kaggles/EarthquakePrediction/LANL_Earthquake/data/train_data_new')\n",
    "sampler.fit()\n",
    "data_df = sampler.get()\n",
    "# columns_to_drop=columns_to_drop\n",
    "formatter = dtFrm.LANLDataFormatter(data_df=data_df, data_type='train', doTransform=True, doScale=True, cols_to_keep=50)\n",
    "data_df = formatter.transform()\n",
    "\n",
    "# Separate output from inputs\n",
    "y_train = data_df['time_to_failure']\n",
    "x_train_seg = data_df['segment_id']\n",
    "x_train = data_df.drop(['time_to_failure'], axis=1)\n",
    "x_train = data_df.drop(['segment_id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 1000 candidates, totalling 3000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n",
      "[Parallel(n_jobs=3)]: Done  35 tasks      | elapsed:   12.0s\n",
      "[Parallel(n_jobs=3)]: Done 156 tasks      | elapsed:   59.8s\n",
      "[Parallel(n_jobs=3)]: Done 359 tasks      | elapsed: 36.4min\n",
      "[Parallel(n_jobs=3)]: Done 642 tasks      | elapsed: 72.3min\n",
      "[Parallel(n_jobs=3)]: Done 1007 tasks      | elapsed: 109.1min\n",
      "[Parallel(n_jobs=3)]: Done 1452 tasks      | elapsed: 163.1min\n",
      "[Parallel(n_jobs=3)]: Done 1979 tasks      | elapsed: 170.5min\n",
      "[Parallel(n_jobs=3)]: Done 2586 tasks      | elapsed: 214.2min\n",
      "[Parallel(n_jobs=3)]: Done 3000 out of 3000 | elapsed: 284.7min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVR(C=37.08647605824366, cache_size=200, coef0=0.0, degree=2, epsilon=0.001,\n",
       "  gamma=0.000586414861763494, kernel='linear', max_iter=-1, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import reciprocal, uniform\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, make_scorer\n",
    "mae_scorer = make_scorer(mean_absolute_error, greater_is_better=False)\n",
    "\n",
    "param_distributions = {\"gamma\": reciprocal(0.0001, 0.1), \"C\": uniform(1, 50), \"kernel\":['rbf','poly','linear','sigmoid'] \n",
    "                       ,\"max_iter\":[-1],\"degree\":[2,3],\"tol\":[0.001,0.01,0.0001],\"epsilon\":[0.1,0.01,0.001]}\n",
    "rnd_search_cv = RandomizedSearchCV(SVR(), param_distributions, n_iter=1000, verbose=2,n_jobs=3,cv=3, random_state=42,\\\n",
    "                                   scoring=mae_scorer)\n",
    "rnd_search_cv.fit(x_train, y_train)\n",
    "rnd_search_cv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnd_search_cv.cv_results_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVR(C=50.39498941564189, cache_size=200, coef0=0.0, degree=3, epsilon=0.1,\n",
       "  gamma=0.06161049539380964, kernel='rbf', max_iter=-1, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "svReg = SVR(C=50.394989415641891, cache_size=200, coef0=0.0, degree=3, epsilon=0.1,\n",
    "  gamma=0.06161049539380964, kernel='rbf', max_iter=-1, shrinking=True,\n",
    "  tol=0.001, verbose=False)\n",
    "\n",
    "svReg.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.374987652896806"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svReg.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = svReg.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.1188032440094706"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics.regression import mean_absolute_error\n",
    "mean_absolute_error(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well the score is too bad to proceed. Few things we need to look after. Accuracy is around 40% and it seems more than one model might be needed to get better score. Let's try with Random Forest Regressor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data file already exists ..Fitting completed\n",
      "Transformation completed ... \n",
      "Standard Scaler applied ... \n",
      "Dropping columns  ['acc_mean', 'median_50', 'auc'] ...\n"
     ]
    }
   ],
   "source": [
    "import accoustic_sampler as acs\n",
    "\n",
    "degree = 2\n",
    "columns_to_keep = 35\n",
    "\n",
    "sampler = acs.AccousticSampler('D:/PYTHON_WORKSPACES/Kaggles/EarthquakePrediction/LANL_Earthquake/data/train_data_new')\n",
    "sampler.fit()\n",
    "data_df = sampler.get()\n",
    "\n",
    "import data_formatter as dtFrm\n",
    "# This formatter is available within the path and has all formatting techniques used earlier in the notebook. The doTransform parameter \n",
    "# controls weather or not we need to do any logarthmic transformation or not.\n",
    "\n",
    "formatter = dtFrm.LANLDataFormatter(data_df=data_df, data_type='train', doTransform=True,doScale=True)\n",
    "data_df = formatter.transform()\n",
    "\n",
    "corr = data_df.corr()['time_to_failure']\n",
    "most_dependent_columns = corr.abs().nlargest(columns_to_keep + 1, keep='all').index[0:]\n",
    "most_dependent_columns = most_dependent_columns.tolist()\n",
    "most_dependent_columns.append('segment_id')\n",
    "data_df = data_df[most_dependent_columns]\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_set, test_set = train_test_split(data_df, test_size=0.5, random_state=42)\n",
    "# Separate output from inputs\n",
    "y_train = train_set['time_to_failure']\n",
    "x_train_seg = train_set['segment_id']\n",
    "x_train = train_set.drop(['time_to_failure'], axis=1)\n",
    "x_train = x_train.drop(['segment_id'], axis=1)\n",
    "\n",
    "y_test = test_set['time_to_failure']\n",
    "x_test_seg = test_set['segment_id']\n",
    "x_test = test_set.drop(['time_to_failure'], axis=1)\n",
    "x_test = x_test.drop(['segment_id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000],\n",
       " 'max_features': ['auto', 'sqrt', 'log2'],\n",
       " 'max_depth': [10,\n",
       "  20,\n",
       "  30,\n",
       "  40,\n",
       "  50,\n",
       "  60,\n",
       "  70,\n",
       "  80,\n",
       "  90,\n",
       "  100,\n",
       "  110,\n",
       "  120,\n",
       "  130,\n",
       "  140,\n",
       "  150,\n",
       "  160,\n",
       "  170,\n",
       "  180,\n",
       "  190,\n",
       "  200,\n",
       "  None],\n",
       " 'min_samples_split': [2, 5, 10],\n",
       " 'min_samples_leaf': [1, 2, 4],\n",
       " 'bootstrap': [True, False]}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble.forest import RandomForestRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import reciprocal, uniform\n",
    "import numpy as np\n",
    "\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt','log2']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 200, num = 20)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "\n",
    "random_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed: 25.3min\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed: 239.6min\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed: 525.4min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=False, criterion='mse', max_depth=60,\n",
       "           max_features='log2', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=1800, n_jobs=None,\n",
       "           oob_score=False, random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the random grid to search for best hyperparameters\n",
    "# First create the base model to tune\n",
    "rf = RandomForestRegressor()\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
    "# Fit the random search model\n",
    "rf_random.fit(x_train, y_train)\n",
    "rf_random.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data file already exists ..Fitting completed\n",
      "Transformation completed ... \n",
      "Dropping columns  ['acc_mean', 'median_50', 'auc'] ...\n"
     ]
    }
   ],
   "source": [
    "import accoustic_sampler as acs\n",
    "import data_formatter as dtFrm\n",
    "sampler = acs.AccousticSampler('D:/PYTHON_WORKSPACES/Kaggles/EarthquakePrediction/LANL_Earthquake/data/train_data_new')\n",
    "sampler.fit()\n",
    "data_df = sampler.get()\n",
    "\n",
    "formatter = dtFrm.LANLDataFormatter(data_df=data_df, data_type='train', doTransform=True)\n",
    "data_df = formatter.transform()\n",
    "\n",
    "#data_df = data_df.drop(['acc_max','acc_min','chg_acc_max','chg_acc_min'],axis=1)\n",
    "# Splitting data into test_1 and train\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_set, test_set = train_test_split(data_df, test_size=0.2, random_state=42)\n",
    "# Separate output from inputs\n",
    "y_train = train_set['time_to_failure']\n",
    "x_train_seg = train_set['segment_id']\n",
    "x_train = train_set.drop(['time_to_failure'], axis=1)\n",
    "x_train = x_train.drop(['segment_id'], axis=1)\n",
    "\n",
    "y_test = test_set['time_to_failure']\n",
    "x_test_seg = test_set['segment_id']\n",
    "x_test = test_set.drop(['time_to_failure'], axis=1)\n",
    "x_test = x_test.drop(['segment_id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 800\n",
      "building tree 2 of 800\n",
      "building tree 3 of 800\n",
      "building tree 4 of 800\n",
      "building tree 5 of 800\n",
      "building tree 6 of 800\n",
      "building tree 7 of 800\n",
      "building tree 8 of 800\n",
      "building tree 9 of 800\n",
      "building tree 10 of 800\n",
      "building tree 11 of 800\n",
      "building tree 12 of 800\n",
      "building tree 13 of 800\n",
      "building tree 14 of 800\n",
      "building tree 15 of 800\n",
      "building tree 16 of 800\n",
      "building tree 17 of 800\n",
      "building tree 18 of 800\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-41203cb13c77>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m            \u001b[0mmin_weight_fraction_leaf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_estimators\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m800\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m            oob_score=False, random_state=None, verbose=2, warm_start=False)\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mrandForReg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\Anaconda\\envs\\ptc\\lib\\site-packages\\sklearn\\ensemble\\forest.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    331\u001b[0m                     \u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrees\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    332\u001b[0m                     verbose=self.verbose, class_weight=self.class_weight)\n\u001b[1;32m--> 333\u001b[1;33m                 for i, t in enumerate(trees))\n\u001b[0m\u001b[0;32m    334\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    335\u001b[0m             \u001b[1;31m# Collect newly grown trees\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\ptc\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    928\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    929\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 930\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    931\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    932\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\ptc\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    831\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    832\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 833\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    834\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    835\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\ptc\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    675\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    676\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 677\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    678\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mready\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    679\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\ptc\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    672\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    673\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 674\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    675\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    676\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\ptc\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    550\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    551\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 552\u001b[1;33m                 \u001b[0msignaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    553\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    554\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\ptc\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    294\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m    \u001b[1;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    295\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 296\u001b[1;33m                 \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    298\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble.forest import RandomForestRegressor\n",
    "randForReg = RandomForestRegressor(bootstrap=False, criterion='mae', max_depth=170,\n",
    "           max_features='log2', max_leaf_nodes=None,\n",
    "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "           min_samples_leaf=1, min_samples_split=2,\n",
    "           min_weight_fraction_leaf=0.0, n_estimators=800, n_jobs=4,\n",
    "           oob_score=False, random_state=None, verbose=2, warm_start=False)\n",
    "randForReg.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9816723538691756"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "randForReg.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.regression import mean_absolute_error\n",
    "y_pred = randForReg.predict(x_test)\n",
    "mean_absolute_error(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VOILA! This seems pretty good. Our svm score is not great however RandomForest witth 800 estimetors has did the trick. Let's proceed for actula test file. But before that we must train the model with entire data set now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data file already exists ..Fitting completed\n",
      "Train data size  125821\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc_max</th>\n",
       "      <th>acc_min</th>\n",
       "      <th>acc_sd</th>\n",
       "      <th>chg_acc_max</th>\n",
       "      <th>chg_acc_min</th>\n",
       "      <th>median_25</th>\n",
       "      <th>median_70</th>\n",
       "      <th>segment_id</th>\n",
       "      <th>time_to_failure</th>\n",
       "      <th>time_per_max_range</th>\n",
       "      <th>distance</th>\n",
       "      <th>time_per_max_chg_range</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.875197</td>\n",
       "      <td>-4.762174</td>\n",
       "      <td>1.951047</td>\n",
       "      <td>3.688879</td>\n",
       "      <td>-3.555348</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5J8Aoorc</td>\n",
       "      <td>0.718996</td>\n",
       "      <td>0.000686</td>\n",
       "      <td>5.557186</td>\n",
       "      <td>0.002269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.744932</td>\n",
       "      <td>-4.624973</td>\n",
       "      <td>1.883296</td>\n",
       "      <td>3.828641</td>\n",
       "      <td>-3.737670</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4KBrRoSo</td>\n",
       "      <td>0.479596</td>\n",
       "      <td>0.000781</td>\n",
       "      <td>5.456024</td>\n",
       "      <td>0.001926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.025352</td>\n",
       "      <td>-3.912023</td>\n",
       "      <td>1.153917</td>\n",
       "      <td>3.044522</td>\n",
       "      <td>-3.091042</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>jb3Q37EU</td>\n",
       "      <td>0.030598</td>\n",
       "      <td>0.001540</td>\n",
       "      <td>4.739611</td>\n",
       "      <td>0.003796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.709530</td>\n",
       "      <td>-4.744932</td>\n",
       "      <td>1.745552</td>\n",
       "      <td>3.688879</td>\n",
       "      <td>-3.828641</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>ewfS5gDo</td>\n",
       "      <td>1.382997</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>5.488152</td>\n",
       "      <td>0.002102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.976734</td>\n",
       "      <td>-5.087596</td>\n",
       "      <td>1.944435</td>\n",
       "      <td>3.828641</td>\n",
       "      <td>-4.060443</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>dy32aN4v</td>\n",
       "      <td>0.812699</td>\n",
       "      <td>0.000545</td>\n",
       "      <td>5.781167</td>\n",
       "      <td>0.001609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.267858</td>\n",
       "      <td>-5.147494</td>\n",
       "      <td>1.969736</td>\n",
       "      <td>4.094345</td>\n",
       "      <td>-4.127134</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>UjpSjrHG</td>\n",
       "      <td>0.381696</td>\n",
       "      <td>0.000465</td>\n",
       "      <td>5.955314</td>\n",
       "      <td>0.001394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.615121</td>\n",
       "      <td>-4.521789</td>\n",
       "      <td>1.944932</td>\n",
       "      <td>3.663562</td>\n",
       "      <td>-3.610918</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>ER3XKUcI</td>\n",
       "      <td>0.760496</td>\n",
       "      <td>0.000875</td>\n",
       "      <td>5.334768</td>\n",
       "      <td>0.002223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4.094345</td>\n",
       "      <td>-4.007333</td>\n",
       "      <td>1.268534</td>\n",
       "      <td>3.091042</td>\n",
       "      <td>-3.258097</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>PTnwd7Tk</td>\n",
       "      <td>0.189196</td>\n",
       "      <td>0.001417</td>\n",
       "      <td>4.825232</td>\n",
       "      <td>0.003396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5.023881</td>\n",
       "      <td>-4.836282</td>\n",
       "      <td>1.900622</td>\n",
       "      <td>3.931826</td>\n",
       "      <td>-3.828641</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8xz5KcPU</td>\n",
       "      <td>1.090396</td>\n",
       "      <td>0.000647</td>\n",
       "      <td>5.685064</td>\n",
       "      <td>0.001853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4.787492</td>\n",
       "      <td>-4.762174</td>\n",
       "      <td>1.805081</td>\n",
       "      <td>3.688879</td>\n",
       "      <td>-3.526361</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>EmTMzpw1</td>\n",
       "      <td>0.725398</td>\n",
       "      <td>0.000728</td>\n",
       "      <td>5.514574</td>\n",
       "      <td>0.002333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    acc_max   acc_min    acc_sd  chg_acc_max  chg_acc_min  median_25  \\\n",
       "0  4.875197 -4.762174  1.951047     3.688879    -3.555348        2.0   \n",
       "1  4.744932 -4.624973  1.883296     3.828641    -3.737670        2.0   \n",
       "2  4.025352 -3.912023  1.153917     3.044522    -3.091042        2.0   \n",
       "3  4.709530 -4.744932  1.745552     3.688879    -3.828641        2.0   \n",
       "4  4.976734 -5.087596  1.944435     3.828641    -4.060443        2.0   \n",
       "5  5.267858 -5.147494  1.969736     4.094345    -4.127134        2.0   \n",
       "6  4.615121 -4.521789  1.944932     3.663562    -3.610918        2.0   \n",
       "7  4.094345 -4.007333  1.268534     3.091042    -3.258097        2.0   \n",
       "8  5.023881 -4.836282  1.900622     3.931826    -3.828641        2.0   \n",
       "9  4.787492 -4.762174  1.805081     3.688879    -3.526361        2.0   \n",
       "\n",
       "   median_70 segment_id  time_to_failure  time_per_max_range  distance  \\\n",
       "0        7.0   5J8Aoorc         0.718996            0.000686  5.557186   \n",
       "1        7.0   4KBrRoSo         0.479596            0.000781  5.456024   \n",
       "2        6.0   jb3Q37EU         0.030598            0.001540  4.739611   \n",
       "3        7.0   ewfS5gDo         1.382997            0.000800  5.488152   \n",
       "4        7.0   dy32aN4v         0.812699            0.000545  5.781167   \n",
       "5        7.0   UjpSjrHG         0.381696            0.000465  5.955314   \n",
       "6        7.0   ER3XKUcI         0.760496            0.000875  5.334768   \n",
       "7        6.0   PTnwd7Tk         0.189196            0.001417  4.825232   \n",
       "8        7.0   8xz5KcPU         1.090396            0.000647  5.685064   \n",
       "9        7.0   EmTMzpw1         0.725398            0.000728  5.514574   \n",
       "\n",
       "   time_per_max_chg_range  \n",
       "0                0.002269  \n",
       "1                0.001926  \n",
       "2                0.003796  \n",
       "3                0.002102  \n",
       "4                0.001609  \n",
       "5                0.001394  \n",
       "6                0.002223  \n",
       "7                0.003396  \n",
       "8                0.001853  \n",
       "9                0.002333  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import accoustic_sampler as acs\n",
    "import data_formatter as dtFrm\n",
    "sampler = acs.AccousticSampler('D:/PYTHON_WORKSPACES/Kaggles/EarthquakePrediction/LANL_Earthquake/data/train_data_new')\n",
    "sampler.fit()\n",
    "data_df = sampler.get()\n",
    "\n",
    "formatter = dtFrm.LANLDataFormatter(data_df=data_df, data_type='train', doTransform=True)\n",
    "train_df = formatter.transform()\n",
    "print('Train data size ',train_df.shape[0])\n",
    "train_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc_max</th>\n",
       "      <th>acc_min</th>\n",
       "      <th>acc_sd</th>\n",
       "      <th>chg_acc_max</th>\n",
       "      <th>chg_acc_min</th>\n",
       "      <th>median_25</th>\n",
       "      <th>median_70</th>\n",
       "      <th>time_per_max_range</th>\n",
       "      <th>distance</th>\n",
       "      <th>time_per_max_chg_range</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.875197</td>\n",
       "      <td>-4.762174</td>\n",
       "      <td>1.951047</td>\n",
       "      <td>3.688879</td>\n",
       "      <td>-3.555348</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.000686</td>\n",
       "      <td>5.557186</td>\n",
       "      <td>0.002269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.744932</td>\n",
       "      <td>-4.624973</td>\n",
       "      <td>1.883296</td>\n",
       "      <td>3.828641</td>\n",
       "      <td>-3.737670</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.000781</td>\n",
       "      <td>5.456024</td>\n",
       "      <td>0.001926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.025352</td>\n",
       "      <td>-3.912023</td>\n",
       "      <td>1.153917</td>\n",
       "      <td>3.044522</td>\n",
       "      <td>-3.091042</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.001540</td>\n",
       "      <td>4.739611</td>\n",
       "      <td>0.003796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.709530</td>\n",
       "      <td>-4.744932</td>\n",
       "      <td>1.745552</td>\n",
       "      <td>3.688879</td>\n",
       "      <td>-3.828641</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>5.488152</td>\n",
       "      <td>0.002102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.976734</td>\n",
       "      <td>-5.087596</td>\n",
       "      <td>1.944435</td>\n",
       "      <td>3.828641</td>\n",
       "      <td>-4.060443</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.000545</td>\n",
       "      <td>5.781167</td>\n",
       "      <td>0.001609</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    acc_max   acc_min    acc_sd  chg_acc_max  chg_acc_min  median_25  \\\n",
       "0  4.875197 -4.762174  1.951047     3.688879    -3.555348        2.0   \n",
       "1  4.744932 -4.624973  1.883296     3.828641    -3.737670        2.0   \n",
       "2  4.025352 -3.912023  1.153917     3.044522    -3.091042        2.0   \n",
       "3  4.709530 -4.744932  1.745552     3.688879    -3.828641        2.0   \n",
       "4  4.976734 -5.087596  1.944435     3.828641    -4.060443        2.0   \n",
       "\n",
       "   median_70  time_per_max_range  distance  time_per_max_chg_range  \n",
       "0        7.0            0.000686  5.557186                0.002269  \n",
       "1        7.0            0.000781  5.456024                0.001926  \n",
       "2        6.0            0.001540  4.739611                0.003796  \n",
       "3        7.0            0.000800  5.488152                0.002102  \n",
       "4        7.0            0.000545  5.781167                0.001609  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = train_df['time_to_failure']\n",
    "x_train_seg = train_df['segment_id']\n",
    "x_train = train_df.drop(['time_to_failure','segment_id'], axis=1)\n",
    "print('')\n",
    "x_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X Train data size  125821\n",
      "Y Train data size  125821\n",
      "Segment Id data size  125821\n"
     ]
    }
   ],
   "source": [
    "print('X Train data size ',x_train.shape[0])\n",
    "print('Y Train data size ',y_train.shape[0])\n",
    "print('Segment Id data size ',x_train_seg.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 800building tree 2 of 800\n",
      "\n",
      "building tree 3 of 800\n",
      "building tree 4 of 800\n",
      "building tree 5 of 800\n",
      "building tree 6 of 800\n",
      "building tree 7 of 800\n",
      "building tree 8 of 800\n",
      "building tree 9 of 800\n",
      "building tree 10 of 800\n",
      "building tree 11 of 800\n",
      "building tree 12 of 800\n",
      "building tree 13 of 800\n",
      "building tree 14 of 800\n",
      "building tree 15 of 800\n",
      "building tree 16 of 800\n",
      "building tree 17 of 800\n",
      "building tree 18 of 800\n",
      "building tree 19 of 800\n",
      "building tree 20 of 800\n",
      "building tree 21 of 800\n",
      "building tree 22 of 800\n",
      "building tree 23 of 800\n",
      "building tree 24 of 800\n",
      "building tree 25 of 800\n",
      "building tree 26 of 800\n",
      "building tree 27 of 800\n",
      "building tree 28 of 800\n",
      "building tree 29 of 800\n",
      "building tree 30 of 800\n",
      "building tree 31 of 800\n",
      "building tree 32 of 800\n",
      "building tree 33 of 800\n",
      "building tree 34 of 800\n",
      "building tree 35 of 800\n",
      "building tree 36 of 800\n",
      "building tree 37 of 800\n",
      "building tree 38 of 800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  33 tasks      | elapsed:    4.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 39 of 800\n",
      "building tree 40 of 800\n",
      "building tree 41 of 800\n",
      "building tree 42 of 800\n",
      "building tree 43 of 800\n",
      "building tree 44 of 800\n",
      "building tree 45 of 800\n",
      "building tree 46 of 800\n",
      "building tree 47 of 800\n",
      "building tree 48 of 800\n",
      "building tree 49 of 800\n",
      "building tree 50 of 800\n",
      "building tree 51 of 800\n",
      "building tree 52 of 800\n",
      "building tree 53 of 800\n",
      "building tree 54 of 800\n",
      "building tree 55 of 800\n",
      "building tree 56 of 800\n",
      "building tree 57 of 800\n",
      "building tree 58 of 800\n",
      "building tree 59 of 800\n",
      "building tree 60 of 800\n",
      "building tree 61 of 800\n",
      "building tree 62 of 800\n",
      "building tree 63 of 800\n",
      "building tree 64 of 800\n",
      "building tree 65 of 800\n",
      "building tree 66 of 800\n",
      "building tree 67 of 800\n",
      "building tree 68 of 800\n",
      "building tree 69 of 800\n",
      "building tree 70 of 800\n",
      "building tree 71 of 800\n",
      "building tree 72 of 800\n",
      "building tree 73 of 800\n",
      "building tree 74 of 800\n",
      "building tree 75 of 800\n",
      "building tree 76 of 800\n",
      "building tree 77 of 800\n",
      "building tree 78 of 800\n",
      "building tree 79 of 800\n",
      "building tree 80 of 800\n",
      "building tree 81 of 800\n",
      "building tree 82 of 800\n",
      "building tree 83 of 800\n",
      "building tree 84 of 800\n",
      "building tree 85 of 800\n",
      "building tree 86 of 800\n",
      "building tree 87 of 800\n",
      "building tree 88 of 800\n",
      "building tree 89 of 800\n",
      "building tree 90 of 800\n",
      "building tree 91 of 800\n",
      "building tree 92 of 800\n",
      "building tree 93 of 800\n",
      "building tree 94 of 800\n",
      "building tree 95 of 800\n",
      "building tree 96 of 800\n",
      "building tree 97 of 800\n",
      "building tree 98 of 800\n",
      "building tree 99 of 800\n",
      "building tree 100 of 800\n",
      "building tree 101 of 800\n",
      "building tree 102 of 800\n",
      "building tree 103 of 800\n",
      "building tree 104 of 800\n",
      "building tree 105 of 800\n",
      "building tree 106 of 800\n",
      "building tree 107 of 800\n",
      "building tree 108 of 800\n",
      "building tree 109 of 800\n",
      "building tree 110 of 800\n",
      "building tree 111 of 800\n",
      "building tree 112 of 800\n",
      "building tree 113 of 800\n",
      "building tree 114 of 800\n",
      "building tree 115 of 800\n",
      "building tree 116 of 800\n",
      "building tree 117 of 800\n",
      "building tree 118 of 800\n",
      "building tree 119 of 800\n",
      "building tree 120 of 800\n",
      "building tree 121 of 800\n",
      "building tree 122 of 800\n",
      "building tree 123 of 800\n",
      "building tree 124 of 800\n",
      "building tree 125 of 800\n",
      "building tree 126 of 800\n",
      "building tree 127 of 800\n",
      "building tree 128 of 800\n",
      "building tree 129 of 800\n",
      "building tree 130 of 800\n",
      "building tree 131 of 800\n",
      "building tree 132 of 800\n",
      "building tree 133 of 800\n",
      "building tree 134 of 800\n",
      "building tree 135 of 800\n",
      "building tree 136 of 800\n",
      "building tree 137 of 800\n",
      "building tree 138 of 800\n",
      "building tree 139 of 800\n",
      "building tree 140 of 800\n",
      "building tree 141 of 800\n",
      "building tree 142 of 800\n",
      "building tree 143 of 800\n",
      "building tree 144 of 800\n",
      "building tree 145 of 800\n",
      "building tree 146 of 800\n",
      "building tree 147 of 800\n",
      "building tree 148 of 800\n",
      "building tree 149 of 800\n",
      "building tree 150 of 800\n",
      "building tree 151 of 800\n",
      "building tree 152 of 800\n",
      "building tree 153 of 800\n",
      "building tree 154 of 800\n",
      "building tree 155 of 800\n",
      "building tree 156 of 800\n",
      "building tree 157 of 800\n",
      "building tree 158 of 800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done 154 tasks      | elapsed:   19.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 159 of 800\n",
      "building tree 160 of 800\n",
      "building tree 161 of 800\n",
      "building tree 162 of 800\n",
      "building tree 163 of 800\n",
      "building tree 164 of 800\n",
      "building tree 165 of 800\n",
      "building tree 166 of 800\n",
      "building tree 167 of 800\n",
      "building tree 168 of 800\n",
      "building tree 169 of 800\n",
      "building tree 170 of 800\n",
      "building tree 171 of 800\n",
      "building tree 172 of 800\n",
      "building tree 173 of 800\n",
      "building tree 174 of 800\n",
      "building tree 175 of 800\n",
      "building tree 176 of 800\n",
      "building tree 177 of 800\n",
      "building tree 178 of 800\n",
      "building tree 179 of 800\n",
      "building tree 180 of 800\n",
      "building tree 181 of 800\n",
      "building tree 182 of 800\n",
      "building tree 183 of 800\n",
      "building tree 184 of 800\n",
      "building tree 185 of 800\n",
      "building tree 186 of 800\n",
      "building tree 187 of 800\n",
      "building tree 188 of 800\n",
      "building tree 189 of 800\n",
      "building tree 190 of 800\n",
      "building tree 191 of 800\n",
      "building tree 192 of 800\n",
      "building tree 193 of 800\n",
      "building tree 194 of 800\n",
      "building tree 195 of 800\n",
      "building tree 196 of 800\n",
      "building tree 197 of 800\n",
      "building tree 198 of 800\n",
      "building tree 199 of 800\n",
      "building tree 200 of 800\n",
      "building tree 201 of 800\n",
      "building tree 202 of 800\n",
      "building tree 203 of 800\n",
      "building tree 204 of 800\n",
      "building tree 205 of 800\n",
      "building tree 206 of 800\n",
      "building tree 207 of 800\n",
      "building tree 208 of 800\n",
      "building tree 209 of 800\n",
      "building tree 210 of 800\n",
      "building tree 211 of 800\n",
      "building tree 212 of 800\n",
      "building tree 213 of 800\n",
      "building tree 214 of 800\n",
      "building tree 215 of 800\n",
      "building tree 216 of 800\n",
      "building tree 217 of 800\n",
      "building tree 218 of 800\n",
      "building tree 219 of 800\n",
      "building tree 220 of 800\n",
      "building tree 221 of 800\n",
      "building tree 222 of 800\n",
      "building tree 223 of 800\n",
      "building tree 224 of 800\n",
      "building tree 225 of 800\n",
      "building tree 226 of 800\n",
      "building tree 227 of 800\n",
      "building tree 228 of 800\n",
      "building tree 229 of 800\n",
      "building tree 230 of 800\n",
      "building tree 231 of 800\n",
      "building tree 232 of 800\n",
      "building tree 233 of 800\n",
      "building tree 234 of 800\n",
      "building tree 235 of 800\n",
      "building tree 236 of 800\n",
      "building tree 237 of 800\n",
      "building tree 238 of 800\n",
      "building tree 239 of 800\n",
      "building tree 240 of 800\n",
      "building tree 241 of 800\n",
      "building tree 242 of 800\n",
      "building tree 243 of 800\n",
      "building tree 244 of 800\n",
      "building tree 245 of 800\n",
      "building tree 246 of 800\n",
      "building tree 247 of 800\n",
      "building tree 248 of 800\n",
      "building tree 249 of 800\n",
      "building tree 250 of 800\n",
      "building tree 251 of 800\n",
      "building tree 252 of 800\n",
      "building tree 253 of 800\n",
      "building tree 254 of 800\n",
      "building tree 255 of 800\n",
      "building tree 256 of 800\n",
      "building tree 257 of 800\n",
      "building tree 258 of 800\n",
      "building tree 259 of 800\n",
      "building tree 260 of 800\n",
      "building tree 261 of 800\n",
      "building tree 262 of 800\n",
      "building tree 263 of 800\n",
      "building tree 264 of 800\n",
      "building tree 265 of 800\n",
      "building tree 266 of 800\n",
      "building tree 267 of 800\n",
      "building tree 268 of 800\n",
      "building tree 269 of 800\n",
      "building tree 270 of 800\n",
      "building tree 271 of 800\n",
      "building tree 272 of 800\n",
      "building tree 273 of 800\n",
      "building tree 274 of 800\n",
      "building tree 275 of 800\n",
      "building tree 276 of 800\n",
      "building tree 277 of 800\n",
      "building tree 278 of 800\n",
      "building tree 279 of 800\n",
      "building tree 280 of 800\n",
      "building tree 281 of 800\n",
      "building tree 282 of 800\n",
      "building tree 283 of 800\n",
      "building tree 284 of 800\n",
      "building tree 285 of 800\n",
      "building tree 286 of 800\n",
      "building tree 287 of 800\n",
      "building tree 288 of 800\n",
      "building tree 289 of 800\n",
      "building tree 290 of 800\n",
      "building tree 291 of 800\n",
      "building tree 292 of 800\n",
      "building tree 293 of 800\n",
      "building tree 294 of 800\n",
      "building tree 295 of 800\n",
      "building tree 296 of 800\n",
      "building tree 297 of 800\n",
      "building tree 298 of 800\n",
      "building tree 299 of 800\n",
      "building tree 300 of 800\n",
      "building tree 301 of 800\n",
      "building tree 302 of 800\n",
      "building tree 303 of 800\n",
      "building tree 304 of 800\n",
      "building tree 305 of 800\n",
      "building tree 306 of 800\n",
      "building tree 307 of 800\n",
      "building tree 308 of 800\n",
      "building tree 309 of 800\n",
      "building tree 310 of 800\n",
      "building tree 311 of 800\n",
      "building tree 312 of 800\n",
      "building tree 313 of 800\n",
      "building tree 314 of 800\n",
      "building tree 315 of 800\n",
      "building tree 316 of 800\n",
      "building tree 317 of 800\n",
      "building tree 318 of 800\n",
      "building tree 319 of 800\n",
      "building tree 320 of 800\n",
      "building tree 321 of 800\n",
      "building tree 322 of 800\n",
      "building tree 323 of 800\n",
      "building tree 324 of 800\n",
      "building tree 325 of 800\n",
      "building tree 326 of 800\n",
      "building tree 327 of 800\n",
      "building tree 328 of 800\n",
      "building tree 329 of 800\n",
      "building tree 330 of 800\n",
      "building tree 331 of 800\n",
      "building tree 332 of 800\n",
      "building tree 333 of 800\n",
      "building tree 334 of 800\n",
      "building tree 335 of 800\n",
      "building tree 336 of 800\n",
      "building tree 337 of 800\n",
      "building tree 338 of 800\n",
      "building tree 339 of 800\n",
      "building tree 340 of 800\n",
      "building tree 341 of 800\n",
      "building tree 342 of 800\n",
      "building tree 343 of 800\n",
      "building tree 344 of 800\n",
      "building tree 345 of 800\n",
      "building tree 346 of 800\n",
      "building tree 347 of 800\n",
      "building tree 348 of 800\n",
      "building tree 349 of 800\n",
      "building tree 350 of 800\n",
      "building tree 351 of 800\n",
      "building tree 352 of 800\n",
      "building tree 353 of 800\n",
      "building tree 354 of 800\n",
      "building tree 355 of 800\n",
      "building tree 356 of 800\n",
      "building tree 357 of 800\n",
      "building tree 358 of 800\n",
      "building tree 359 of 800\n",
      "building tree 360 of 800\n",
      "building tree 361 of 800\n",
      "building tree 362 of 800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done 357 tasks      | elapsed:   46.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 363 of 800\n",
      "building tree 364 of 800\n",
      "building tree 365 of 800\n",
      "building tree 366 of 800\n",
      "building tree 367 of 800\n",
      "building tree 368 of 800\n",
      "building tree 369 of 800\n",
      "building tree 370 of 800\n",
      "building tree 371 of 800\n",
      "building tree 372 of 800\n",
      "building tree 373 of 800\n",
      "building tree 374 of 800\n",
      "building tree 375 of 800\n",
      "building tree 376 of 800\n",
      "building tree 377 of 800\n",
      "building tree 378 of 800\n",
      "building tree 379 of 800\n",
      "building tree 380 of 800\n",
      "building tree 381 of 800\n",
      "building tree 382 of 800\n",
      "building tree 383 of 800\n",
      "building tree 384 of 800\n",
      "building tree 385 of 800\n",
      "building tree 386 of 800\n",
      "building tree 387 of 800\n",
      "building tree 388 of 800\n",
      "building tree 389 of 800\n",
      "building tree 390 of 800\n",
      "building tree 391 of 800\n",
      "building tree 392 of 800\n",
      "building tree 393 of 800\n",
      "building tree 394 of 800\n",
      "building tree 395 of 800\n",
      "building tree 396 of 800\n",
      "building tree 397 of 800\n",
      "building tree 398 of 800\n",
      "building tree 399 of 800\n",
      "building tree 400 of 800\n",
      "building tree 401 of 800\n",
      "building tree 402 of 800\n",
      "building tree 403 of 800\n",
      "building tree 404 of 800\n",
      "building tree 405 of 800\n",
      "building tree 406 of 800\n",
      "building tree 407 of 800\n",
      "building tree 408 of 800\n",
      "building tree 409 of 800\n",
      "building tree 410 of 800\n",
      "building tree 411 of 800\n",
      "building tree 412 of 800\n",
      "building tree 413 of 800\n",
      "building tree 414 of 800\n",
      "building tree 415 of 800\n",
      "building tree 416 of 800\n",
      "building tree 417 of 800\n",
      "building tree 418 of 800\n",
      "building tree 419 of 800\n",
      "building tree 420 of 800\n",
      "building tree 421 of 800\n",
      "building tree 422 of 800\n",
      "building tree 423 of 800\n",
      "building tree 424 of 800\n",
      "building tree 425 of 800\n",
      "building tree 426 of 800\n",
      "building tree 427 of 800\n",
      "building tree 428 of 800\n",
      "building tree 429 of 800\n",
      "building tree 430 of 800\n",
      "building tree 431 of 800\n",
      "building tree 432 of 800\n",
      "building tree 433 of 800\n",
      "building tree 434 of 800\n",
      "building tree 435 of 800\n",
      "building tree 436 of 800\n",
      "building tree 437 of 800\n",
      "building tree 438 of 800\n",
      "building tree 439 of 800\n",
      "building tree 440 of 800\n",
      "building tree 441 of 800\n",
      "building tree 442 of 800\n",
      "building tree 443 of 800\n",
      "building tree 444 of 800\n",
      "building tree 445 of 800\n",
      "building tree 446 of 800\n",
      "building tree 447 of 800\n",
      "building tree 448 of 800\n",
      "building tree 449 of 800\n",
      "building tree 450 of 800\n",
      "building tree 451 of 800\n",
      "building tree 452 of 800\n",
      "building tree 453 of 800\n",
      "building tree 454 of 800\n",
      "building tree 455 of 800\n",
      "building tree 456 of 800\n",
      "building tree 457 of 800\n",
      "building tree 458 of 800\n",
      "building tree 459 of 800\n",
      "building tree 460 of 800\n",
      "building tree 461 of 800\n",
      "building tree 462 of 800\n",
      "building tree 463 of 800\n",
      "building tree 464 of 800\n",
      "building tree 465 of 800\n",
      "building tree 466 of 800\n",
      "building tree 467 of 800\n",
      "building tree 468 of 800\n",
      "building tree 469 of 800\n",
      "building tree 470 of 800\n",
      "building tree 471 of 800\n",
      "building tree 472 of 800\n",
      "building tree 473 of 800\n",
      "building tree 474 of 800\n",
      "building tree 475 of 800\n",
      "building tree 476 of 800\n",
      "building tree 477 of 800\n",
      "building tree 478 of 800\n",
      "building tree 479 of 800\n",
      "building tree 480 of 800\n",
      "building tree 481 of 800\n",
      "building tree 482 of 800\n",
      "building tree 483 of 800\n",
      "building tree 484 of 800\n",
      "building tree 485 of 800\n",
      "building tree 486 of 800\n",
      "building tree 487 of 800\n",
      "building tree 488 of 800\n",
      "building tree 489 of 800\n",
      "building tree 490 of 800\n",
      "building tree 491 of 800\n",
      "building tree 492 of 800\n",
      "building tree 493 of 800\n",
      "building tree 494 of 800\n",
      "building tree 495 of 800\n",
      "building tree 496 of 800\n",
      "building tree 497 of 800\n",
      "building tree 498 of 800\n",
      "building tree 499 of 800\n",
      "building tree 500 of 800\n",
      "building tree 501 of 800\n",
      "building tree 502 of 800\n",
      "building tree 503 of 800\n",
      "building tree 504 of 800\n",
      "building tree 505 of 800\n",
      "building tree 506 of 800\n",
      "building tree 507 of 800\n",
      "building tree 508 of 800\n",
      "building tree 509 of 800\n",
      "building tree 510 of 800\n",
      "building tree 511 of 800\n",
      "building tree 512 of 800\n",
      "building tree 513 of 800\n",
      "building tree 514 of 800\n",
      "building tree 515 of 800\n",
      "building tree 516 of 800\n",
      "building tree 517 of 800\n",
      "building tree 518 of 800\n",
      "building tree 519 of 800\n",
      "building tree 520 of 800\n",
      "building tree 521 of 800\n",
      "building tree 522 of 800\n",
      "building tree 523 of 800\n",
      "building tree 524 of 800\n",
      "building tree 525 of 800\n",
      "building tree 526 of 800\n",
      "building tree 527 of 800\n",
      "building tree 528 of 800\n",
      "building tree 529 of 800\n",
      "building tree 530 of 800\n",
      "building tree 531 of 800\n",
      "building tree 532 of 800\n",
      "building tree 533 of 800\n",
      "building tree 534 of 800\n",
      "building tree 535 of 800\n",
      "building tree 536 of 800\n",
      "building tree 537 of 800\n",
      "building tree 538 of 800\n",
      "building tree 539 of 800\n",
      "building tree 540 of 800\n",
      "building tree 541 of 800\n",
      "building tree 542 of 800\n",
      "building tree 543 of 800\n",
      "building tree 544 of 800\n",
      "building tree 545 of 800\n",
      "building tree 546 of 800\n",
      "building tree 547 of 800\n",
      "building tree 548 of 800\n",
      "building tree 549 of 800\n",
      "building tree 550 of 800\n",
      "building tree 551 of 800\n",
      "building tree 552 of 800\n",
      "building tree 553 of 800\n",
      "building tree 554 of 800\n",
      "building tree 555 of 800\n",
      "building tree 556 of 800\n",
      "building tree 557 of 800\n",
      "building tree 558 of 800\n",
      "building tree 559 of 800\n",
      "building tree 560 of 800\n",
      "building tree 561 of 800\n",
      "building tree 562 of 800\n",
      "building tree 563 of 800\n",
      "building tree 564 of 800\n",
      "building tree 565 of 800\n",
      "building tree 566 of 800\n",
      "building tree 567 of 800\n",
      "building tree 568 of 800\n",
      "building tree 569 of 800\n",
      "building tree 570 of 800\n",
      "building tree 571 of 800\n",
      "building tree 572 of 800\n",
      "building tree 573 of 800\n",
      "building tree 574 of 800\n",
      "building tree 575 of 800\n",
      "building tree 576 of 800\n",
      "building tree 577 of 800\n",
      "building tree 578 of 800\n",
      "building tree 579 of 800\n",
      "building tree 580 of 800\n",
      "building tree 581 of 800\n",
      "building tree 582 of 800\n",
      "building tree 583 of 800\n",
      "building tree 584 of 800\n",
      "building tree 585 of 800\n",
      "building tree 586 of 800\n",
      "building tree 587 of 800\n",
      "building tree 588 of 800\n",
      "building tree 589 of 800\n",
      "building tree 590 of 800\n",
      "building tree 591 of 800\n",
      "building tree 592 of 800\n",
      "building tree 593 of 800\n",
      "building tree 594 of 800\n",
      "building tree 595 of 800\n",
      "building tree 596 of 800\n",
      "building tree 597 of 800\n",
      "building tree 598 of 800\n",
      "building tree 599 of 800\n",
      "building tree 600 of 800\n",
      "building tree 601 of 800\n",
      "building tree 602 of 800\n",
      "building tree 603 of 800\n",
      "building tree 604 of 800\n",
      "building tree 605 of 800\n",
      "building tree 606 of 800\n",
      "building tree 607 of 800\n",
      "building tree 608 of 800\n",
      "building tree 609 of 800\n",
      "building tree 610 of 800\n",
      "building tree 611 of 800\n",
      "building tree 612 of 800\n",
      "building tree 613 of 800\n",
      "building tree 614 of 800\n",
      "building tree 615 of 800\n",
      "building tree 616 of 800\n",
      "building tree 617 of 800\n",
      "building tree 618 of 800\n",
      "building tree 619 of 800\n",
      "building tree 620 of 800\n",
      "building tree 621 of 800\n",
      "building tree 622 of 800\n",
      "building tree 623 of 800\n",
      "building tree 624 of 800\n",
      "building tree 625 of 800\n",
      "building tree 626 of 800\n",
      "building tree 627 of 800\n",
      "building tree 628 of 800\n",
      "building tree 629 of 800\n",
      "building tree 630 of 800\n",
      "building tree 631 of 800\n",
      "building tree 632 of 800\n",
      "building tree 633 of 800\n",
      "building tree 634 of 800\n",
      "building tree 635 of 800\n",
      "building tree 636 of 800\n",
      "building tree 637 of 800\n",
      "building tree 638 of 800\n",
      "building tree 639 of 800\n",
      "building tree 640 of 800\n",
      "building tree 641 of 800\n",
      "building tree 642 of 800\n",
      "building tree 643 of 800\n",
      "building tree 644 of 800\n",
      "building tree 645 of 800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done 640 tasks      | elapsed:  1.5min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 646 of 800\n",
      "building tree 647 of 800\n",
      "building tree 648 of 800\n",
      "building tree 649 of 800\n",
      "building tree 650 of 800\n",
      "building tree 651 of 800\n",
      "building tree 652 of 800\n",
      "building tree 653 of 800\n",
      "building tree 654 of 800\n",
      "building tree 655 of 800\n",
      "building tree 656 of 800\n",
      "building tree 657 of 800\n",
      "building tree 658 of 800\n",
      "building tree 659 of 800\n",
      "building tree 660 of 800\n",
      "building tree 661 of 800\n",
      "building tree 662 of 800\n",
      "building tree 663 of 800\n",
      "building tree 664 of 800\n",
      "building tree 665 of 800\n",
      "building tree 666 of 800\n",
      "building tree 667 of 800\n",
      "building tree 668 of 800\n",
      "building tree 669 of 800\n",
      "building tree 670 of 800\n",
      "building tree 671 of 800\n",
      "building tree 672 of 800\n",
      "building tree 673 of 800\n",
      "building tree 674 of 800\n",
      "building tree 675 of 800\n",
      "building tree 676 of 800\n",
      "building tree 677 of 800\n",
      "building tree 678 of 800\n",
      "building tree 679 of 800\n",
      "building tree 680 of 800\n",
      "building tree 681 of 800\n",
      "building tree 682 of 800\n",
      "building tree 683 of 800\n",
      "building tree 684 of 800\n",
      "building tree 685 of 800\n",
      "building tree 686 of 800\n",
      "building tree 687 of 800\n",
      "building tree 688 of 800\n",
      "building tree 689 of 800\n",
      "building tree 690 of 800\n",
      "building tree 691 of 800\n",
      "building tree 692 of 800\n",
      "building tree 693 of 800\n",
      "building tree 694 of 800\n",
      "building tree 695 of 800\n",
      "building tree 696 of 800\n",
      "building tree 697 of 800\n",
      "building tree 698 of 800\n",
      "building tree 699 of 800\n",
      "building tree 700 of 800\n",
      "building tree 701 of 800\n",
      "building tree 702 of 800\n",
      "building tree 703 of 800\n",
      "building tree 704 of 800\n",
      "building tree 705 of 800\n",
      "building tree 706 of 800\n",
      "building tree 707 of 800\n",
      "building tree 708 of 800\n",
      "building tree 709 of 800\n",
      "building tree 710 of 800\n",
      "building tree 711 of 800\n",
      "building tree 712 of 800\n",
      "building tree 713 of 800\n",
      "building tree 714 of 800\n",
      "building tree 715 of 800\n",
      "building tree 716 of 800\n",
      "building tree 717 of 800\n",
      "building tree 718 of 800\n",
      "building tree 719 of 800\n",
      "building tree 720 of 800\n",
      "building tree 721 of 800\n",
      "building tree 722 of 800\n",
      "building tree 723 of 800\n",
      "building tree 724 of 800\n",
      "building tree 725 of 800\n",
      "building tree 726 of 800\n",
      "building tree 727 of 800\n",
      "building tree 728 of 800\n",
      "building tree 729 of 800\n",
      "building tree 730 of 800\n",
      "building tree 731 of 800\n",
      "building tree 732 of 800\n",
      "building tree 733 of 800\n",
      "building tree 734 of 800\n",
      "building tree 735 of 800\n",
      "building tree 736 of 800\n",
      "building tree 737 of 800\n",
      "building tree 738 of 800\n",
      "building tree 739 of 800\n",
      "building tree 740 of 800\n",
      "building tree 741 of 800\n",
      "building tree 742 of 800\n",
      "building tree 743 of 800\n",
      "building tree 744 of 800\n",
      "building tree 745 of 800\n",
      "building tree 746 of 800\n",
      "building tree 747 of 800\n",
      "building tree 748 of 800\n",
      "building tree 749 of 800\n",
      "building tree 750 of 800\n",
      "building tree 751 of 800\n",
      "building tree 752 of 800\n",
      "building tree 753 of 800\n",
      "building tree 754 of 800\n",
      "building tree 755 of 800\n",
      "building tree 756 of 800\n",
      "building tree 757 of 800\n",
      "building tree 758 of 800\n",
      "building tree 759 of 800\n",
      "building tree 760 of 800\n",
      "building tree 761 of 800\n",
      "building tree 762 of 800\n",
      "building tree 763 of 800\n",
      "building tree 764 of 800\n",
      "building tree 765 of 800\n",
      "building tree 766 of 800\n",
      "building tree 767 of 800\n",
      "building tree 768 of 800\n",
      "building tree 769 of 800\n",
      "building tree 770 of 800\n",
      "building tree 771 of 800\n",
      "building tree 772 of 800\n",
      "building tree 773 of 800\n",
      "building tree 774 of 800\n",
      "building tree 775 of 800\n",
      "building tree 776 of 800\n",
      "building tree 777 of 800\n",
      "building tree 778 of 800\n",
      "building tree 779 of 800\n",
      "building tree 780 of 800\n",
      "building tree 781 of 800\n",
      "building tree 782 of 800\n",
      "building tree 783 of 800\n",
      "building tree 784 of 800\n",
      "building tree 785 of 800\n",
      "building tree 786 of 800\n",
      "building tree 787 of 800\n",
      "building tree 788 of 800\n",
      "building tree 789 of 800\n",
      "building tree 790 of 800\n",
      "building tree 791 of 800\n",
      "building tree 792 of 800\n",
      "building tree 793 of 800\n",
      "building tree 794 of 800\n",
      "building tree 795 of 800\n",
      "building tree 796 of 800\n",
      "building tree 797 of 800\n",
      "building tree 798 of 800\n",
      "building tree 799 of 800\n",
      "building tree 800 of 800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done 800 out of 800 | elapsed:  2.0min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=False, criterion='mse', max_depth=100,\n",
       "           max_features='sqrt', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=5,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=800, n_jobs=4,\n",
       "           oob_score=False, random_state=None, verbose=2, warm_start=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's train our model without any splitting\n",
    "from sklearn.ensemble.forest import RandomForestRegressor\n",
    "randForReg = RandomForestRegressor(bootstrap=False, criterion='mse', max_depth=100,\n",
    "           max_features='sqrt', max_leaf_nodes=None,\n",
    "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "           min_samples_leaf=1, min_samples_split=5,\n",
    "           min_weight_fraction_leaf=0.0, n_estimators=800, n_jobs=4,\n",
    "           oob_score=False, random_state=None, verbose=2, warm_start=False)\n",
    "randForReg.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to prepare our test set in order to fit it into the model. Same sampler class can be used with following parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data file already exists ..Fitting completed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc_max</th>\n",
       "      <th>acc_mean</th>\n",
       "      <th>acc_min</th>\n",
       "      <th>acc_sd</th>\n",
       "      <th>auc</th>\n",
       "      <th>chg_acc_max</th>\n",
       "      <th>chg_acc_min</th>\n",
       "      <th>median_25</th>\n",
       "      <th>median_50</th>\n",
       "      <th>median_70</th>\n",
       "      <th>segment_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>115.0</td>\n",
       "      <td>4.491780</td>\n",
       "      <td>-75.0</td>\n",
       "      <td>4.893690</td>\n",
       "      <td>0.168440</td>\n",
       "      <td>29.0</td>\n",
       "      <td>-27.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>seg_00030f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>152.0</td>\n",
       "      <td>4.171153</td>\n",
       "      <td>-140.0</td>\n",
       "      <td>5.922839</td>\n",
       "      <td>0.156417</td>\n",
       "      <td>39.0</td>\n",
       "      <td>-52.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>seg_0012b5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>248.0</td>\n",
       "      <td>4.610260</td>\n",
       "      <td>-193.0</td>\n",
       "      <td>6.946990</td>\n",
       "      <td>0.172883</td>\n",
       "      <td>56.0</td>\n",
       "      <td>-70.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>seg_00184e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>85.0</td>\n",
       "      <td>4.531473</td>\n",
       "      <td>-93.0</td>\n",
       "      <td>4.114147</td>\n",
       "      <td>0.169929</td>\n",
       "      <td>37.0</td>\n",
       "      <td>-30.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>seg_003339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>177.0</td>\n",
       "      <td>4.128340</td>\n",
       "      <td>-147.0</td>\n",
       "      <td>5.797164</td>\n",
       "      <td>0.154812</td>\n",
       "      <td>58.0</td>\n",
       "      <td>-46.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>seg_0042cc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   acc_max  acc_mean  acc_min    acc_sd       auc  chg_acc_max  chg_acc_min  \\\n",
       "0    115.0  4.491780    -75.0  4.893690  0.168440         29.0        -27.0   \n",
       "1    152.0  4.171153   -140.0  5.922839  0.156417         39.0        -52.0   \n",
       "2    248.0  4.610260   -193.0  6.946990  0.172883         56.0        -70.0   \n",
       "3     85.0  4.531473    -93.0  4.114147  0.169929         37.0        -30.0   \n",
       "4    177.0  4.128340   -147.0  5.797164  0.154812         58.0        -46.0   \n",
       "\n",
       "   median_25  median_50  median_70  segment_id  \n",
       "0        2.0        4.0        7.0  seg_00030f  \n",
       "1        2.0        4.0        7.0  seg_0012b5  \n",
       "2        2.0        5.0        7.0  seg_00184e  \n",
       "3        3.0        5.0        7.0  seg_003339  \n",
       "4        2.0        4.0        6.0  seg_0042cc  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import accoustic_sampler as acs\n",
    "\n",
    "sampler = acs.AccousticSampler('D:/PYTHON_WORKSPACES/Kaggles/EarthquakePrediction/LANL_Earthquake/data/test_data',data_type='test')\n",
    "sampler.fit()\n",
    "test_data_df = sampler.get()\n",
    "test_data_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc_max 0\n",
      "acc_mean 0\n",
      "acc_min 0\n",
      "acc_sd 0\n",
      "chg_acc_max 0\n",
      "chg_acc_min 0\n",
      "median_25 0\n",
      "median_50 0\n",
      "median_70 0\n"
     ]
    }
   ],
   "source": [
    "#Check for NAN columns\n",
    "import utility as util\n",
    "columns_numeric = ['acc_max','acc_mean','acc_min','acc_sd','chg_acc_max','chg_acc_min','median_25','median_50','median_70']\n",
    "util.checkNaNColumns(columns_numeric,test_data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformation completed ... \n",
      "Dropping columns  ['acc_mean', 'median_50', 'auc'] ...\n",
      "Test data size  2624\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc_max</th>\n",
       "      <th>acc_min</th>\n",
       "      <th>acc_sd</th>\n",
       "      <th>chg_acc_max</th>\n",
       "      <th>chg_acc_min</th>\n",
       "      <th>median_25</th>\n",
       "      <th>median_70</th>\n",
       "      <th>segment_id</th>\n",
       "      <th>time_per_max_range</th>\n",
       "      <th>distance</th>\n",
       "      <th>time_per_max_chg_range</th>\n",
       "      <th>chg_med25</th>\n",
       "      <th>chg_med70</th>\n",
       "      <th>max_dist_from_mean</th>\n",
       "      <th>min_dist_from_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.744932</td>\n",
       "      <td>-4.317488</td>\n",
       "      <td>1.587947</td>\n",
       "      <td>3.367296</td>\n",
       "      <td>-3.295837</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>seg_00030f</td>\n",
       "      <td>0.000887</td>\n",
       "      <td>5.288675</td>\n",
       "      <td>0.003008</td>\n",
       "      <td>-0.554742</td>\n",
       "      <td>0.558402</td>\n",
       "      <td>4.705090</td>\n",
       "      <td>4.375654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.023881</td>\n",
       "      <td>-4.941642</td>\n",
       "      <td>1.778816</td>\n",
       "      <td>3.663562</td>\n",
       "      <td>-3.951244</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>seg_0012b5</td>\n",
       "      <td>0.000536</td>\n",
       "      <td>5.723099</td>\n",
       "      <td>0.001719</td>\n",
       "      <td>-0.520516</td>\n",
       "      <td>0.678193</td>\n",
       "      <td>4.996055</td>\n",
       "      <td>4.971001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.513429</td>\n",
       "      <td>-5.262690</td>\n",
       "      <td>1.938308</td>\n",
       "      <td>4.025352</td>\n",
       "      <td>-4.248495</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>seg_00184e</td>\n",
       "      <td>0.000392</td>\n",
       "      <td>6.128281</td>\n",
       "      <td>0.001372</td>\n",
       "      <td>-0.566185</td>\n",
       "      <td>0.518353</td>\n",
       "      <td>5.494664</td>\n",
       "      <td>5.286297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.442651</td>\n",
       "      <td>-4.532599</td>\n",
       "      <td>1.414431</td>\n",
       "      <td>3.610918</td>\n",
       "      <td>-3.401197</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>seg_003339</td>\n",
       "      <td>0.000955</td>\n",
       "      <td>5.248034</td>\n",
       "      <td>0.002536</td>\n",
       "      <td>-0.337964</td>\n",
       "      <td>0.544751</td>\n",
       "      <td>4.387866</td>\n",
       "      <td>4.580175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.176150</td>\n",
       "      <td>-4.990433</td>\n",
       "      <td>1.757369</td>\n",
       "      <td>4.060443</td>\n",
       "      <td>-3.828641</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>seg_0042cc</td>\n",
       "      <td>0.000478</td>\n",
       "      <td>5.829775</td>\n",
       "      <td>0.001489</td>\n",
       "      <td>-0.515544</td>\n",
       "      <td>0.453369</td>\n",
       "      <td>5.152549</td>\n",
       "      <td>5.018129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.508769</td>\n",
       "      <td>-6.514713</td>\n",
       "      <td>3.210149</td>\n",
       "      <td>5.283204</td>\n",
       "      <td>-5.164786</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>seg_004314</td>\n",
       "      <td>0.000116</td>\n",
       "      <td>7.241696</td>\n",
       "      <td>0.000418</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.928358</td>\n",
       "      <td>6.502567</td>\n",
       "      <td>6.520840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.828314</td>\n",
       "      <td>-4.672829</td>\n",
       "      <td>1.549083</td>\n",
       "      <td>3.784190</td>\n",
       "      <td>-3.784190</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>seg_004cd2</td>\n",
       "      <td>0.000665</td>\n",
       "      <td>5.513949</td>\n",
       "      <td>0.001753</td>\n",
       "      <td>-0.513854</td>\n",
       "      <td>0.458439</td>\n",
       "      <td>4.794848</td>\n",
       "      <td>4.710557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4.787492</td>\n",
       "      <td>-4.787492</td>\n",
       "      <td>1.785816</td>\n",
       "      <td>3.663562</td>\n",
       "      <td>-3.784190</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>seg_004ee5</td>\n",
       "      <td>0.000676</td>\n",
       "      <td>5.537125</td>\n",
       "      <td>0.001956</td>\n",
       "      <td>-0.537933</td>\n",
       "      <td>0.617233</td>\n",
       "      <td>4.750755</td>\n",
       "      <td>4.822926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4.770685</td>\n",
       "      <td>-4.736198</td>\n",
       "      <td>1.770616</td>\n",
       "      <td>3.637586</td>\n",
       "      <td>-3.526361</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>seg_004f1f</td>\n",
       "      <td>0.000647</td>\n",
       "      <td>5.492714</td>\n",
       "      <td>0.002084</td>\n",
       "      <td>-0.500092</td>\n",
       "      <td>0.499725</td>\n",
       "      <td>4.736192</td>\n",
       "      <td>4.770691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5.638355</td>\n",
       "      <td>-5.552960</td>\n",
       "      <td>2.189022</td>\n",
       "      <td>4.356709</td>\n",
       "      <td>-4.394449</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>seg_00648a</td>\n",
       "      <td>0.000310</td>\n",
       "      <td>6.331435</td>\n",
       "      <td>0.001052</td>\n",
       "      <td>-0.551449</td>\n",
       "      <td>0.569929</td>\n",
       "      <td>5.622360</td>\n",
       "      <td>5.570094</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    acc_max   acc_min    acc_sd  chg_acc_max  chg_acc_min  median_25  \\\n",
       "0  4.744932 -4.317488  1.587947     3.367296    -3.295837        2.0   \n",
       "1  5.023881 -4.941642  1.778816     3.663562    -3.951244        2.0   \n",
       "2  5.513429 -5.262690  1.938308     4.025352    -4.248495        2.0   \n",
       "3  4.442651 -4.532599  1.414431     3.610918    -3.401197        3.0   \n",
       "4  5.176150 -4.990433  1.757369     4.060443    -3.828641        2.0   \n",
       "5  6.508769 -6.514713  3.210149     5.283204    -5.164786        0.0   \n",
       "6  4.828314 -4.672829  1.549083     3.784190    -3.784190        2.0   \n",
       "7  4.787492 -4.787492  1.785816     3.663562    -3.784190        2.0   \n",
       "8  4.770685 -4.736198  1.770616     3.637586    -3.526361        2.0   \n",
       "9  5.638355 -5.552960  2.189022     4.356709    -4.394449        2.0   \n",
       "\n",
       "   median_70  segment_id  time_per_max_range  distance  \\\n",
       "0        7.0  seg_00030f            0.000887  5.288675   \n",
       "1        7.0  seg_0012b5            0.000536  5.723099   \n",
       "2        7.0  seg_00184e            0.000392  6.128281   \n",
       "3        7.0  seg_003339            0.000955  5.248034   \n",
       "4        6.0  seg_0042cc            0.000478  5.829775   \n",
       "5        8.0  seg_004314            0.000116  7.241696   \n",
       "6        6.0  seg_004cd2            0.000665  5.513949   \n",
       "7        7.0  seg_004ee5            0.000676  5.537125   \n",
       "8        6.0  seg_004f1f            0.000647  5.492714   \n",
       "9        7.0  seg_00648a            0.000310  6.331435   \n",
       "\n",
       "   time_per_max_chg_range  chg_med25  chg_med70  max_dist_from_mean  \\\n",
       "0                0.003008  -0.554742   0.558402            4.705090   \n",
       "1                0.001719  -0.520516   0.678193            4.996055   \n",
       "2                0.001372  -0.566185   0.518353            5.494664   \n",
       "3                0.002536  -0.337964   0.544751            4.387866   \n",
       "4                0.001489  -0.515544   0.453369            5.152549   \n",
       "5                0.000418  -1.000000   0.928358            6.502567   \n",
       "6                0.001753  -0.513854   0.458439            4.794848   \n",
       "7                0.001956  -0.537933   0.617233            4.750755   \n",
       "8                0.002084  -0.500092   0.499725            4.736192   \n",
       "9                0.001052  -0.551449   0.569929            5.622360   \n",
       "\n",
       "   min_dist_from_mean  \n",
       "0            4.375654  \n",
       "1            4.971001  \n",
       "2            5.286297  \n",
       "3            4.580175  \n",
       "4            5.018129  \n",
       "5            6.520840  \n",
       "6            4.710557  \n",
       "7            4.822926  \n",
       "8            4.770691  \n",
       "9            5.570094  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import data_formatter as dtFrm\n",
    "formatter = dtFrm.LANLDataFormatter(data_df=test_data_df, data_type='test', doTransform=True)\n",
    "test_df = formatter.transform()\n",
    "print('Test data size ',test_df.shape[0])\n",
    "test_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc_max</th>\n",
       "      <th>acc_min</th>\n",
       "      <th>acc_sd</th>\n",
       "      <th>chg_acc_max</th>\n",
       "      <th>chg_acc_min</th>\n",
       "      <th>median_25</th>\n",
       "      <th>median_70</th>\n",
       "      <th>time_per_max_range</th>\n",
       "      <th>distance</th>\n",
       "      <th>time_per_max_chg_range</th>\n",
       "      <th>chg_med25</th>\n",
       "      <th>chg_med70</th>\n",
       "      <th>max_dist_from_mean</th>\n",
       "      <th>min_dist_from_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.744932</td>\n",
       "      <td>-4.317488</td>\n",
       "      <td>1.587947</td>\n",
       "      <td>3.367296</td>\n",
       "      <td>-3.295837</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.000887</td>\n",
       "      <td>5.288675</td>\n",
       "      <td>0.003008</td>\n",
       "      <td>-0.554742</td>\n",
       "      <td>0.558402</td>\n",
       "      <td>4.705090</td>\n",
       "      <td>4.375654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.023881</td>\n",
       "      <td>-4.941642</td>\n",
       "      <td>1.778816</td>\n",
       "      <td>3.663562</td>\n",
       "      <td>-3.951244</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.000536</td>\n",
       "      <td>5.723099</td>\n",
       "      <td>0.001719</td>\n",
       "      <td>-0.520516</td>\n",
       "      <td>0.678193</td>\n",
       "      <td>4.996055</td>\n",
       "      <td>4.971001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.513429</td>\n",
       "      <td>-5.262690</td>\n",
       "      <td>1.938308</td>\n",
       "      <td>4.025352</td>\n",
       "      <td>-4.248495</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.000392</td>\n",
       "      <td>6.128281</td>\n",
       "      <td>0.001372</td>\n",
       "      <td>-0.566185</td>\n",
       "      <td>0.518353</td>\n",
       "      <td>5.494664</td>\n",
       "      <td>5.286297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.442651</td>\n",
       "      <td>-4.532599</td>\n",
       "      <td>1.414431</td>\n",
       "      <td>3.610918</td>\n",
       "      <td>-3.401197</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.000955</td>\n",
       "      <td>5.248034</td>\n",
       "      <td>0.002536</td>\n",
       "      <td>-0.337964</td>\n",
       "      <td>0.544751</td>\n",
       "      <td>4.387866</td>\n",
       "      <td>4.580175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.176150</td>\n",
       "      <td>-4.990433</td>\n",
       "      <td>1.757369</td>\n",
       "      <td>4.060443</td>\n",
       "      <td>-3.828641</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.000478</td>\n",
       "      <td>5.829775</td>\n",
       "      <td>0.001489</td>\n",
       "      <td>-0.515544</td>\n",
       "      <td>0.453369</td>\n",
       "      <td>5.152549</td>\n",
       "      <td>5.018129</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    acc_max   acc_min    acc_sd  chg_acc_max  chg_acc_min  median_25  \\\n",
       "0  4.744932 -4.317488  1.587947     3.367296    -3.295837        2.0   \n",
       "1  5.023881 -4.941642  1.778816     3.663562    -3.951244        2.0   \n",
       "2  5.513429 -5.262690  1.938308     4.025352    -4.248495        2.0   \n",
       "3  4.442651 -4.532599  1.414431     3.610918    -3.401197        3.0   \n",
       "4  5.176150 -4.990433  1.757369     4.060443    -3.828641        2.0   \n",
       "\n",
       "   median_70  time_per_max_range  distance  time_per_max_chg_range  chg_med25  \\\n",
       "0        7.0            0.000887  5.288675                0.003008  -0.554742   \n",
       "1        7.0            0.000536  5.723099                0.001719  -0.520516   \n",
       "2        7.0            0.000392  6.128281                0.001372  -0.566185   \n",
       "3        7.0            0.000955  5.248034                0.002536  -0.337964   \n",
       "4        6.0            0.000478  5.829775                0.001489  -0.515544   \n",
       "\n",
       "   chg_med70  max_dist_from_mean  min_dist_from_mean  \n",
       "0   0.558402            4.705090            4.375654  \n",
       "1   0.678193            4.996055            4.971001  \n",
       "2   0.518353            5.494664            5.286297  \n",
       "3   0.544751            4.387866            4.580175  \n",
       "4   0.453369            5.152549            5.018129  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_seg = test_df['segment_id']\n",
    "x_test = test_df.drop(['segment_id'],axis=1)\n",
    "x_test.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Using backend ThreadingBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  29 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=6)]: Done 150 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=6)]: Done 353 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=6)]: Done 636 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=6)]: Done 800 out of 800 | elapsed:    0.1s finished\n"
     ]
    }
   ],
   "source": [
    "import pickle as pickle\n",
    "outfile = 'random_forest_mae.model'\n",
    "randForReg = pickle.load(open(outfile, 'rb'))\n",
    "\n",
    "y_test_pred = randForReg.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.68409208, 3.11329414, 3.11955645, ..., 2.79858352, 3.02739058,\n",
       "       3.76398325])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create dataframe with the series y_test_pred and segments\n",
    "y_test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['seg_00030f', 'seg_0012b5', 'seg_00184e', ..., 'seg_ff79d9',\n",
       "       'seg_ffbd6a', 'seg_ffe7cc'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_seg.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total predicted segments  2624\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seg_id</th>\n",
       "      <th>time_to_failure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>seg_00030f</td>\n",
       "      <td>3.684092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>seg_0012b5</td>\n",
       "      <td>3.113294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>seg_00184e</td>\n",
       "      <td>3.119556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>seg_003339</td>\n",
       "      <td>3.609233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>seg_0042cc</td>\n",
       "      <td>3.090252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>seg_004314</td>\n",
       "      <td>1.162185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>seg_004cd2</td>\n",
       "      <td>3.420281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>seg_004ee5</td>\n",
       "      <td>3.385127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>seg_004f1f</td>\n",
       "      <td>3.414032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>seg_00648a</td>\n",
       "      <td>2.896904</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       seg_id  time_to_failure\n",
       "0  seg_00030f         3.684092\n",
       "1  seg_0012b5         3.113294\n",
       "2  seg_00184e         3.119556\n",
       "3  seg_003339         3.609233\n",
       "4  seg_0042cc         3.090252\n",
       "5  seg_004314         1.162185\n",
       "6  seg_004cd2         3.420281\n",
       "7  seg_004ee5         3.385127\n",
       "8  seg_004f1f         3.414032\n",
       "9  seg_00648a         2.896904"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data_dict = {'seg_id': x_test_seg.values,'time_to_failure': y_test_pred}\n",
    "out_df = pd.DataFrame(data_dict)\n",
    "print('Total predicted segments ',out_df.shape[0])\n",
    "out_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_df.to_csv('results.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result scores 1.8 in Kaggle test. The score is not that great but surely indicates more feature engineering. Moving on to another notebook for future regressions. Click on  <a href=\"http://localhost:8888/notebooks/LANL_Earthquake_prediction_2.ipynb\">LANL_Earthquake_prediction_2.ipynb</a> for next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
